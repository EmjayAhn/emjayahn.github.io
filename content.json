{"posts":[{"title":"181018_DailyScrum","text":"181018오늘 한 일 Web Crawling (Requests, BS4) 공부 Github 사용할 준비 GitPages 사용 방법 공부 했던 내용, 공부할 내용 어떻게 정리 할지 고민 프로젝트 팀 회의 내일 할 일 Pandas 내용 정리, 반복 숙달 수업 내용 복습 주말 공부할 내용 계획 코딩 습관을 기르기 위해 일일코딩과 TWIL에 대해 고민 뭘 느꼈는가 크롤링 코드를 보면서 공부하고, 또 다시 스스로 짜는 것을 연습하면서 내용의 개념과 코드 자체는 어려운 것이 없으나 BeautifulSoup 이나 Requests 패키지에 담겨있는 각 메서드 들의 종류, 기능, 메서드마다 들어가는 attribute를 참고 할 줄 알아야 된다고 느꼈다. 매우 기본적인 메서드들일 수 있기에 외워야 할 수도 있겠지만 (또한 반복한다면 숙달되겠지만) 잊어버렸을 때 각 라이브러리들의 Document들을 잘 볼 줄 아는 것이 중요하다고 느꼈다. 프로젝트 OT 를 한 만큼 본격적인 프로젝트를 진행하기에 앞서 꼼꼼히 준비해 나가야겠다.","link":"/2018/10/18/181018-TodayWhatILearned/"},{"title":"181019 TodayWhatILearned","text":"181019오늘 한 일 Web Crawling (Requests, BS4) 공부 Github 사용할 준비 GitPages 사용 방법 공부 했던 내용, 공부할 내용 어떻게 정리 할지 고민 프로젝트 팀 회의 내일 할 일 Pandas 내용 정리, 반복 숙달 수업 내용 복습 주말 공부할 내용 계획 코딩 습관을 기르기 위해 일일코딩과 TWIL에 대해 고민 뭘 느꼈는가 크롤링 코드를 보면서 공부하고, 또 다시 스스로 짜는 것을 연습하면서 내용의 개념과 코드 자체는 어려운 것이 없으나 BeautifulSoup 이나 Requests 패키지에 담겨있는 각 메서드 들의 종류, 기능, 메서드마다 들어가는 attribute를 참고 할 줄 알아야 된다고 느꼈다. 매우 기본적인 메서드들일 수 있기에 외워야 할 수도 있겠지만 (또한 반복한다면 숙달되겠지만) 잊어버렸을 때 각 라이브러리들의 Document들을 잘 볼 줄 아는 것이 중요하다고 느꼈다. 프로젝트 OT 를 한 만큼 본격적인 프로젝트를 진행하기에 앞서 꼼꼼히 준비해 나가야겠다. 181019오늘 한 일 Web Crawling 공부 : Selenium을 활용한 크롤링 Pandas 활용하여 여러가지 data import 하고, 정렬 바꾸는 연습 Terminal 환경설정 zsh, oh-my-zsh 설치했다. git을 적극적으로 활용할 계획이므로, git사용에 유리한 zsh 설정을 마쳤다. 팀 프로젝트에 활용할 데이터 셋 탐색 github 블로그 Deploy 에 성공했다. Daily 스크럼을 작성하는 것이 하루의 계획과 정리를 하는데 유용하기에, 꾸준히 작성하면서, github 블로그에도 올려볼 계획이다. 내일 할 일 Pandas 내용 정리, 반복 숙달 Naver Article Crawling, NBA Data Crawling 확률과 통계 정리 (연속확률분포 부분) 뭘 느꼈는가 점차 학습하는 내용과 알아야 될 내용이 많아지면서, 내가 배운 것들, 알고 있는 것들. 정확히는 어떤 것에 관해 존재는 알고 있으나 내 머릿속에서 당장 꺼내서 쓰기에는 어려운 것들이 많아지고 있다. 또한, 내 머릿속에서 꺼내기 쓰기 힘들어 구글을 통해 찾고자하면 내가 기억했던, 알고 있는 정보들과 조금은 내용이 다르고, 이것을 Searching 하는데 쓰는 시간이 아깝다는 생각이 들었다. 앞으로는 매일 학습하는 내용을 바탕으로, 직접 찾기 쉬운 형태로 정리할 필요성을 느꼈다. 개인. WIKI화.","link":"/2018/10/19/181019_TodayWhatILearned/"},{"title":"181024 TodayWhatILearned","text":"181024 TWIL오늘 할 일은 무엇인가 멀티스레딩으로 네이버 크롤링 코드 작성 오후 4시 스터디 확률 분포 공부 오늘 한 일은 무엇인가 멀티스레딩 개념을 활용한 크롤링 코드 작성 오후 4시 스터디 확률분포 공부 내일 할 일은 무엇인가 확률분포 공부 프로젝트 모임 Pandas 정리해보기 무엇을 느꼈는가 Documentation 과 각종 개념 자료들을 혼자 보고 공부하면서, 파이썬이라는 언어가 단순히 책 한권 끝냈다고 해서 끝나는 언어가 아님을 깨달았다. 기본적인 문법을 금방 익숙해져서, ‘역시 쉬운 언어인가’라고 생각했다가 오늘 다양한 자료를 찾아보고 읽어보면서 언어 하나만해도 아직 공부할게 무궁무진 하다는 것을 깨달았다.","link":"/2018/10/24/181024-TodayWhatILearned/"},{"title":"181022 TodayWhatILearned","text":"181022 TWIL오늘 할 일은 무엇인가 블로그 테마 바꾸기 Selenium 과제 두번째 것 (17:47 - 19:00) 확률 분포 다시 한번 정리하기 데이터구조 (PseudoLinkedList, Stack, Queue)정리 새 맥북 환경 설정 조금씩 마저 더하기 DailyScrum Upload 오늘 한 일은 무엇인가 Selenium NBA Page Crawling 해서, DataFrame으로 정리 (17:47 - 18:55) Stack 정리 Github 설정 내일 할 일은 무엇인가 확률 분포 공부 Queue 정리 무엇을 느꼈는가 맥북을 바꾸면서, 환경 설정하는데 너무 많은 시간이 든다. 틈틈히 하고 있는데도 아직 이전 맥북의 환경에서 100% 똑같은 환경을 만들지 못하고 있다. 장비를 바꿀 때, 혹은 다른 작업 환경에서 연속성을 이어 나가기 위해 나에게 맞는 환경설정도 정리할 필요성을 느낀다. 오늘 공부한 PseudoLinkedList, Stack, Queue 의 활용성에 대해 깊이 고민 해 볼 수 있어서 뿌듯하다. 특히나 PseudoLinkedList의 경우 내가 사용하지 않았던 자료구조나 class를 목적에 맞게 customize 할 수 있는 측면에서 활용성이 높다고 생각된다. 다른 사람이 작성한 class 를 잘 읽어보고, 그 활용도를 높이기 위해 overriding 하는 방법을 틈틈히 챙겨 봐야겠다.","link":"/2018/10/22/181022-TodayWhatILearned/"},{"title":"181023 TodayWhatILearned","text":"181023 TWIL오늘 할 일은 무엇인가 Queue 정리 하기 확률 분포 공부 &lt;스터디&gt;멀티 스레딩 개념을 포함한 네이버 크롤링 코드짜기 오늘 한 일은 무엇인가 &lt;스터디&gt; 멀티 스레딩에 관해 이야기, 공부해볼 정보들 공유, 어떻게 코드를 구성할 것인지 의견을 나누었다. Queue 개념 정리 및 코드 구현 연습 베르누이 분포, 이항분포 정리 및 Searching 블로그 수정 내일 할 일은 무엇인가 오후 4시 멀티 스레드 관련한 내용으로 온라인 스터디 모임 예정 멀티스레딩 개념을 활용한 네이버 크롤링 코드 짜기 각종 확률 분포 및 검정 부분까지 복습 무엇을 느꼈는가 오늘 공부한 testing 시작부분부터는 그간 배웠던 것을 한꺼번에 적용한다. 배웠던 여러가지 분포를 활용하여,가설을 세우고 이 가설이 선택한 분포의 관점에서 봤을 떄, 가설을 선택할지 기각할지에 관한 내용은 점차data를 통해 prediction 을 해가는 과정에 있는 듯한 느낌을 받았다. 아직 검정 과정과 앞으로 공부하게 될 여러가지 분석 모델을 이해하기에 앞서배운 확률분포 부분의 내용이부족한듯하여, 계속 꾸준히 앞부분을 공부해야될 것 같다.","link":"/2018/10/23/181023-TodayWhatILearned/"},{"title":"181026_TodayWhatILearned","text":"181026 TWIL오늘 한 일은 무엇인가 Xpath, Scrapy 를 활용한 Crawling 공부 DataScience 와 DataEngineering 의 차이점 찾아보기 내일 할 일은 무엇인가 확률분포 공부 Scrapy 활용해보기 무엇을 느꼈는가 DataScience 와 DataEngineering 의 공통점과 차이점에 대해 알아보았는데, 아직은 현업에서 각분야가 하고 있는 일이 어떻게 다른지 확실한 감이 오지 않는 것 같다. 내가 명확히 재밌어하는 것은 아직까지는어떤 디테일한 분야가 아니라, 수학적인 것, 프로그래밍 적인 것들을 배운 것을 적용해보고 응용하는 것에흥미를 느끼는 것 같은데 이보다 더 앞서 생각해보고 결정하려고 하니 감이 잘 오지 않는 것 같다. 지금 현재로서는, 다양한 기계학습 알고리즘과 머신러닝 등을 이용하여 prediction 등을 통해 새로운 Insight를 얻어내는 것에 관심이 있는 것 같다. 이 분야를 공부하고 배워 나가면서 엔지니어링 분야를 필요에 의해 점차공부해 나가는 방향으로 삼고 싶다.","link":"/2018/10/26/181026-TodayWhatILearned/"},{"title":"181027-TodayWhatILearned","text":"181027 TWIL오늘 한 일은 무엇인가 확률 수학 공부 자기전 (스터디)데이터구조 부분 1강 듣기 내일 할 일은 무엇인가 확률분포를 다시 복습하면서 검정, 추정에서 이어지는 부분 꼼꼼히 공부 데이터 구조 강의 수강 계획 세우기 무엇을 느꼈는가 검정방법론에 대해 좀더 꼼꼼히 보았다. 수학적인 수식들은 수업시간에 다 이해가 되는 편이지만 이 수식들을말로써 표현하고, 글로 풀어쓰는 순간 머리가 빠릿빠릿 안돌아가는 느낌이어서, 한단계한단계 논리적으로 따져가며공부하니 이제야 좀 편해진것 같다. 가설 검정 같은 때에도, 말로 풀어쓰는 것 보다 간단하게 수식으로 표현하고,각각의 p-value 를 확인한뒤 원래 작성했던 H_0, H_a 에 대해 생각해보면 쉽게 되었으나 이것을 말로 표현하고글로 구성하려고 하니 간단한것도 복잡하게 생각했던 것 같다. 결국 내가 알게 된것을 상대방과 논의하고앞으로 만나게 될 클라이언트들을 대상으로 설명해야하는 것이 모두 이런 부분에서 시작되는 것임을 느꼈기에,내 생각과 가정 -&gt; 수식으로 표현 -&gt; 다시 말 혹은 글로 표현 하는 것을 습관처럼 해야겠다.","link":"/2018/10/27/181027-TodayWhatILearned/"},{"title":"181028-TodayWhatILearned","text":"181028 TWIL 오늘 한 일은 무엇인가 검정과 추정 공부 Blog 테마 수정 내일 할 일은 무엇인가 ‘추정’에서 수식 부분 다시 보기 (Study) 데이터 구조 강의 듣기 무엇을 느꼈는가 MaximumLikelihood 를 실제로 손으로 써가며 풀어보는 과정에서, 지금까지 배웠던 수학적 테크닉들이 모두 쓰이는 것을 보고 뿌듯하면서도 재미있었다. 뿌듯한 이유는 아마도 한줄 한줄 써가는 내용이 여태 공부한 수학 개념들로 이루어진것 때문일 것이다. 그 중에서도 다음 식을 전개하는 과정에서 눈에 잘 들어오지 않아 전개하지 못할 때도 있었다. 이것은 아마 앞부분 개념이 그 순간에 적용이 되지 않기 때문이라고 생각된다. 행렬의 내용중 몇가지 특성들과 라그랑주 멀티플라이어에 대한 수식을 틈이 생길떄 챙겨서 봐야겠다. 오늘은 수학을 공부하느라 프로그래밍은 하지 못했다. 중간에 졸린 걸 해소해보고자 블로그 테마 색깔 수정과 그 수정을 위해 블로그의 코드 구조를 본게 전부 였다. 30분 푹빠져서 하다가 주객전도 되지않으려 다음으로 미뤘다. 위 주제들에 관해 알게된 것도 많은 하루였고, 뿌듯한 하루였다.","link":"/2018/10/28/181028-TodayWhatILearned/"},{"title":"181025_TodayWhatILearned","text":"181025 TWIL오늘 할 일은 무엇인가 확률분포 공부 프로젝트 모임 Selenium, Scrapy, Pillow 활용 공부 오늘 한 일은 무엇인가 Selenium, Pillow 활용 공부 내일 할 일은 무엇인가 확률분포 공부 무엇을 느꼈는가 동영상과 이미지를 처리하는 방법에 대해 공부하면서, Selenium 을 활용해 많은 활용도를 느꼈다.주말을 이용해 동영상이나 이미지들을 Crawling 해서 class 형태로 만드는 방법을 시도해봐야겠다.","link":"/2018/10/25/181025-TodayWhatILearned/"},{"title":"181031-TodayWhatILearned","text":"181031 TWIL 오늘 한 일은 무엇인가 선형회귀분석 공부 행렬의 미분 공부 (PROJECTmini)A star Algorithm 개념 정리 (PROJECT)프로젝트 진행 data 탐구 데이터 전처리 공부 내일 할 일은 무엇인가 Project 모임 데이터 전처리, 데이터들의 의미 파악, 예측할 delay 부분 정의하기 무엇을 느꼈는가 오늘은 아침부터 하루종일 컴퓨터 앞에 앉아 있어서, 눈과 목이 너무 아프다. 그래도 새로운 알고리즘 내용에관한 이해와, 앞으로 진행할 메인 프로젝트의 data들의 의미를 파악해서 뿌듯한 하루였다. Data의 의미를파악했으나 이것을 처리하기 위해서 numpy 와 pandas 의 documentation 을 읽으면서 데이터들을 다뤘다.라이브러리와 패키지들의 메소드와 클래스들을 자유자재로 다루기 위해선, 계속 사용해보면서 익혀야 함을 느꼈다.메소드들을 알면 복잡하게 코드를 안짜도 이미 내장되어있는 메소드로 손쉽게 처리할 수 있기 때문이다. data를 혼자 곰곰히 보다, 시간에 관한 column 의 의미를 파악했으나 이것을 손쉽게 합쳐서 데이터들을재정렬하는데 오늘 실패했다. 의미는 파악했으니, 내일 좀더 시도해보면 시간에 관한 data 를 정리할 수 있지않을까 한다.","link":"/2018/10/31/181031-TodayWhatILearned/"},{"title":"181029-TodayWhatILearned","text":"181029 TWIL 오늘 한 일은 무엇인가 자료구조 Binary Tree, Stack 으로 Queue구현, Stack 응용 추정 부분 복습 스터디 나갈 방향 이야기 A star algorithm search 내일 할 일은 무엇인가 ‘추정’에서 수식 부분 다시 보기 무엇을 느꼈는가 스터디 첫 모임을 가졌다. 프로그래밍에 관해 알고있는 것들을 활용하고 응용하는 쪽으로 어떻게 하면 될지 많은 의견을 나누었다. 상상의 나래를 펼치니, 타오르는 열정과 함께 만들어보고 싶은 것은 많았으나…. 아직 아는게 많지 않기에.. 다시 현실에 눈을 돌렸다. Maze 문제에서 다른 알고리즘을 통해 구현해보려고 의견이 모아졌다. 직접 찾아서 적용해보는 첫 algorithm 이기에, 직접 찾아가면서 공부하고, 이것을 적용하는 경험을 통해 또 다른 배울 것이 있을 것 같아 매우 기대된다.","link":"/2018/10/29/181029-TodayWhatILearned/"},{"title":"181101-TodayWhatILearned","text":"181101 TWIL 오늘 한 일은 무엇인가 Project 모임 Data 일부 전처리 Crawling 공부 내일 할 일은 무엇인가 Database - MySQL 공부 Pandas 라이브러리 살펴보기 miniProject Crawling 주제 선정, 코드짜기 무엇을 느꼈는가 프로젝트 모임에서 우리가 예측할 Data (Departure Delay)를 정의하고, 나는 오늘 시각 data 의 전처리를 하였다. Data 들이 의미없는 값들을 가지고 있을 때 어떻게 처리해야 할지 고민하다가 확실한 답은 못얻은 채, 우선 시각 데이터의 formatting 만 바꾸었다. data들을 어떻게 채워넣어주어야 할지는 조금더 공부해 보아야 할 것 같다. 첫 프로젝트 모임의 느낌이 매우 좋았다. 모임을 하기 전까지는 내가 했던 것들이 맞는가 하는 의구심과 project를 하기에는 아직 부족한 지식과 실력이라는 걱정이 앞섰다. 오늘 모임을 하면서 각자 살펴보았던 data 의 특징들과 앞으로 어떻게 data 를 다듬을 것인지 얘기하면서, 더 좋은 방향과 몰랐던 것들, 알았던 것들을 서로 나누면서 발전적인 대화가 되었다는게 매우 뿌듯하다. 모임에서 받은 좋은 느낌을 이어서, 오늘 내가 맡기로한 부분을 해결하기 위해 앉았고, 또 나름 해결한 부분이 있는 것 같아 작은 성취감을 맛보았다. 협업을 하기 위해 git에 관해 좀더 공부하고 나눌 필요성이 느껴졌다. 특히나 code conflict 가 실제로 발생하기 전에 어떻게 다루어야 하는 것인지 좀더 깊게 공부할 필요성을 느꼈다.","link":"/2018/11/01/181101-TodayWhatILearned/"},{"title":"181102-TodayWhatILearned","text":"181102 TWIL 오늘 한 일은 무엇인가 Database - MySQL 공부 A * 알고리즘 스터디 NaN 값 처리에관한 자료 서칭 내일 할 일은 무엇인가 Project 모임 Pandas 라이브러리 정리 miniProject Crawling 코드짜기 A * 알고리즘 짜기 무엇을 느꼈는가 오늘 스터디에서 A* 알고리즘를 주제로 얘기를 좀더 나누었다. 각자 공부해오신 내용을 바탕으로 알고리즘의흐름이 어떻게 되어가는가 좀더 구체적으로 생각해보고자 했다. 좀더 해결법에 가까워진 느낌을 받았으나,이제는 좀더 구체적으로 구현해보면서 다가오는 문제들을 해결해보고자 했다. 모든걸 완벽하게 이해하고 실현하는것만이 답은 아니기 때문이라고 생각한다. 주말동안은 프로젝트, 미니프로젝트, 알고리즘 적용 코딩, 수학 공부, DB공부.. 산더미지만 하나씩 그어나가야겠다.","link":"/2018/11/02/181102-TodayWhatILearned/"},{"title":"181103-TodayWhatILearned","text":"181103 TWIL 오늘 한 일은 무엇인가 Crawling miniProject 코드 작성 Pandas 라이브러리 정리 Project 주말동안 할일 정하기 내일 할 일은 무엇인가 Project Data 회기 돌려보기 회기 부분 공부 크롤링 프로젝트 개선 사항 고민 (시간이 되면) A* 알고리즘 코드 짜보기 무엇을 느꼈는가 whoscored 사이트의 Player 정보를 크롤링 하는 miniProject 의 코드를 작성하였다. Selenium을통해서 크롤링하는데, headless 적용을 하면 에러가 나는 부분을 어떻게 처리해야할지 고민해보아야 한다.Chrome webdriver 를 열어놓는 환경과 headless 환경의 차이가 있는 것 같은데, 이 부분은 document를 살펴보아야 할 것같다. window창을 열어놓는것 과 그렇지 않은 것의 차이점이 있는지 확인해야한다. 함수로 짠 코드를 class 화 시킬 때는 다루는 범위가 커져야 한다는 강박관념이 있다. class 화 시켰을때의 편의성 부분을 고민하면서 위 생각으로 흐름이 이어지는 것 같은데, 그렇지 않기 위해 class의 장점을좀더 체감해볼 필요가 있다. Linear Regression 강의를 들으면서, LineByLine 수식을 이해하는데는 문제가 없으나 이야기의 큰 그림을 놓치는 경향이 있는 것 같다. 내일은 이 부분을 중점적으로 공부해보고, 메인 프로젝트에 적용해보는 것 까지해봐야겠다.","link":"/2018/11/03/181103-TodayWhatILearned/"},{"title":"181104-TodayWhatILearned","text":"181104 TWIL 오늘 한 일은 무엇인가 회기 부분 공부 Project Data 회기 돌려보기 내일 할 일은 무엇인가 Project 모임 회기 부분 정리 크롤링 프로젝트 개선 사항 고민 (시간이 되면) A* 알고리즘 코드 짜보기 무엇을 느꼈는가 다리를 다치고 통증으로 인해 집중해서 코드를 짜기 힘들었다. 수학 이론을 공부하면서 내일 있을 프로젝트모임을 준비했고, 팀원들께서 만든 코드를 정리하며 데이터를 다시 추출하였다. 이 데이터들을 통해 회기의 몇몇가지를 돌려보았다. 이것을 토대로 내일 팀원들과 함께 이야기를 나눠보며 좀더 어떻게 할 수 있을지 고민해봐야겠다.","link":"/2018/11/04/181104-TodayWhatILearned/"},{"title":"181105-TodayWhatILearned","text":"181105 TWIL 프로젝트 STEP 전처리 Nan 값 처리 해결 Partial Regression Plot 그려보기 오늘 한 일은 무엇인가 프로젝트 모임 Crawling miniProject 와 mainProject 진행 내일 할 일은 무엇인가 프로젝트, 오늘까지 진행사항 코드 정리 수학 회기 전체 정리 프로젝트 생각하기 무엇을 느꼈는가 오늘은 프로젝트 모임을 통해서, 많은 것을 얻었다. OLS function 을 실제로 돌림에 있어서 많은 제약조건이필요함을 알게되었고, 그만큼 데이터전처리가 매우 중요하다는 것을 알게 되었다. 다양한 feature 들마다 다양한 방법으로 전처리를 해주어야 한다. 처음엔 NaN값의 처리 방식에 대해 고민했으나,이제는 각 feature 의 특성들마다 전처리 해주는 방식이 달라져야 하고, 또 이번 고비가 넘어가게 되면좋은 prediction 결과를 얻기 위해 다양한 feature 의 조합이 필요함이 피부에 와닿았다. 만족스런 결과물을 얻기 위해선, 아는게 많은 것 보다, 그 결과물을 만들고자 하는 구성원이 중요함을 느꼈다.알고있는 지식은 해결해야할 문제보다 항상 작기 마련이다. 또한 알고있는 지식이 완벽한지는 계속 스스로 의문을던지며 업데이트 해야만한다. 하지만 이보다 더 중요한 것은 문제에 부딪힐 때마다 의욕적이고, 해결해보고자 하는 팀원들덕분에 오늘의 보람과 뿌듯함을 얻을 수 있었던 것 같다.","link":"/2018/11/05/181105-TodayWhatILearned/"},{"title":"181108-TodayWhatILearned","text":"181108 TWIL 오늘 한 일은 무엇인가 Project Data EDA, OLS 돌려보기 내일 할 일은 무엇인가 Project Data EDA, OLS 돌려보기 무엇을 느꼈는가 프로젝트 과정에서 Performance 가 안나오는 이유에 대해 알게된 계기였다. EDA 는 계속 하더라도 부족함이 많은것이고,데이터를 처리할 때 line by line 근거가 있어야 한다고 느꼈다. 처음부터 전 과정을 진행하는데 있어 매우 시행착오가 많았고, 또 앞으로도 많을 것이지만 계속 반복해서 시행해보는 것이 중요할 것 같다.","link":"/2018/11/08/181108-TodayWhatILearned/"},{"title":"181107-TodayWhatILearned","text":"181107 TWIL 오늘 한 일은 무엇인가 Crawling Project 정리 및 제출 내일 할 일은 무엇인가 Prediction Project","link":"/2018/11/07/181107-TodayWhatILearned/"},{"title":"181109-TodayWhatILearned","text":"181109 TWIL 오늘 한 일은 무엇인가 Crawling miniproject 발표 Prediction main project data 탐색 내일 할 일은 무엇인가 Project 모임 무엇을 느꼈는가 Crawling miniproject 의 troubleshooting 시간이 있었다. 발표를 끝내고 나서는 하나를 마쳤다는 시원한 감이 있었지만, comment 들을 듣고 많이 부족함을 느낀 시간이었다. 코드를 작성할 때, 공통된 요소의 추상화가 선택적이 아니라 필수적임을 알게되었다. 간단한 것이라도 반복적으로 작성하는 것은 python convention 에도, 또 프로그래밍의 근본적인 취지에도 어긋나는 것이다. 처음부터 일반화된 포맷으로 작성하기엔 아직 실력이 많이 부족하다. 간단한 구현에서 module 화까지 내가 짜는 대부분의 코드를 연습하다 보면 늘겠지… 메인 프로젝트의 data 간의 연관성이 잘 보이지 않는다. 지난 시간에 알게된 하루 주기로의 delay가 반복됨을 알고 있었으나, datetime 형식으로, 혹은 int나 float 형식으로 ols 에 집어 넣으면 주기성을 잡아내지 못하는 것 같다. 시간 단위로 X feature 로 들어가면 좋을 것 같은데, ols formula 에 시간을 집어넣으면 계속 category 화 된다. 이렇기 때문에 그 해당 정확한 시간이 있지 않으면 coefficient 가 먹지 않지…. 시간을 표현하기 위해 60진법도 찾아보고, 1분 단위로 int 숫자에 mapping 할까도 생각해보았으나, 결국 mapping 해서 ols 에 돌리면 2400 이후 값은 없는데도 x 축에 들어가게 된다….","link":"/2018/11/09/181109-TodayWhatILearned/"},{"title":"181110-TodayWhatILearned","text":"181110 TWIL 오늘 한 일은 무엇인가 Prediction main project data 탐색 내일 할 일은 무엇인가 Project 모임 무엇을 느꼈는가 어제 고민했던, 시간을 사용하여 Regression 을 돌리는데는 성공하였다. 단위를 바꿔주는 방법으로 60진법도 생각하고, radian 으로 바꾸는 방법도 생각해보다가 epoch 방법으로 기준시점에서 지난 초 수 로 scale 과 unit 을 바꿔준디 돌렸더니, 돌아는간다… 문제는 전혀 예측했던 모형이 아니었다. scatter plot 의 외형만 보고 판단했다는 것을 마지막에 깨달은 것 같다. 모델을 하기위해 묶어보고 새로운 feature 라고 생각되는 것도 빼보지만 아직 경향성이나 공통적인 특정 같은 것은 보이지 않는다.","link":"/2018/11/10/181110-TodayWhatILearned/"},{"title":"181112-TodayWhatILearned","text":"181112 TWIL 오늘 한 일은 무엇인가 프로젝트 발표 및 Feedback 내일 할 일은 무엇인가 프로젝트 모임 &amp; 시계열 공부 무엇을 느꼈는가 메인프로젝트를 다루는 기간동안의 중간결과를 발표하는 시간을 가졌다. 전달력이 충분하지 못한 느낌을 많이 받았다. 내 머릿속에 있는 것을 다른 사람에게 전달하는 능력 역시 많이 필요함을 깨달은 시간이었다. 프로젝트 내용에 있어서는, 아직 부족한것이 많다. 퍼포먼스도 눈에 띄게 나오는 것이 없다. 원인은 아마도 눈에 띄는 데이터들의 경향성을 보지 못한 탓이 아닐까 싶다. 가지고 있는 train 데이터 전체를 두고는 뚜렷한 경향성을 보지 못하고 있다. 여러가지 제한 조건을 두면서 쪼개서 봐야하는 작업이 더 필요한 것 같다.","link":"/2018/11/12/181112-TodayWhatILearned/"},{"title":"181119-TodayWhatILearned","text":"181119 TWIL 오늘 한 일은 무엇인가 시계열 공부 MA, AR, ARMA 공부 및 수식 꼼꼼히 전개 스터디 모임 : 프로그래밍 구현계획짜기 내일 할 일은 무엇인가 ARIMA, SARIMA 수식 정리 DataStructure 코드 정리 A* 알고리즘 공부 회기분석 리뷰 무엇을 느꼈는가 할게 산더미인듯한 느낌이지만, 하나씩 그어나가다보면 되겠지라는 마음으로…체력적으로 힘듬이 느껴진다..","link":"/2018/11/19/181119-TodayWhatILearned/"},{"title":"181111-TodayWhatILearned","text":"181111 TWIL 오늘 한 일은 무엇인가 Project 모임 내일 할 일은 무엇인가 Project_Data 탐색 시계열 분석 공부 무엇을 느꼈는가 어제보다는 약간의 진보가 있었지만, 이에 대한 이유는 명확히 몰라 사실 분석이라기보다 얻어걸린 기분이든다. EDA 를 통해 작성한 모델링에서의 식은 아직까지 완성된 느낌을 받지 못해 답답하고, 방향성을 잘못 접근하고 있는 것인가 하는 느낌을 받기도 했지만, 마지막에 조금 기분이 나아졌다. 내일 오전에는 프로젝트에 밀렸던 시계열 데이터 분석에 관한 기초적인 공부를 다시 하고, 오후에는 프로젝트 데이터를 좀더 살펴보아야겠다.","link":"/2018/11/11/181111-TodayWhatILearned/"},{"title":"181120-TodayWhatILearned","text":"181120 TWIL 오늘 한 일은 무엇인가 시계열 공부(SARIMA) BST 공부 내일 할 일은 무엇인가 A* 알고리즘 공부 회기분석 리뷰 무엇을 느꼈는가 오늘 시계열을 강의가 마무리 되면서, 가장 중요한 교훈은 ‘세상의 모든 시계열 데이터를 현재 배운 모델로구현할 수 없다’인 것 같다. 회기 분석보다 훨씬더 어려웠던, 수식 전개들이 많았는데 모델링 할 수 있는 실제데이터가 많이 없다는 것이 안타까웠다. 그럼에도 불구하고 이전 프로젝트에서 다루었던 데이터를 ARIMA 등을 적용할 수 있을지 다시한번 프로젝트파일을 열어봐야겠다. 내일은 Projectmini 에서 하기로한 A* 알고리즘을 구현하는 것을 고민해 봐야한다. 프로젝트 기간동안미뤄두었던 것을 하는 것이라, 의지는 충만하지만, 이전에 막혔던 부분에서 다시 어디서부터 봐야할지 복기 하는시간이 오래 걸릴 것 같다.","link":"/2018/11/20/181120-TodayWhatILearned/"},{"title":"181121-TodayWhatILearned","text":"181121 TWIL 오늘 한 일은 무엇인가 A* Alogorithm : Pseudo Code 작성 ~ PACF 공부 내일 할 일은 무엇인가 시계열 모형의 추정 부분 나머지 공부 NLTK, KoNLPY 메소드 정리 무엇을 느꼈는가 A* 알고리즘에 관련된 많은 자료들을 읽어보고, 정리하면서 어떻게 구체적으로 이 알고리즘이 흘러가는지파악했다. 기초적인 알고리즘들은 체계적으로 정리되어있는 자료들이 많지만, 이렇게 응용이 된 알고리즘들은업계와 학계에서 사용하면서 점차 개발됨에 따라 다양하고, 어느 방면에 효율성을 맞추느냐에 따라서 정말 다양하게파생된 것들이 많다. 그 중에서도 가장 간단하고 기본적인 원리가 설명되어있는 documentation 을 찾고,이해하려고 하다보니 시간이 많이 걸린 것 같다. 이렇게 기본적인 이해를하고, 다양한 응용된 문서를 보니, 그 각각이 추구하고 있는 방향도 읽혀지는 것 같다.내일부터는 이렇게 파악된 것을 바탕으로 본격적인 코드 구현을 해보아야할 것 같다. 오늘 잠깐 생각한 바로는,우리가 배웠던 자료구조를 사용하는 것이 효율적인지, 파이썬에 내장되어있는 자료구조를 사용 할 것인지 간에효율을 결정하는데, 어떤 factor 를 기준으로 정해야 할지 모르겠다. 스터디 때 이 부분도 물어보고, 이야기를나눠보면 좋을 것 같다. AR, MA 가 p, q 차로 되었을 때, k에 따른 PACF 함수의 모양을 증명해 보면서, AR, MA 의 ACF,COV general form 을 계속 찾아보면서 증명하게 되었다. 사실은 이 부분까지 다시한번더 증명하고 이를참조하는 방향으로 증명을 써 내려가야하는 것이 맞지만, 이전에 했다는 핑계로 참조했는데, 찜찜하다.증명은 어렵지 않았으나, 외워야 한다는 것이 좀 압박이다.","link":"/2018/11/21/181121-TodayWhatILearned/"},{"title":"181125-TodayWhatILearned","text":"181125 TWIL 오늘 한 일은 무엇인가 (스터디) A* Alogorithm git 정리 (프로젝트) 프로젝트 리뷰 (프로젝트) 깃허브 다루기 (개인공부) 판다스 공부 (개인공부) 자연어 처리 메서드 정리 내일 할 일은 무엇인가 (개인공부) 자연어 처리 메서드 마저 정리 (개인공부) AWS 정리 (개인공부) 연속확률분포 정리(수식 꼼꼼하게) 무엇을 느꼈는가 지난주 프로젝트 리뷰 시간에 박사님께서 주신 Comment를 바탕으로 지난 프로젝트 했던 것을 복기하는 시간을 가졌다. 그 중 오늘 집중해서 탐구 했던 것은, Partial Regression 에서 경향이 보였을 때, 이를 구체적으로 어떻게 다루는지 연구하였다. 우리가 Partial Regression plot 을 보고 두가지 경향이 있을때, 한 경향에 대해 뽑아 냈고, 이 뽑아낸 경향을 바탕으로 다시한번 본 Feature 들이 어떤 특성을 가지고 있는지 알 수 있었다. 여기서 필요한 것은 Partial Regression 을 해석 할 수 있는 개념과 이를 바탕으로 다시한번 DataFrame 을 정렬하고, 여기서 Data 들의 특성을 뽑아 낼수 있는 판단력이 필요했다. 당연히 이를 구현하기 위해 Pandas를 다루는데 능숙함 역시 필요했다. 커멘트 받은 것을 이렇게 다시 구현했다는 것에 큰 보람을 느끼며, 프로젝트 진행 당시 좀더 꼼꼼하게 이런것을 생각 할 수 있었으면 좋았을 것이라는 아쉬움도 함꼐 느낀다. 퍼포먼스에 치중하는 것이 아니라 데이터 자체에 어떤 특성이 있는지 파악하려고 노력하는것이 무엇보다도 중요함을 느낀다. 판단을 위해서는 Data 를 보기 편하게 정렬하고, 시각화 하는 것이 매우 중요하다. 앞으로 이를 위해 알고 있는, 알아야되는, 한번 봤는데 잘 기억 안나는 것이 어쩌면 다행이기에, method 들을 간단하게 나마 정리하려고 한다. 개인적인 기록으로 git, github 를 사용하는 것은 어렵지 않았다. 하지만 팀 협업을 하려고보니, git 을 다루는게 아직 능숙지 않았다는 것을 깨달았다. 오늘은 git과 github 에 대해 가볍게 공부했고, 이를 바탕으로 어떤식으로 협업해야하는 것인지 간단하게 나마 알게 된것 같다.","link":"/2018/11/25/181125-TodayWhatILearned/"},{"title":"181128-TodayWhatILearned","text":"181128 TWIL To-do-list : 오늘 할일 ~ Classification 성능평가 수학 9장 2절 Pandas ~ 100pages 오늘 한 일은 무엇인가 ~ Classification 성능평가 수학 9장 2절 내일 할 일은 무엇인가 Pandas 100page 무엇을 느꼈는가 프로젝트를 한번 해서 그런지, 지금 공부하는 내용도 앞으로 프로젝트에서 어떻게 활용해야할지 염두? 걱정?하며 공부를 하게 되는 것 같다. 메소드를 정리할 필요가 있고, 배우는 각 개념들이 어떤 판단을 바탕으로 사용해야하는지 생각하며 공부하게 되는 것 같다. 시간이 부족하여, 메소드들을 좀더 디테일하게 보지 못하는 아쉬움이 있지만, 이런 것들을 주말 등을 통하여보충할 필요가 있다.","link":"/2018/11/28/181128-TodayWhatILearned/"},{"title":"181126-TodayWhatILearned","text":"181126 TWIL To-do-list : 오늘 할일 이미지 데이터 처리, 사운드 데이터 처리 공부 Shell script 정리 Pandas - 50page 수학 8장-2절 오늘 한 일은 무엇인가 Shell script 공부 내일 할 일은 무엇인가 알고리즘 복습 Shell scipt cheatsheet 작성 Pandas - 100 page 수학 9장-2절 --- ## 무엇을 느꼈는가 - RedBlack tree 를 배우면서, 왜 color violation 을 해결하고, 색을 기준으로 정렬했을 때, O(logN) 으로 장점이 되는지에 관해 궁금하다. 자세한 수학적 증명보다, color 와 알고리즘의 효율이 어디서 연결 되는지 궁금하다. 이런 궁금증들은 이렇게 메모 해두었다가, 여유가 생길 때 꼭 찾아 보아야 겠다. - shell script 기본 문법을 공부하면서, Python 이 얼마나 직관적인 언어인지 느꼈다. 직접 해보면서, while, if 조건문 등을 쓸때, 띄어쓰기에 예민했고, DO ~ DONE 의 couple 이 중요했다. 또한, if , case 가 끝날 때는, 직관대로 done 이 아니라 fi, esac 등으로 닫아 줘야 하는 것이 위트 있지만서도, 쉽게 기억될 것은 아님을 알게 되었다. DO 도 OD 였다는데, 지금 OD 는 안되네.. DO 는 DONE 으로 쓰자 !!!!","link":"/2018/11/26/181126-TodayWhatILearned/"},{"title":"181127-TodayWhatILearned","text":"181127 TWIL To-do-list : 오늘 할일 알고리즘 복습 Shell script cheatsheet 작성 Pandas - 100page 수학 9장-2절 오늘 한 일은 무엇인가 알고리즘 복습 Shell script cheatsheet 작성 내일 할 일은 무엇인가 Pandas - 100page 수학 9장-2절 Classification Intro, Scikit-Learn 의 전처리 부분 code 정리 무엇을 느꼈는가 알고리즘 복습이 계획했던 것 보다 훨씬더 오래 걸려서, 기존에 계획했던 Pandas 와 수학은 보지 못했다. 오늘 공부한 분류도 다시 공부해야하는 만큼, 내일 공부할 양은 매우 많을 것 같다. 정리하는 내용들을 내가 보기 편하고, 쉽게 사용 할 수 있도록 하는 방법을 많이 고민해보아야겠다. 파일들이 누적되고 쌓이면서, 이제는 효율적으로 검색하거나 찾아서 볼 수 있는 것이 매우 중요한 것 같다. 어떻게 정리하거나 검색할 수 있는 Tool이 있을지 틈나는대로 생각해봐야겠다.","link":"/2018/11/27/181127-TodayWhatILearned/"},{"title":"181030-TodayWhatILearned","text":"181030 TWIL 오늘 한 일은 무엇인가 검정, 추정 부분 수식 꼼꼼히 다시 보기 A star(A*) Algorithm 개념 읽기 내일 할 일은 무엇인가 선형회귀분석 정리 (패키지 별로 특징, 메서드 파라미터 위주) 데이터 전처리 부분 공부 Test data 처리는 어떻게 하는 건지 공부해보기 무엇을 느꼈는가 추정부분 수식을 공부하면서 eigenvalue 부분이 기억이 잘 안나던 것을 시간이 될 때 자료들을 챙겨봐야겠다. 오늘 공부한 선형 회귀분석을 배우니 조금이나마 프로젝트를 어떻게 진행해야되는 건지 감이 잡힌 것 같다. 미약한시작을 하기위해 오늘 공부한 개념들을 사용해서 여러가지 돌려보고 데이터를 파악해볼 수 있을 것 같다.하지만, 우리가 가지고 있는 데이터셋이 바로 적용 할 수 없는 현실적인 데이터이기 때문에, 여러가지 전처리작업이 필요할 것 같다. 오늘 배운 것을 적용해보기 위해 내일은 데이터 전처리를 공부해보고, 또한 test data의생성 역시 공부해보아야할 부분인 것 같다.","link":"/2018/10/30/181030-TodayWhatILearned/"},{"title":"181129-TodayWhatILearned","text":"181129 TWIL To-do-list : 오늘 할일 Pandas ~ 150page wiki 구성 방안 REST API, NGINX, AWS 공부 오늘 한 일은 무엇인가 Pandas 80page wiki 구성 REST API, NGINX, AWS 공부 내일 할 일은 무엇인가 Pandas 150page 마무리 복습 --- ## 무엇을 느꼈는가 - 지금껏 구성해온 개인 wiki 혹은 cheatsheet등을 로컬 서버등을 이용해 wiki page 를 이용하고 싶었다. 가장 많이 사용한다는 gollum api 를 설치해보았지만, 생각보다 편하지 않았다. gitlab이나 github 등은 온라인에서 작성이 가능하지만, 로컬에서 그 해당 파일을 갖기가 불편했다. 또 검색기능도 중요했다. - 결국, 지금 작성하고 있는 git blog 에 wiki tab 관리로 하기로 했다. - 돌고돌아 gitblog 의 tab 을 활용해서 wiki 하기로 했다. 앞으로 좀더 깔끔하게 정리 파일을 관리하고, - 직접 참고할 자료이니, 무엇보다도 내가 보기 편해야 할 것이다.","link":"/2018/11/29/181129-TodayWhatILearned-1/"},{"title":"181203-TodayWhatILearned","text":"181203 TWIL To-do-list : 오늘 할일 Pandas Cookbook 2장 복습, 3장 ROC 커브, Logistic Regression 시간 날 때, 새로운 데이터셋 EDA 오늘 한 일은 무엇인가 ROC, AUC, Logistic Regression 정리 Flask_app : classification model application 코드 해석 Pandas 2장 복습 내일 할 일은 무엇인가 Heap, Graph 부분 복습 Pandas 3장, 4장 새로운 데이터셋 EDA, Regression 함수 적용 --- ## 무엇을 느꼈는가 - Pandas를 조금씩 정리하고, 새로운 것들을 알게 되면서 이전에는 몰랐던 편리한 기능들이 많이 있음을 알게 되었다. 손에 익히게 되면서 아주 조금씩 판다스에대해서 편해지기 시작하였다. Pandas 를 심도 있고 공부해보고자 했던 처음 이유인 '데이터셋을 보고 먼저 손이 나가도록 하자'는 목표에는 아직도 멀었지만, 하루하루 조금씩 노력해온 1주 반동안, 이전보다 조금더 편해졌다는 것이 느껴진다. - 이렇게 체감적으로, 한파트 한파트씩 아주 더디지만 조금씩 편해지고, 손에 익는 다는 것을 느끼면서, 점점더 재미있어 질것이라 믿는다. ---","link":"/2018/12/03/181203-TodayWhatILearned/"},{"title":"181114-TodayWhatILearned","text":"181114 TWIL 오늘 한 일은 무엇인가 flight prediction 내일 할 일은 무엇인가 프로젝트 모임 무엇을 느꼈는가 계속 비행기 delay시간을 예측하는 프로젝트를 진행하고 있다. 여러가지 feature 들을 다루면서 arrival delay 를 예측하는 것을 목표로 삼고 있는데, 가지고 있는 데이터에서 공통적인 특징을 발견할 수가 없다. 외부 데이터를 사용해야할지, 갸지고 있는 데이터 셋에서 새로운 컬럼을 만들어야 할지 모르겠다. 많은 컬럼을 만들고 지우면서, 단순히 아이디어, 혹은 이러지 않을까라는 추측으로 컬럼을 만드는 것이 방법론 적으로 잘못된 것인가하는 의문이 들기도 한다. correlation 이 높은 것을 가지고 OLS 를 돌리는 것 외에 새로운 컬럼을 가지고 만드는 것. 어떻게 다루어야 할지 고민이다. 이제 due date 가 얼마 남지 않은 만큼 최대한 남은 기간 열심히 돌려보고 만들어보면서 계속 trial and error 로 찾아보아야 겠다.","link":"/2018/11/14/181114-TodayWhatILearned/"},{"title":"181204-TodayWhatILearned","text":"181204 TWIL 오늘 한 일은 무엇인가 Heap 구조 공부, 코드 짜보기 Logistic Regression method 정리 내일 할 일은 무엇인가 QDA, LDA, 나이브 베이지안 모델 복습, 정리 특히, 수식들 정리 + Method보다는 predict 결과가 나오는 데까지 확률계산, 흐름 중점적으로 공부 (Study) A* 알고리즘 구현 Pandas 3장 무엇을 느꼈는가 Heap 구조를 공부하면서, class 단위로 짜져 있는 코드들을 혼자서 구현하려면 어디서부터 계획을 세워야되는가에 대해 고민했다. 또한, 어떤 이슈가 있을 때, 어떤 알고리즘과 자료구조를 선택해야하는지에 대한 판단근거 역시 앞으로 정리 해야할 필요성을 느낀다. 우선 간단하게 알고 있는 데이터 구조 전체에 대해 서로 비교하여 장, 단점 정도 빠른시일 내에 정리해야겠다.","link":"/2018/12/04/181204-TodayWhatILearned/"},{"title":"181123-TodayWhatILearned","text":"181123 TWIL Today’s To-Do-List (스터디) 스터디 원들과 A* Alogorithm 개념 정립 (스터디) 스터디 원들과 함께할 깃 레포 설정, Code Convention 정하기 (개인공부) AWS EC2, crontab, shell-script 공부 (개인공부) 기본 통계량 복습 (개인공부) KoNLPY, NLTK 훑어보기 오늘 한 일은 무엇인가 (스터디) A* Alogorithm 공부 (스터디) A* 구현, Class 단위로 윤곽 잡기 (개인공부) 확률분포, 기본 통계량 꼼꼼히 보기 (개인공부) shell-script 내일 할 일은 무엇인가 확률분포, 기본 통계량 스터디 main프로젝트 Review (Procedure 정리, 시계열 적용 고민) AWS 복습 (스터디) git repo 설정, A* Algorithm 코드 작성 무엇을 느꼈는가 열심히 개념을 정립하는 것도 중요하지만, 계속 해서 정리하고 스스로에게 Feedback 을 주는 것이 중요하다. 어떤 Procedure 중에 있는 것인가를 아는 것이 가장 중요하다. 앞으로의 적용을 항상 고민해야한다. 회기분석 프로젝트를 마친 것을 다시한번 복기할 필요가 있기에, 이번 주말을 통해 개인적으로 복기를 해보려고 한다. 이에 앞서 이번주부터 시작한 기본 통계량 부터의 복습을 같이 하면서 프로젝트 과정중 잊었던 개념들을 적용하는 연습을 주말동안 다시한번 차근차근 해보아야 한다.","link":"/2018/11/23/181123-TodayWhatILearned/"},{"title":"181205-TodayWhatILearned","text":"181205 TWIL To-do-list : 오늘 할일 QDA, LDA, 나이브 베이지안 모델 복습, 정리 수식, Predict 과정 중심적으로 공부 (Study) A* 알고리즘 구현 Pandas 3장 오늘 한 일은 무엇인가 (Study) A* 알고리즘 손코딩 QDA, LDA, 나이브 베이지안 모델 복습, 정리 내일 할 일은 무엇인가 (Study) A* 알고리즘 구현 Pandas 3장 --- ## 무엇을 느꼈는가 - 스터디에서 다같이 알고리즘을 파악하고, 이를 바탕으로 손코딩을 진행했다. Class 단위로 짜는 거였고, 우리끼리 자료들을 바탕으로 알고리즘을 공부하고, 이를 구현하는 것까지 개인적으로 매우 Challenging 했다. 오늘 손코딩을 마무리 하면서, 머릿속에 있는 알고리즘을 어떻게 풀어내는지, 설계부터 각각의 함수까지 계획을 세우는데 매우 큰 보람과 배움이 있었다. - 내일부터는 스터디원들과 함께 오늘 작성한 것을 바탕으로 실제 코딩을 들어갈 계획이다. 아직 미숙한 점이 많기에, 손코딩을 진행한 것들에 대해 Debugging 이 많이 필요하겠지만, 너무 재미있는 시간이었다. - 오후 남은 시간에는 QDA 부터 나이브 베이지안 모델까지(gaussain, bernoulli, multinomial) 수식과 그 메소드들을 하나하나 뜯어보고 분석하는 시간을 가졌다. 단순히 패키지의 메소드를 돌리면 되겠지가 아니라, 메소드를 돌리기전에 간단한 data에 대해 결과를 얻기까지 직접 손으로 풀어보고 계산하여, 메소드를 돌렸을 때 결과와 비슷한지 확인 하는 시간을 통해, 각 분포가 모델링 되는데까지 과정을 이해하는데 도움이 많이 되었다. - 또한 자료에 나오는 다양한 시각화 메소드, 시각화 하는데 필요한 domain 설정, Numpy와 Seaborn 의 메소드들을 파악해보면서, 시각자료의 의도를 생각해보기도 하였다. - 많지 않은 범위를 이렇게 공부하다보니, 꽤많은 시간이 필요하여 오늘의 다른 목표들을 채우지는 못했지만, 스터디와 개인 공부 두가지를 통해, 하루를 매우 생산적으로 보낸 것 같아 뿌듯하다.","link":"/2018/12/05/181205-TodayWhatILearned/"},{"title":"181207_TodayWhatILearned","text":"181207 TWIL 오늘 한 일은 무엇인가 Pandas 3장, 4장(일부) (Project) 데이터셋 정하기 내일 할 일은 무엇인가 MySQL 복습, QUIZ 풀기 새로운 데이터셋 EDA, Regression Pandas 4장, 7장 지난 프로젝트(Flight_Delay Regression) Update 알고리즘 추가과제 하나씩 풀기 --- ## 무엇을 느꼈는가 - 와.. 오늘은 그간의 파이썬과 알고리즘, 데이터 구조의 공부한 것을 평가받는 첫 시간이었다. 시간내에 주어진 문제를 효율적으로 푸는 것이 생각보다 어려웠다. pandas의 method 나 numpy method 를 자주 사용하면서, 기본적인 내장 method 는 오히려 더 어색했다. 함수를 짜서, 테스트 케이스를 통과하다가 중간에 발생한 에러는 debugging을 하지 못했다. 또한, 코드 역시 비효율적이고 못생겼다. pyint 의 PEP 8 점수 역시 매우 낮았다. - 다시한번 많이 부족함을 느꼈고, 더 공부해야되고 알아야 하는 것이 한참이나 많다. - 쌓이고 쌓이는 ToDoList 에서 우선순위를 매번 잘 매기고, 너무 한 issue 에만 묻혀있지 말아야하며, 동시에 다양한 주제를 공부해야하므로 정리를 잘해야하고, 그 정리를 다음번에 참조할 수 있게 잘 기록해야하며, scheduling 을 효율적으로 해야하고, 무엇보다 그 순간에 매우 집중해야한다. ---","link":"/2018/12/07/181207-TodayWhatILearned/"},{"title":"181209-TodayWhatILearned","text":"181209 TWIL 오늘 한 일은 무엇인가 Classification 복습 (Entropy, DecisionTree) MySQL Query Code Imporvement, CodeReview Insurance Data regression Algorithm 추가 과제 (2진수, 8진수, 16진수) 내일 할 일은 무엇인가 MySQl, NOSQL 복습, 정리 Insurance Regression 과정 정리, 알게된 것들 정리 Pandas 4장, 7장, 9장 정리 Algorithm 추가 과제 마무리 수학 12-5장까지 복습 --- ## 무엇을 느꼈는가 - Insuracne Data regression 을 진행하면서, 지난 프로젝트에서는 다가가지 못한 Step 들을 수행하였다. 잔차의 정규성을 검토하면서, 이를 발전 시킬 수 있는 방법에 대해 코드를 작성하였고, EDA 과정을 꼼꼼히 한 덕분인지, regression formula 를 돌리는데 있어 각 스텝마다, 작은 근거들이 생겨났다. - 아직은 수업 자료에서 모든 내용을 담을 만큼 Performance 와 스텝간의 근거들이 명확하지 않기 때문에 공부할 것이 한참남았지만, 오늘 새로운 데이터셋을 좀더 꼼꼼히 EDA 를 하면서, 새롭게 알게되고, 적용할 수 있는 것들이 생겨 뿌듯했다. ---","link":"/2018/12/09/181209-TodayWhatILearned/"},{"title":"181208-TodayWhatILearned","text":"181208 TWIL 오늘 한 일은 무엇인가 Decision Tree 연습문제 18.4.2 풀기 Imporve Flights_Delay Regression Project Insurance Cost dataset EDA MySQL Quiz 마무리 내일 할 일은 무엇인가 Classification 복습 MySQL 복습 MySQL Query Code Imporvement Insurance Data EDA Pandas 정리 Regression 수학 12-5장 복습 --- ## 무엇을 느꼈는가 - Query 문을 작성하면서, 다양한 방법으로 같은 결과를 얻을 수 있음을 알게 되었다. 같은 결과를 뽑아내는 Query 문의 비교에서, 오늘은 간결하고, 깔끔한 코드를 작성하려고 노력을 하였다. 하지만, 결국 가장 중요한 것은 Query 문이 얼마나 빠르게 동작 하느냐의 문제인 것 같다. 내일은 간결하면서도, 빠르게 동작하는 코드를 작성하는데 좀더 고민해봐야겠다. - 지난 Flights_delay regression project 를 개선하는데 있어, 코드적으로, 기술적으로 부분회기 plot 를 바탕으로 다시 모델링을 하는 방법에 대해 알게 되었다. 여기까지 알게 된 것을 바탕으로, 새로운 Medical cost(Insurance) data 를 regression 으로 모델링 해보려고 한다. 오늘 간단한 EDA 를 진행하였으나, 조금더 데이터를 자세하게 보는 방법론에 대해 공부를 하면서 진행해 보려고 한다. ---","link":"/2018/12/08/181208-TodayWhatILearned/"},{"title":"181211-TodayWhatILearned","text":"181210 TWIL To-Do-list Insurance EDA 정리 Pandas 12-5장까지 수학복습 MST 복습 오늘 한 일은 무엇인가 Insurance EDA 정리 (STUDY) A* 알고리즘 시각화 선형회귀 개념 복습 내일 할 일은 무엇인가 데이터톤 무엇을 느꼈는가 파이썬으로 작성한 A*알고리즘의 시각화코드를 작성하였다. 제일 빠른 길을 찾아 주었으나, 이것을 시각화하는것이 생각보다 어렵다. 그리고 좀더 동적으로 시각화를 해주고 싶은데, 좀더 삽질을 많이해봐야겠다.결과데이터를 보여주면 되겠지 했지만, 답을 얻는 과정을 세세하게 시각화하여 보여주는 것 역시 어려운 문제였다.비단 알고리즘을 보여주는 것만이 아니라, 지금 공부하는 모든 것이 아마 그럴 것이다. A* 알고리즘을 적용해서 주어진 미로의 최적의 길을 찾는 것은 미로의 크기가 커질수록 검증이 어렵다. 우리가작성한 알고리즘으로 풀어준 path가 진짜 제일 빠른 길인지 확인하는 방법이 무엇인가 하는 생각이 든다. 크기가작은 미로에서 우리가 한길 한길 찾아가는 정답과 맞아서, 알고리즘이 제대로 작동하고 있다고 생각했다. 하지만,점차 크기가 커지면서 정답이 맞는가 확인하는 것은 어려웠다. 작은단위에서 맞는 것이라고 해서, 큰 단위에서 내놓은 답이 과연 정답일 것인지는 어떻게 검증해야하는가. 우리가 소단위에서 다 맞춘 알고리즘이라고 해서 전부 믿어야 하는 것인가라는 생각이든다. 내일은 데이터톤이다. 여태까지 공부한 것을 적용해보고, 실제로 제한시간내에 데이터를 분석해야한다. 아직도 많이 모르고,아는 것도 확신하기 어려운데, 잘 할 수 있을지 걱정된다.","link":"/2018/12/11/181211-TodayWhatILearned/"},{"title":"181215-TodayWhatILearned","text":"181210 TWIL To-Do-list DataThon 발표 준비 Pandas 4장 공부 알고리즘 문제풀기 (Study) 프로젝트 미니(웹어플리케이션) 준비 (Project) Classification Project Data EDA 오늘 한 일은 무엇인가 Datathon 발표준비 알고리즘 문제 풀기 (Study) 프로젝트 미니(웹어플리케이션) 준비 내일 할 일은 무엇인가 Pandas 4장 공부 Support Vector Machine 공부 알고리즘 문제풀기 NoSQL, MySQL syntax 정리 무엇을 느꼈는가 데이터톤 발표를 준비하면서, 제출했던 코드와 과정을 다시 살펴보니 Markdown 이나주석이 부족함을 느꼈다. 다시 볼 때 좀더 편할 수 있도록, 코드와 과정을 다시 이어 나가는데 시간을 덜 소비하도록 나름 신경써서 작성하며 진행했는데, 다시 보려고 하니 머릿속에 있었던 것들이 다 작성되어 있지 않았다. 지금은 데이터톤에서 얼마 지나지 않았기 때문에, 기억에 남는 것이겠다. 하지만 추후에 다시 볼때는 기억이 나지 않아, 내가 작성한 코드와 문서임에도 불구하고 그 맥락을 이해하기 위해 처음부터 읽어 볼 것이다. 앞으로는 좀더 주석과 마크다운 문서에 신경을 많이 써야겠다. 짤막하게라도, 데이터 분석과정 중에 들었던 생각들을 작성해 놓아야, 그 시간이 지난뒤에 Develop 을 하던, 복기를 하던 계속 생각의 흐름을 이어 나갈 수 있을 것이다. 일일코딩, DailyCommit 등에 관한 글을 읽었다. 개인의 다짐과도 비슷하고, 개인 프로젝트로 개발자들이 많이 하는 것 같다. 글을 읽은 직후에는 나도 하고 싶다는 생각을 했지만, 과연 할 수 있을 것인가 하며 반문을 하였다. 다짐의 문제라고 하기엔, 너무 정신 없는 나날을 보내고 있기에.. 도전할 것인지 하루만 더 고민해봐야겠다.","link":"/2018/12/15/181215-TodayWhatILearned/"},{"title":"181216-TodayWhatILearned","text":"181216 TWIL 오늘 한 일은 무엇인가 DataThon 발표 Perceptron 공부 (Project) Quara Dataset EDA question_text 에서 vectorize 하기전에 특징값들을 뽑아내기 나이브 베이지안 돌려보기 (Study) 스터디때 나눌 WebApplication 의 구조, MVC model 나누기 내일 할 일은 무엇인가 (Study) 스터디원 블로그 개설, Flask에 비유한 WebApplication, MVC model 공부하기 (Stydy) PROJECTmini WebApplication 계획 세우기 (Project) EDA 짬짬히 계속하기 SVM 공부 무엇을 느꼈는가 Datathon에서 분석했던 내용을 발표하는 시간을 가졌다. 발표를 하면서 부족하다고 생각했던 점과 comment 를잊기 전에 정리해본다. 후기 및 생각과 느낌 프레젠테이션 능력이 부족하다.- 긴장, 생각의 흐름을 말로 표현하는 것이 부족했다. 나름대로 이야기 할 것을 리스트업해갔지만, 잘 눈에 들어오지 않았다.- 스크립트를 다 작성해가는 것이 좋은 것일까? 프레젠테이션 혹은 데이터를 모르는 사람도 읽을 수 있는 마크다운 정리가 부족했다.- 데이터톤 당시 시간에 쫓기는 것도 있었고, 데이터를 분석하고 코드를 작성하면서 나중에 하면 되겠지 라고 생각했다.- 결과는 제대로 마무리와 정리를 하지 못한 채로 제출했고, 이는 발표할 때 쓰는 자료로서는 0점에 가까웠다.- 프로젝트나, 코드를 작성할 때 comment 를 좀더 세세하게 작성하도록 노력해야겠다. 지적해주신 comment Regression 에서 intercept 의 의미- 실제로 모델링한 결과를 현실 데이터에서 사용하기 위해서는 intercept 를 꼭 추가해야한다고 말씀해주셨다.- comment 를 듣자 마자, 조금 찾아봤을 때, intercept 가 error 의 mean 값을 잡아준다고 한다.- 이 부분은 좀더 보충이 필요하다.- 더미변수를 사용하지만, Intercept 의 효과에 대해서.. 단지 해석의 의미로만 상수항을 생각하였는데, 좀더 본질적인 이유가 있는 것 같다.- 꼭 보충할 것! 데이터를 분석하는 과정에서 insight를 얻었을 때, 이를 꼭 알기 쉽게 기록하라.- 개인적으로 느꼈던 후기와 생각에서와 비슷한 취지의 말씀이었다. 자신과 다른사람이 알 수 있게 insight 를 꼭 기록하라고 말씀하셨다. R square 를 기준으로 분석을 진행할 때는 조심하여야 한다.","link":"/2018/12/16/181216-TodayWhatILearned/"},{"title":"181220-TodayWhatILearned","text":"181220 TWIL 오늘 한 일은 무엇인가 (Project) Classification Project 모임 딥러닝 엔지니어 현업자 특강 Celery 복습 간단한 알고리즘 문제 풀기 Linear Algebra(Gilbert) 1강 내일 할 일은 무엇인가 Linear Algebra(Gilbert) 2강 (Project) Classification Project Classification 개념 다시 보기 무엇을 느꼈는가 즐기자","link":"/2018/12/20/181220-TodayWhatILearned/"},{"title":"181225-TodayWhatILearned","text":"181225 TWIL 오늘 한 일은 무엇인가 (Project) Text Preprocessing 내일 할 일은 무엇인가 (Project) Project 모임 Linear Algebra 강의 2강, 3강 듣기 무엇을 느꼈는가 모든 전처리가 그렇겠지만, 텍스트 데이터의 전처리는 유독 할게 많다. 실제 사람이 사용하는 언어 데이터이다 보니,예외사항들이 많고 모델 성능에 이 전처리들이 큰 영향을 미친다고 하기에, 열심히 전처리를 하고 있다. 오늘은 embedding 데이터를 활용해 줄임말들 (I’d, We’re 등) 늘려주는 작업을(I would, We are 등) 해줬다.기존에 짰던 영어이냐 아니냐를 분류하려고 만든 알고리즘의 성능이 위 작업을 통해 좀 더 좋아질 것이라 예상된다. 또한오늘 한 작업이 main modeling 을 하기 위해 진행할 Tokenizing 에도 좋은 영향을 줄 것이다. Stopwords 들을빼거나 더할 때도, What’s 보다는 What is 로 늘려주었을 때, 훨씬더 세밀해 질 것이다. 내일은 spelling 체크, 띄어쓰기 체크해서 올바르게 고쳐주는 작업을 해야한다. 그리고, Baseline 모델을잡기 위해 본격적인 modeling 에 들어가야한다.","link":"/2018/12/26/181225-TodayWhatILearned/"},{"title":"[REBOOT]2019_NEWYEAR : 190108-TodayWhatILearned","text":"** REBOOT ** Text Classification Project 를 한다는 핑계로 그간 TodayWhatILearned의 작성을 하지 못했다.프로젝트를 하는 동안은 매일 어떤 것을 공부할 계획이고, 어떤 공부를 했는지 남길 만한 내용이 없었던 것도 사실이다.프로젝트 동안 미뤄뒀던 공부들, 보고싶었던 주제들을 이제 다시 새로운 마음가짐을 가지고 시작할 것이다.새해가 밝은 만큼 블로그를 만들기 시작하면서 다짐했던 초심을 상기하자. To-Do-List Graph모형, 네트워크 추론 공부 (수식) - 새로운 패키지, 코드 정리하면서 공부 LinearAlgebra 1강, 2강 다시 시작 오늘 한 일은 무엇인가 Graph모형 공부 LinearAlgebra 1강, 2강 내일 할 일은 무엇인가 네트워크 추론 공부(수식 위주로 공부)","link":"/2019/01/08/190108-TodayWhatILearned/"},{"title":"190109-TodayWhatILearned","text":"190109 TWIL 오늘 한 일은 무엇인가 BLOG RENEWAL 내일 할 일은 무엇인가 Graph모형 공부 LinearAlgebra 1강, 2강 무엇을 느꼈는가 새해를 맞아 블로그를 새 테마로 바꾸었다. 기존에 hueman theme 에 익숙해져 있어서, 새로운 테마의 기능을수정하고, 전처럼 편해지려면 또 적응의 시간이 필요할 것 같다. 블로그의 테마는 작년부터 글의 양이 늘어나면 늘어날수록그 욕구가 더 심해 졌다. 특정 카테고리에서 글이 누적되가면서, 어떤 글들이 담겨있는지 제목을 통해 직관적으로보고싶었다. hueman 은 글마다 썸네일들이 있고, 글의 순서가 조금 불편하게 배치되어 있다. 시리즈성 글들을 올린다거나,주제가 1, 2, 3 등으로 나뉘는 글들이 있을 때, 글 제목으로 연속성을 보기가 힘들었다. 위의 이유로 선택한 이번 테마는 내가 중점적으로 생각한 부분을 조금이나마 개선할 수 있는 것 같다. 틈틈히새로운 테마의 세팅도 마쳐야겠다.","link":"/2019/01/09/190109-TodayWhatILearned/"},{"title":"[github] github token 설정 및 키체인 등록","text":"최근에 맥북을 사고, 새로산 맥북에 개발환경을 하나씩 셋팅하고 있다. 그러면서 오랜만에 등록하는 github token과 매번 귀찮게 비밀번호를 기입하는 것을 막기 위한 키체인 등록까지 완료하여, 이 부분을 정리해 기록한다. 이번 글에서 소개하는 github 환경 셋팅은 크게 두 단계로 나뉜다. github token 발급 macbook에 token 저장 및 git config 수정 1. github token 발급1-1. github 접속 및 설정 페이지 접속자신의 github 계정에 접속하여 오른쪽 상단에 setting 을 클릭한다. 1-2. Developer Settings 에 접속왼쪽에 developer settings 클릭 1-3. Token 메뉴 접속빨간색 박스 친 부분을 클릭하여, 토큰 생성 페이지에 접속한다. 1-4. 생성하는 Token의 권한 생성(1) 본인이 관리 할 수 있도록 이름을 지어준다. (2) 본 토큰의 만료 일자 지정 (3) 토큰의 권한 범위 설정 1-5. 생성되는 토큰 저장하단의 Generate token 버튼을 누르면 토큰이 발급된다. 본 토큰은 해당 페이지를 닫으면 더이상 확인 할 수 없으므로 잘 복사해두고 관리 해두어야 한다. 나는 개인 맥북에서 환경설정을 하는 중이므로, 다음 단계를 통해 해당 토큰을 내 개인 맥북의 keychain 에 저장하여 자동으로 기입 될 수 있도록 했다. 2. Keychain 등록 및 비밀번호 자동기입2-1. keychain access application 실행맥북 spotlight에서 keychain [Access.app](http://Access.app) (키체인 접근) 을 검색하여 들어간다. 검색에서 github.com 을 검색한다. 검색 결과, 방금 생성한 token 이 등록 되어 있으면 상관없지만 만약 등록 되어 있지 않다면, 이름 : github.com 계정 : 본인 깃헙 아이디 암호 : 방금 생성한 토큰 위 내용으로 등록한다. 2-2. github config 에 키체인 등록기본 terminal 혹은 iterm에서 github config 를 등록해준다. 1$ git config --global credential.helper oskeychain 위 과정을 통해, 깃헙 비밀번호(토큰) 기입 없이 자유롭게 푸쉬할 수 있게 된다.","link":"/2022/12/05/20221205-github-setting/"},{"title":"[글또] 삶의 지도","text":"00. 들어가는 글글또 8기에 지원하며, 삶의 지도를 그려보는 시간을 가졌다. 공지를 보고 일주일이 지나도록 어떻게 글을 써내려가야 할지 손이 움직이지 않았다. 나 자체를 돌아보며, 글 자체보다 나를 돌아보는 이 시간들이 매우 값졌다. 나를 이루는 다양한 면들이 단순히 한가지 사건에서 비롯되지 않았다는 것을 깨달음과 동시에 복잡하게 얽힌 시간과 경험을 글로 써내려가며 조금씩 정리 되는 것도 경험했다. 아래의 짧은 글을 통해서 조금이나마 나에게 관심 있는 사람들에게 내 삶의 지도가 잘 전달되었으면 한다. 01. 모험과 도전을 즐기는 현재의 나#2023 #데이터사이언티스트 #ML엔지니어 #개척자 #도전 나는 현재 나스미디어 데이터사이언티스트로 일을 하고 있다. 미디어렙사이자 광고 플랫폼을 운영하고 있는 나스미디어는 온라인 / 오프라인 광고 시장에서 1위를 선점하고 있는 회사이다. 이곳의 데이터사이언티스트로 일을 하면서 다양한 프로젝트를 리딩하고, 현재는 광고 추천 시스템을 연구하고 있다. 나는 나스미디어 최초의 데이터사이언티스트로 입사했다. 2021년에 들어왔을 때 우리 데이터사이언스팀은 팀원이 혼자인 1인팀이었고, 현재는 7명의 팀원들이 있다. 처음 회사에 들어왔을 때는 연구개발을 위한 인프라도 부재했고, 하루 수억건의 트래픽 데이터는 머신러닝/데이터분석을 위한 형태로 적재되지 않았다. 처음 입사하자마자 광고 도메인에 대한 비지니스 공부를 함과 동시에 이런 인프라를 구축하는데 힘을 썼다. 2021년의 나스미디어에 합류한 나의 결정을 돌아보니, 나는 모험과 도전을 좋아하는 사람이다. 또한 나를 가장 들뜨게 하는 것은 이런 모험과 도전을 하는 과정에서 겪는 시행착오와 그 시행착오 끝에 얻어지는 지혜와 지식을 정리하고 알아가는 과정에 희열을 느끼는 사람이다. 지금도 내가 모르는 것에 대한 탐구와 아는 것을 정리하여 공유할 때 얻어지는 보람을 향해 달려가고 있다. 02. 암흑기.. 현재의 초석이된 과거의 나#201x #고시생 #회색빛 #밑거름 지금의 나를 이루고 있는 성격/지식/삶에 대한 태도가 언제 구성되었는가 돌이켜보니, 21살의 내가 떠올랐다. 나는 대학에 입학하고, 21살부터 고시생이 되었다. 그리고 5년을 신림동 고시촌에서 공부했고, 첫 실패와 포기라는 단어를 마주했다. 주변 지인들과 그 시절을 회상하며 나는 “회색빛의 나와 회색하늘의 신림”이라는 표현을 자주했다. 하지만 그 때의 경험은 지금의 나를 지탱하는 큰 밑거름이다. 도전. 실패. ..그리고 다시 도전. 시험에 도전하고, 그리고 도전과 도전 사이에는 반드시 실패가 존재한다. 당시에는 도전 자체에 큰 의미를 두었지만, 지금의 나는 그 실패를 딛고 일어서는 자세에 대해 중요하게 생각한다. 어떤 일과 계획이 뜻대로 되지 않을 때 우리는 이를 실패라고 정의 할 수 있다. 하지만 실패는 다음 실행과 계획에 중요한 경험을 쌓게 한다. 이 가치관은 과거의 내가 여러차례의 낙방을 경험하며 체화된 가치관이다. 쌓인 지식. 컴퓨터, 데이터, 프로그래밍. 고시생활을 5년 하면서, 5년 동안 24시간 공부만 했겠는가. 시험기간에는 평소에 보지도 않던 뉴스가 그렇게 재밌을수가 없다는 것은 모두가 공감할 것이다. 나 역시 하루 12시간 공부를 하고 녹초가 되어 집에 돌아와서 법전을 다시 펴지 못했다. 고시생활의 유일한 낙은 밤에 와서 보는 열혈강의 C언어 책과 C by Dissection 전공책이었다. 전공시간 때는 하나도 재미없었던 책을 아무 생각 없이(?) 코드를 타이핑하면서 보내는 시간을 좋아했었다. 다음날 아침 6시에 독서실을 나가야하는데, 새벽 3시까지 테트리스 게임을 짤 때도 있었다. 그 때의 딴짓은 지금의 밑거름이 되었다. 지금도 간직하고 있는 그 시절 열혈강의 C.요즘은 표지가 바뀌었다는데.. 지금도 간직하고 있는 그 시절 C by Dissection 전공책. 03. 데이터사이언스로의 도전하는 나#딥러닝 #알파고 #다시도전 2016년에 늦은 나이로 군입대를 한 나는 알파고와 이세돌 대국을 경험하며, 딥러닝이 뉴스를 도배하는 시기를 마주한다. 딥러닝이라는 단어는 이미지 프로세싱 전공 수업 마지막 챕터에서 접했지만, “대학원에 와서 공부하라”는 교수님의 말씀만 기억이 날뿐었다. 전공수업에서 나왔던 단어가 뉴스를 도배하니, 자연스레 관심이 갔다. 이미지프로세싱 교과서를 다시 펼쳐보며, 모델 위주로 공부하던 나는 점차 데이터 생애 주기의 앞으로 관심이 갔다. 어떤 데이터가 어떻게 생성되며, 적재되는 방법과 관리하는 체계에 관심이 갔고, 분석하고 그 끝에 모델링을 하고 서빙하는 그 과정 전체를 공부하기 시작했다. 지금도 이 관심사는 여전하다. 다양한 기술과 새로운 방법론을 접할 때마다 관심을 갖고 follow-up 하려는 나의 노력은 과거의 나의 존재들이 만들어준 좋은 습관인 것 같다.","link":"/2023/01/14/20230114-geultto-map-of-life/"},{"title":"[MAC] xcrun: error: invalid active developer 에러 해결방법","text":"방금 전, MacOS Ventura 13.0.1로 업그레이드 하고, flutter, python 개발 중 다음 과 같은 에러 코드를 내뱉으며 잘 되던 것들이 안되기 시작했다.간단한 git부터 시작해서, 맥 내 환경변수를 포함하는 대부분의 명령어에서 다음과 같은 에러 메시지를 보냈다. 다음 글에서 그 해결방법을 정리했다. Error Message1xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun [Error Message] xcrun: error: invalid active developer 이런 현상은 맥 OS를 업데이트하면 종종 나타나왔었는데, M1으로 넘어오고나서는 처음 보는 현상이기에 해결법도 여전한지 확인해보며, 이 글을 적고 있다. 해결방법맥의 개발자 도구인 CommandLineTools를 재설치하여 해당 에러를 고칠 수 있다. 1$ xcode-select --install","link":"/2022/12/12/20221212-mac-xcrunn-error-invalid-active-ddeveloper-error/"},{"title":"[글또] 글또 8기를 시작하는 글","text":"01. Greetings글또 8기를 시작하며, 앞으로 활동하는 동안 목표하고자 하는 바를 정리해본다. 작년 한해 동안 너무나도 정신없는 한해를 보냈다. 회사 내에서 머신러닝 프로젝트 2건에 대한 기획에서부터 ETL, Data Pipeline, 모델 연구 개발, 모델 서빙까지 작업했다. 한 해를 돌아보면서 아쉬웠던 부분은 새롭게 알게된 다양한 기술(특히, Data Engineering 분야와 MLOps 분야)과 새로 접하는 논문 (Tabular Network, RecSys), 그리고 작업한 코드들을 단백하게 정리하지 못했던 것이다. 이번 활동을 통해서, 알고 싶은 것과 알게 된 것을 체계적이고 알기 쉽게 정리하는 것이 나의 목표이다. 02. Objective이번 글또 8기를 활동하면서 목표하는 바는 다음과 같다. 글 쓰는 습관 기르기 평소 논문 요약과 기술 정리는 개인적으로 정리하고 있으나, 남에게 공개할 만큼 “글”로 묘사 하지 않는다. 이런 점은 작성할 때는 편하지만, 다시 볼 때 기억을 되살리는 면에서 매우 큰 약점을 가지고 있다. 심지어는 논문을 다시 읽을 떄도 있고, 코드 전문을 다시 볼 때도 많다. 주제를 선정해, 공개하는 글에 대해서는 최대한 자세하고 친절한 설명과 정리를 하겠다. 추천시스템, 특히 CTR based / Audience Extension 추천 정리 요즘 관심 있는 주제는 CTR based 추천과 Audience Extension 에 대한 추천에 관심이 많다. 잡고 있는 논문 중심으로 정리하며, 테스트를 진행할 수 있는 코드를 짜는 것이 목표이다. NiFi, Airflow 정리 작년부터 nifi 를 활용해 데이터 파이프라인 구축을 완료했다. Nifi 를 활용해 튜닝 할 수 있는 부분을 알게 될 때 마다 잘 정리하고 싶다. 또한 다른 회사에서는 airflow 를 많이 활용 하고 있다보니, nifi와의 공통점/차이점들을 살펴볼 필요가 있겠다는 생각을 했다. 틈틈히 airflow부분도 살펴봐야겠다. 다른 분들의 글 읽기 / 커피챗 참여 글또에 정말 다양한 분야에 계신 분들이 많다. 머신러닝/ai 와 관련된 분야 뿐만 아니라 데이터 엔지니어, 데이터 분석 분야에 글을 틈틈히 읽고 싶다. 또 광고 분야에 계신분들도 있는 것 같아, ad-tech 관련된 글과 커뮤니케이션도 많이 할 수 있을 것 같아 기대 중이다. 블로그 플랫폼 이사 현재 github 블로그를 이용중이다. 근데 이사하고 싶다. 현재 후보는 tistory, oopy, medium. 새로운 플랫폼을 활용하려면 또 시간을 내어서 플랫폼 탐색을 해야하기 때문에.. 매번 글을 업로드 할 때마다 github 외에 한군데씩 올려보고, 조금씩 만져보며 이사를 천천히 준비하려고 한다. 03. Conclusion가볍게 쓰기 시작한 목표 정리 글이 쓰다보니 장대해진 것 같다. 6개월이 지난 시점에 활동을 마무리 하면서 후회 없는 시간이 되었으면 좋겠다.","link":"/2023/02/04/20230204-geultto-objective/"},{"title":"[논문리뷰] Real-time Attention Based Look-alike Model for Recommender System (Part 1)","text":"본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 핵심을 살펴보고, 위 논문의 각 파트를 구현하면서 마주한 문제와 고민을 공유해보고자 한다. Part 1, 2로 나누어 User representation learning 파트와 Online Processing 파트를 나누어 살펴보자. 광고를 송출 하는데 있어, 요즘 내가 풀고 있는 문제는 “오디언스의 확보”이다. 광고주마다 특정 KPI 를 달성하는데 필요한 오디언스는 정해져있다고 전제할 때, 광고 시스템은 전체 오디언스 풀에서 특정 KPI를 달성하는데 유리한 오디언스를 찾아내 타겟팅, 리타겟팅을 잘 해내야 한다. “오디언스 확보”를 위해서 다양한 아이디어에 근간해 개발을 하고 있고, 우리 광고 시스템에 실험을 하고 있다. 그 중 RecSys분야에서 재미있게 읽은 Attention based Look-alike Model 논문을 리뷰해 본다. Look-alike Model 은 특정 캠페인에서 효율(간단하게는 CTR, CVR 등)이 좋았던 N명의 오디언스의 특징을 찾고, 전체 오디언스 풀에서 N명과 유사한 M을 찾는 것이다. Key Features본 논문의 핵심은 3가지로 구분된다. 1. User representation을 학습하는 offline train model 2. Seeds representation 을 학습하는 비동기 online processing 3. user와 seed간의 similarity를 계산하고, 점수를 매겨 서빙하는 Online Serving 본 논문을 직접 구현하는데 있어 가장 중요한 것은 1, 2번의 모델링 방법이다. 3의 경우, 각 회사나 시스템마다 적용할 수 있는 방법은 다양하게 있을 것이다. 본 글에서는 1번에 집중하여 핵심을 파악해보자. 다음글에서 2번 모델에 알아보자. 1. User Representation Learning유저 profile 데이터는 매우 다양하게 있을 것이다. 기본적인 메타데이터부터 특정 광고 캠페인에서의 클릭수, 랜딩 페이지, 랜딩 페이지에서의 활동 등. user 를 표현 할 수 있는 profile feature data 는 잘 정제 되어 있다는 전제하에 본 논문이 제시하는 user representation learning 모델을 살펴보자. 그림 : User representation learning Model Architecture Sampling 먼저, 본 논문은 user representation embedding 을 학습시키기 위해 multi-class classification 문제를 만들었다. 유저마다 클릭하는 아이템의 카테고리를 부여하고, 각 카테고리로 분류하는 문제이다. 이 때 수 많은 카테고리가 존재할 것이고, 유저의 분포와 카테고리 마다의 분포가 학습시키는데 불리하므로, 다음과 같은 negative sampling 을 활용했다. $$p(x_{i})= \\frac {log(k+2)-log(k+1)}{log(D+1)}$$ $x_{i}$ : i번째 아이템 $k$ : i 번째 아이템의 랭크 $D$ : 아이템 랭크의 최댓값 $p(x_{i})$ : i번째 아이템이 뽑힐 확률 본 논문에서는 negative sampling 에서 poitive : negative 의 비율을 1:10으로 설정했다. 모델 구조 본 몬문에서는 위의 multi-class classification 문제를 풀기 위해, 모델 구조는 다음과 같이 간단하다. Embedding layer : (user, item) (2-1) Concatenation layer : 붙이자! or (2-2) Attention merge layer : 잘 붙이자! Multi layer perceptron (optimizer) Adam optimizer 마지막 Loss 는 Cross Entropy Loss $$L = - \\Sigma_{j \\in X} y_ilogP(c=i| U, X_{i})$$ $X$: 아이템 embedding 집합 $y_{i}$ : 0 or 1 의 라벨 Attention Merge Layer 본 논문에서는 단순 concatenation layer 을 사용하니, 특정 아이템 필드에서 오버피팅 되는 문제가 있어, 강하고 약한 상관관계를 묘사하기 위해 다음과 같은 attention 유닛을 사용했다. $$u=tanh(W_{1}H)$$ $$a_{i} = \\frac {e^{W_{2}u_{i}^{T}}}{\\Sigma_{j}^{n}e^{W_{2}u_{j}^{T}}}$$ $h \\in \\mathbb {R}^m$, $H \\in \\mathbb {R^{n \\times m}}$ $W_1 \\in \\mathbb{R}^{k \\times n}$, $W_2 \\in \\mathbb {R}^{k}$ $u \\in \\mathbb{R}^n$ : activation 유닛 $a \\in \\mathbb{R}^{n}$ : attention weight $k$ : attention 유닛 사이즈 위 식을 계산하고, 최종적으로 concatenated layer 를 대신하는 vector 는 다음과 같이 계산된다. $$M=aH$$ 2. User Representation Learning 구현에 있어서 마주한 문제들.2-1. User Profile Data 처음과 끝은 데이터임은 모든 데이터사이언티스트가 가지고 있는 고민이다. 양질의 데이터 웨어하우스를 구성하는것. 본 논문을 구현하고 시스템에 테스트 하는데 있어 가장 오랜 시간이 걸린 것이 입력 데이터 웨어하우스를 구성하는 것이었다. 기존에 사용하고 있는 데이터에서 attention 학습을 위해 시계열적인 학습 데이터를 구성했다. 그리고 여전히 추가되는 새로운 feature에 대해서도 고민하고 있다. 광고 특성상 각 소재 및 매체마다 붙는 IAB 카테고리 뿐만 아니라, 유저의 활동에도 각 카테고리 값을 시계열적으로 담았다. 본 논문의 아이디어를 차용해, 일정 기간 동안 클릭 및 전환하는 IAB 카테고리 내에서의 네거티브 샘플링을 적용했다. 2-2. Attention Merge Layer의 효과 본 논문처럼 나 역시 base model을 단순 concatenated layer 로 잡았다. (torch.concat 만 하면 되니까..) 반면에 논문에서 소개된 구조로 attention layer를 추가한 다음 모델에서는 학습 시키는데 어려움이 있었다. 특정 attention weight 만 업데이트 되는 문제를 발견하게 되었다. attention 목적에 맞는 기능을 하긴 했으나, 특정 attention weight 만 업데이트가 되면서, 일부 item embedding 은 반영되지 못하는 효과가 있었다. 이를 만회하기 위해, 나는 attention merge layer 와 base 모델의 concatenated layer 구조를 z 축으로 붙여 학습시키기도 하였다. 수치상으로는 앞 선 두 구조보다 나은 결과를 보였으나, 해당 구조가 같는 의미와 기능은 조금더 고민해보아야 한다.","link":"/2023/02/26/20230226-paper-RALM-1/"},{"title":"[논문리뷰] Real-time Attention Based Look-alike Model for Recommender System (Part 2)","text":"본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 후반부 심을 살펴보고자 한다. 특히 Online Processing, Online Serving 파트를 집중적으로 살펴보자. Key Features본 논문의 핵심은 3가지로 구분된다. 1. User representation을 학습하는 offline train model 2. Seeds representation 을 학습하는 비동기 online processing 3. user와 seed간의 similarity를 계산하고, 점수를 매겨 서빙하는 Online Serving 지난 Part 1에서 User representation과 offline train model을 살펴보았다면, 이번 글에서는 비동기 online processing 과 Online serving 부분에 대해 살펴보자. 1. Online Asynchronous Processing비동기 온라인 프로세싱에서의 핵심은 앞서 데이터베이스에 가지고 있는 유저 pool의 표현 방식 seeds representation을 실시간으로 업데이트 하는 것이다. Seeds는 시스템이 지속되고, 그 pool이 늘어남에 따라 계속 축적될 것이다. 또한 가지고 있는 유저는 계속 그 행동과 히스토리 데이터를 남길 것이고 그 데이터에 따라 유저를 표현하는 방식도 최신화 되어야만한다. 따라서 이 representation 은 주기적인 업데이트가 필요하고, 수많은 seeds를 효율적으로 관리하고 비슷한 seeds를 구분 짓기 위해 군집화를 시행한다. 비동기 온라인 프로세싱은 다음 두 가지로 구성된다. User feedback monitor Seed의 클릭, 페이지 방문 등 프로파일 데이터를 모니터링 하며, 다음 클러스터링에 영향을 주게 되는 user profile 을 실시간으로 업데이트한다. 이 논문에서는 3백만의 click 데이터를 활용하여 seed들의 profile을 업데이트 했다. Seeds Clustering K-means 알고리즘을 이용해 seed 들을 k 개의 군집으로 clustering 하였다. 각 cluster의 중심점과 업데이트 되는 중심점은 저장해 놓고, 이를 seeds의 raw representation $R_{seeds}$ 개념으로 보았다. $$R_{seeds} = &lt;!–swig￼0–&gt;, E_{centroid_{2}}, E_{centroid_{3}} ,…, E_{centroid_{k}}}}$$ 2. Online Serving이 온라인 서빙 부분은 실제 구현하는 각 회사나 개인의 환경에 따라 본 논문의 형태와는 다를 수 있겠다. 하지만 나 역시 이 부분의 이해를 토대로 회사의 환경에 맞게 응용하여 적용하였으므로 차분히 살펴보자. 이 모델이 서빙이 될 때, 그 input 부터 살펴보면 다음과 같다. Current user → Fetch look-alike embedding Fetch the centroid embeddings Predict global embedding (global attention unit) Predict local embedding (local attention unit) Calculate global similarity &amp; local similarity 위 단계별로 걸쳐진 global similarity와 local similarity는 다음의 식으로 통합된다. $$score_{u, s} = \\alpha cosine(E_{u}, E_{global_{s}})+ \\beta cosine(E_{u}, E_{local_{s}})$$ $E_{global_{s}}$ : seeds의 global embedding $E_{local_{s}}$ : seeds의 local embedding $\\alpha , \\beta$ : global similarity와 local similarity의 각 가중치 (본 논문에서는 $\\alpha=0.3$, $\\beta =0.7$로 적용했다.) 이렇게 앞서 만든 모델들의 각 유닛에 input 과 cluster embedding 간의 유사도 계산을 통해 최종 계산된 본 유사도를 활용하여 user extension 의 그룹을 정할 수 있다. 3. 본 논문 리뷰를 마치며회사의 업무로써 이 논문을 처음 읽었을 때는 그리 크게 감탄하지 못했다. 하지만 본격적으로 구현해보면서, 본 논문의 주장하는 바와 그 주장이 논리적으로 다가와 내게 “Aha”포인트를 주어, 이 논문을 정리하고 공유해보고 싶었다. 이 논문의 인상 깊은 점은 attention unit 을 통한 global , local 유저간의 유사도를 얻는 아이디어 였다. attention unit을 제외하고 이 모델을 살펴 보면, linear regression을 이용한 user extension 과 크게 다르지 않다는 것을 알 수 있다. 다른 분야(NLP)의 전유물이라고만 느껴왔던 attention unit 을 적용하는 아이디어에 대해 다시 한번 감탄하며 나 역시 분야를 가리지 않는 스터디를 통해 창의적인 시도를 계속 해봐야겠다는 다짐을 한다.","link":"/2023/03/12/20230312-paper-RALM-2/"},{"title":"[Kubernetes] 쿠버네티스 입문","text":"머신러닝 서비스를 개발, 배포, 운영을 시작하면서 도커에 대한 이해와 필요성을 느끼며 도입을 위해 공부를 시작했다. 도커를 공부하던 끝에 이제는 쿠버네티스를 시작해보려고한다. 그리고 올해 말에는 CKAD 도 도전해보려고 한다. Kubernetes글 시리즈에서는 Kubernetes를 처음 시작하고 공부한 내용들을 정리해보며, 시험 준비기까지 정리해보려고 한다. 시험을 실제로 도전하기전 학습하고 실습한 내용들을 정리하는 글이다보니 그 끝에 시험에 합격할지까지 관심있게 지켜봐주면 좋겠다. 시험 합격 여부와 상관없이, 이 노력과 글, 지식은 내 안에 쌓일테니 꼼꼼히 공부해보려고한다. 1. 쿠버네티스란?쿠버네티스는 도커와 같은 컨테이너를 손쉽게 관리하는 플랫폼이다. 도커 컨테이너를 서비스 트래픽의 양과 컨테이너의 양에 따라 배포하고 확장해야하는 이슈가 생기기 마련이다. 이 다수의 컨테이너를 관리하고 이를 자동화하는 플랫폼이다. 있어보이는 표현으로는 컨테이너 오케스트레이션 툴이라고 정리할 수 있겠다. 2. 쿠버네티스의 구성 요소쿠버네티스의 구성요소를 정리하며, 각 요소들의 기능 및 용어를 정리해보자. 2-1. 파드 : Pod파드란 쿠버네티스 내에서 생성되고 관리되는 배포 가능한 가장 작은 컴퓨팅 단위이다. 어플리케이션의 단일 인스턴스라고 이해할 수 있다. 즉, 파드는 하나 이상의 컨테이너 그룹이다. 파드 내에서는 메모리, 네트워크를 공유하고 함께 스케쥴링된다. 2-2. 노드 : Node노드란 클러스터의 가상 혹은 물리 머신을 의미한다. 각 노드는 아래서 설명할 컨트롤 플레인에 의해 관리되고, 파드를 실행하는데 필요한 서비스를 포함한다. 클러스터 내에는 다수의 노드가 있을 수 있다. 모든 클러스터는 최소 한 개 이상의 워커 노드를 갖게 된다. 이후 워커 노드는 각 어플리케이션의 구성요소인 파드를 호스팅한다. 2-3. 컨테이너 런타임 엔진 컨테이너를 구성하고 실행하기 위해 각 노드 안에는 컨테이너 런타임 엔진이 존재한다. 이 컨테이너 런타임 엔진 개념에 포함되는 한가지 예가 바로 도커이다. 쿠버네티스는 도커뿐만아니라 rkt 와 같은 컨테이너와도 호환이 가능하다. 2-4. 컨트롤 플레인 : Control Plane컨트롤 플레인이란 컨테이너의 전체 라이프 사이클을 정의하고, 배포하며, 관리하기 위한 API 이다. 컨트롤 플레인은 워커 노드와 클러스터 내 파드를 관리하게 된다. 컨트롤 플레인은 앞서 말한 노드와 항상 연결되어 있어, 노드가 정의한 실행환경에 따라 서로 통신하게 된다. Control Plane - 출처 : https://www.redhat.com/ko/topics/containers/kubernetes-architecture 2-5. etcd클러스터 설정 데이터와 클러스터의 상태를 저장하는 key-value 데이터베이스이다. 클러스터 내에 어떤 노드가 몇 개 존재하며, 어떤 파드가 동작하고 있는지에 관한 정보가 etcd 에 기록된다. 이 etcd에 대한 백업 계획이 필수일 것이다. 이 etcd 데이터 유실이 일어나면 클러스터가 사용하는 리소스 정보를 모두 잃어버리기 때문이다. 이 외에도 kude-scheduler, kube-controller-manager, cloud-controller-manager, kube-proxy, kubelet 등 쿠버네티스의 기능과 관련된 개념과 용어드리 많이 등장한다. 위 5개와 관련된 용어는 쿠버네티스를 처음 시작하고 실습하는데 필요한 개념이라면 이후에 나오는 용어들은 각각의 실습과 동시에 그 용어와 개념을 정리해보려고 한다. 몇년동안 줄곧 핫한 플랫폼을 항상 쓰던 기능만 찾아서 써왔다. 이제와서 자세하게 공부하는 것이 조금 늦은 것 같아 아쉬운 점이 많지만, 이 아쉬움을 동기 삼아 열심히 공부해보려고 한다.","link":"/2023/03/26/20230326-basic-kubernetes/"},{"title":"[Linux] screen을 사용해보자","text":"우리가 서버에서 시간이 많이 드는 작업을 한다고 생각해보자. 필자는 모델을 학습시킨다거나 특정 어플리케이션을 빌드할 때를 예로 들 수 있겠다. (특히 최근에는 gcc를 빌드 할 때..) 해당 작업을 하면서 콘솔에 찍히는 아웃풋 모니터링 등도 함께 필요하면 특히나 서버에 붙은 연결을 유지해야할 필요가 있다. 오늘은 이 문제를 해결할 수 있는 linux의 screen을 알아보고 이 기능 외에도 다양하게 활용할 수 있는 응용 예제들도 살펴보자. 1. Screen의 개념screen은 현재 접속해 있는 세션과 상관 없이 가상의 터미널을 띄워주는 리눅스 어플리케이션이다. 터미널 멀티플렉서라고도 한다. 가상의 터미널을 띄워주는 기능 덕분에 우리가 ssh 로 붙어 있는 세션이 time-out 등으로 종료되더라도 이미 띄워진 screen 의 세션은 살아있게 된다. 따라서 앞서 내가 겪은 예처럼 모델 학습이나 어플리케이션 빌드를 진행하는 도중 세션이 끊기더라도 그 screen 위에서 동작하는 작업들은 계속 백그라운드에서 동작하게 된다. 2. Screen 설치screen은 대부분의 linux에서 기본적으로 설치되어 있으나, 다음과 같은 방법으로 그 버전을 확인해보고 없다면 설치해주면 된다. 1$ screen --version Ubuntu 계열 12$ (sudo) apt update$ (sudo) apt install screen Fedora 계열 및 CentOS 1$ (sudo) yum install screen 3. 간단 Screen 시작위 과정으로 screen이 준비 되었다면, 간단하게 screen을 사용해 볼 수 있다. 1$ screen screen을 입력해 실행하더라도, 터미널 상에서 그 전과 다르지 않다는 것을 확인 할 수 있다. 하지만 exit으로 screen을 종료하면 다음과 같은 문구를 확인 할 수 있다. 이렇게 우리가 지금 screen을 사용하는지 안하는지, 어떤 창을 사용하고 있는지 등을 육안으로는 쉽게 확인 할 수 없기 때문에 screenrc 파일을 수정하여 예쁘게(?) 사용한다. 터미널도 예뻐야 일할 맛이 나니 먼저 screenrc 부터 수정해보자. 4. screen을 자유자재로 활용해보기screen에 다양한 옵션을 알아보자. 암기하듯이 나열하는 것보다는 필자가 습관처럼 자주 사용하는 명령어 순으로 나열해보겠다. 4-1. screen -S앞서 screen만 입력하게 되면, default 이름이 들어가게 된다. -S 옵션을 주게 되면 session 마다 1$ screen -S session_name 4-2. screen -ls생성한 세션의 리스트를 확인할 수 있습니다. 1$ screen -ls 4-3. 세션 다시 접속생성했던 세션에 다시 접속하기 위한 명령어이다. 동일한 이름의 세션이름이 두개 이상있다면, 앞에 나와있는 세션 ID까지 같이 입력해주어야 한다. 12$ screen -r session_id_or_session_name$ screen -x session_id_or_session_name screen -r 과 screen -x의 차이 screen -r: Single display mode screen -x: Multi display mode → 같은 스크린 세션에 여러명이 들어갔을 때 모든 명령어와 활동이 함께 보임 아래 예시처럼 서로 다른 터미널을 틀고, 같은 스크린에 -x 옵션을 주어 접속하면 한쪽에서 치는 명령어와 활동이 동일하게 보인다 4-4. 세션 내 윈도우 생성세션 내에서 윈도우를 생성하는 것은 스크린의 주요 기능이라 할 수 있다. 한 세션 내에서 여러 윈도우를 실행하고 각각 다른 작업을 수행할 수 있다. 12$ ctrl + a, c # (create라 기억) 4-5. 세션 detached다음에서 나오는 세션 종료와는 다르다. 현재 연결 되어있는 screen 과의 연결만 끊는 것이다. 12$ ctrl + a, d# (detach라 기억) 4-6. 세션 내 윈도우 종료 &amp; 세션 종료세션에 내 모든 윈도우가 종료되면 screen으로 실행한 세션도 종료된다. 1$ exit 다음 명령어는 screen을 종료하면서 빠져나간다. 1$ ctrl + a, k 4-7. 세션 내 윈도우 목록 보기한 세션 내에서 여러 윈도우가 있는 경우 윈도우의 리스트를 볼 수 있는 방법이다. 아래 명령어를 입력하면 윈도우 목록이 잠시 나타났다가 사라진다. 1234$ ctrl + a, w# (실행되고 있는 window라 기억)$ ctrl + a, &quot; ctrl + a, w 터미널 하단에 나타나는 결과 ctrl + a, “ 윈도우 목록이 보이고, 방향키로 해당 윈도우 선택 가능 4-8. 세션 내 윈도우 이동하기세션에서 윈도우 간의 이동은 윈도우의 번호를 누르면 된다. 혹은 이전 창의 경우 다음 명령어 와 같다 12345$ ctrl + a, 0 # 0번째 윈도우$ ctrl + a, 1 # 1번째 윈도우$ ctrl + a, 2 # 2번째 윈도우$ ctrl + a, a # 이전 사용한 윈도우 4-9. 윈도우 화면 분할 가로 화면 분할 1$ ctrl + a, shift + s 세로 화면 분할 1$ ctrl + a, shift + \\ 분할 윈도우간 이동 1$ ctrl + a, tab 5. 마무리이번 글을 통해 screen 의 기본 사용법 대해 알아보았다. 빌드가 오래걸리는 여러가지 작업들에 도움이 될 것이며, 꼭 오래걸리는 작업 이외에도 한 화면에 다양한 화면 분할 기능으로 생산성이 올라갈 수 있을 것이다. 사용자의 입맛 대로 .screenrc를 작성하여 screen 을 꾸며 볼 수도 있다. 한 번 사용해보세요 🙂","link":"/2023/04/09/20230409-screen-basic/"},{"title":"[FastAPI] FastAPI 입문 part1 - 설치&#x2F;라우팅","text":"회사에서는 그동안 데이터 파이프라인을 만들고 모델을 만드는데 열중하였다. 그리고 모델 개발이 완료되고, 이를 서비스하기 위해 다양한 방법을 고민하였다. 물론 모델 개발을 기획하기전 서비스를 어떻게 할지 구조와 계획을 세웠으나, 다양한 내부적인 이슈들이 있었다. 실시간성과 빠른 응답이 필요한 time-out 이슈, 장비의 노후화 등 여러가지 문제를 마주하였었고 이를 해결하기 위해서 자체 개발한 API가 필요하다는 것이 결론이었다. 머신러닝 모델을 서비스하고 운영하기 위해 MLOps라는 단어가 등장하였다. 다양한 회사와 플랫폼에서 MLOps를 지원하기 위해 많은 제품을 내놓고 있으나 내가 있는 환경에 딱 들어 맞는 것이 없었다. 그래서 이번 기회에 FastAPI 를 이용해 자체 API 를 만들었다. 실제 배포되어 운영되고 있는 코드는 훨씬 복잡할 수는 있겠지만 기본 뼈대와 구조는 모두 동일할 것이다. 글을 쓰는 나 역시 FastAPI를 처음 사용해본 것이기에 스터디하면서 만들었다. 그간의 삽질과 여정을 한번 정리해보면서, 나와 비슷한 고민을 하는 분들에게 조금이나마 도움이 되길 바란다. (또한, 이 시리즈를 쓰는데 동기와 용기를 준 글또 커피드백 조원 두 분에게 감사하며 글을 써본다. Shout out to 문현규 &amp; 박다원) 이 글은 FastAPI 의 설치와 그 입문 그리고 기초적인 라우팅까지의 내용을 담았다. 앞으로 FastAPI시리즈로 담을 것이고 시리즈 안의 글의 순서와 목차는 내가 API를 구성하면서 스터디한 순서대로 담으려고 노력할 것이다. 1. FastAPI의 소개 및 설치Python 세계에 웹 프레임워크는 다양하다. 가장 유명한 장고(Django)와 플라스크(Flask)가 있지만, 이 프레임워크들은 그 유명한 만큼 다양한 기능을 제공한다. 반면에 그 역사와 전통을 자랑하는 것과 비례에 그 속도가 느린 것이 단점이다. FastAPI 는 그 이름에서 느낄 수 있는 것처럼 빠르고 가벼우며, 간단한 API 를 비교적 쉽게 빌드하여 테스트베드로 사용할 수 있다. 먼저 FastAPI를 실습할 수 있게 설치해보자. 1-1. FastAPI 설치1$ pip install fastapi 12345$ pip install uvicorn # or$ pip install &quot;uvicorn[standard]&quot;# or$ pip install gunicorn 이번 실습은 FastAPI 만 설치해도 무난하다. 하지만 웹 어플리케이션을 실제로 배포하고 다양한 request 를 처리하기 위해 나중엔 웹 서버가 필요할 수 있다. 이를 위해 unicorn이나 gunicorn, nginx등이 많이 사용되는데 이에 대해서는 나중에 좀더 자세히 살펴보자. 지금 단계에서는 fastapi, uvicorn 만 치해도 실습하고 배포하는데 큰 문제가 없다. 1-2. HelloWorldFastAPI 를 설치해보았으니, 간단한 웹 어플리케이션을 빌드하여 hello world 를 찍어보자. my_first_app라는 폴더를 만들고 그 안에 app.py 라는 파이썬 파일을 만들자. 123$ mkdir my_first_app$ cd my_first_app$ touch app.py main.py 안에 다음과 같이 작성하자. 123456789101112# my_first_app/main.pyfrom fastapi import FastAPIfrom typing import Dictapp = FastAPI() #1@app.get(&quot;/&quot;) #2async def helloworld() -&gt; Dict: #3 return { &quot;message&quot;: &quot;Hello World&quot; #4 } #1 : app이라는 변수에 FastAPI() 서버의 인스턴스를 생성한다 #2: 데코레이터를 사용하여 이 app에 라우팅을 설정해준다. REST API의 “/”경로로 GET 액션이 들어왔을 때, 실행되는 함수를 밑에 정의한다. #3: helloworld() 라는 함수를 위 라우트가 왔을 때 실행되는 함수명이고 그 내용은 #4의 dictionary 를 리턴한다. 간단하게 만든 우리의 첫 어플리케이션을 실행해보자. 12$ cd my_first_app$ uvicorn main:app --port 8080 --reload 위 실행 명령어를 살펴보면, uvicorn : ASGI 웹 서버 어플리케이션으로 실행한다. main : 우리가 실행시키려고 하는 모듈 이름 app : main 모듈 안에 uvicorn 이 바라보는 인스턴스 이름 —port : 포트를 지정한다. 여기서는 8080 —reload : reload 옵션을 주면 우리가 개발하는 프로젝트내에서 코드 변경이 이루어 졌을 때 다시 서버를 구동하여 변경된 코드를 적용한다. 개발하는 단계에서 잘 사용하면 편하다. 이렇게 사용하게 되면 터미널에서는 다음과 같이 결과가 뜬다. 웹서버가 잘 떴는지 확인하기 위해 자주 사용하는 크롬이나 사파리와 같은 브라우저에서 우리가 방금 만든 웹서버에 접속해보자. url : http://localhost:8080/ 혹은 터미널에서 curl localhost:8080 정상적으로 우리의 첫 어플리케이션을 띄우는데 성공했다면, 그 시작이 매우 보람찰 것이다. 내 손으로 띄운 웹통신 서버라니.. 사실 이게 API의 전부이다. 위 간단한 어플리케이션의 동작 원리를 다시 살펴보면, (1) 우리가 URL 로 접속한다. 정확히는 호스트 주소. 여기서는 localhost:8080 (2) 그리고 접속하고자 하는 경로를 확인한다. 여기서는 “/” (3) 이 request를 받은 우리의 인스턴스는 라우팅을 통해 “/”에 해당하는 함수를 찾는다. (4) helloworld()함수를 실행하고 그 함수에서 정의한 결과값을 리턴한다. 여기서는 {”message”: “hello world”} 정상적으로 응답을 했다면, 다음과 같이 200 사인을 준다. 그 결과는 우리의 콘솔에서도 확인할 수 있다. 2. 라우팅앞서 살펴본 라우트 처리 방법은 실제로는 잘 사용하지 못한다. 위와 같은 방식은 라우팅 중에 단일 경로만 처리하게 되기 때문이다. 이는 uvicorn이 하나의 엔트리 포인트만 실행할 수 있기 때문이다. 여러 함수를 사용하여 연속적이고 다중의 라우트 처리는 FastAPI의 APIRouter클래스를 사용하여 이 문제를 해결 할 수 있다. 실습해보자! my_first_app 안에 routers 라는 폴더를 만들고 test.py 파이썬 파일을 만들자. 123$ cd my_first_app$ mkdir routers$ touch routers/test.py new_router.py 에 다음과 같은 코드를 작성하자. 123456789101112from fastapi import APIRouterfrom typing import Dictrouter = APIRouter( prefix=&quot;/new&quot;)@router.get(&quot;/test&quot;)async def helloworld_new( ) -&gt; Dict: return { &quot;message&quot;: &quot;new router Hello!&quot; } main.py 에 다음을 추가하자. 1234# main.py 에 추가from routers.new_router import routerapp.include_router(router) 최종적으로 main.py의 코드는 다음과 같다. 1234567891011121314from fastapi import FastAPIfrom typing import Dictfrom routers.new_router import routerapp = FastAPI()app.include_router(router)@app.get(&quot;/&quot;)async def helloworld() -&gt; Dict: return { &quot;message&quot;: &quot;Hello World&quot; } 기능확인 localhost:8080/new/test 라는 주소를 입력하면 우리가 새로 작성한 new router hello 메시지를 볼 수 있다. 우리가 추가한 new_router.py 를 살펴보자. (1) APIRouter 클래스 안에 prefix는 여기서 설정하는 router는 /new 뒤에 오는 경로를 설정하겠다는 의미이다. 이부분을 공란으로 두면, localhost:8080/ 루트에 바로 추가되는 경로가 될 것이다. (2) /new 아래에 /test라는 경로가 들어오면 아래 함수를 실행하겠다는 뜻이다. 여기서는 “new router Hello”를 리턴한다. 3. 정리이번 글에서는 FastAPI 를 이용하여 간단하게 첫 어플리케이션을 만들어 보았고, 거기다 더해 다중 라우팅을 처리하기 위한 APIRouter클래스도 살펴보았다. 이번 글에서 미처 설명하지 못한 부분을 한번 개인적으로 찾아보면 좋겠다. 키워드로는 RestAPI, HTTP 메소드중 GET, POST, PUT, DELETE, Router 등의 키워드로 개인적인 공부를 하면 앞으로 업로드하는 FastAPI시리즈를 읽으며 좀더 많은 도움이 될 것이라고 믿는다.","link":"/2023/04/23/20230423-fast-api-1/"},{"title":"[FastAPI] FastAPI 입문 part2 - CRUD 어플리케이션 만들기","text":"지난 part1에서 FastAPI를 활용해 간단한 “hello world”와 “routing”을 살펴보았다. 이번 글에서는 CRUD 기능을 수행하는 간단한 어플리케이션을 만들어보면서 FastAPI 프레임워크에 친숙해져보자. 아래의 실습 과정은 지난 part1 글에서 이어서 해보는 것이므로, 앞의 글을 먼저 읽고 따라해보면 좋겠다. 🖐🏻!여기서 잠깐!🖐🏻 CRUD 를 간단하게 설명하자면, C: Create(생성), R: Read(읽기), U: Update(갱신), Delete(삭제)를 일컫는 말이다. API 를 구축할 때 사용자 혹은 클라이언트가 요구하는 기본적인 기능이라고 이해하면 좋겠다. 1. Alarm 어플리케이션 만들기지금부터 우리가 까먹기 쉽고 상기시켜야 하는 알람들의 리스트를 보여주고, 추가하는 기능을 갖고 있는 어플리케이션을 만들어보려고 한다. 먼저 지난 part1에서 만들었던 main.py와 routers/new_router.py에 코드를 추가하는 형태로 이어가보려고 한다. 먼저 new_router.py에 다음과 같은 코드를 추가하자. 1-1. 새로운 router 추가12345678910111213141516# routers/new_router.pyalarm_list = []@router.get(&quot;/alarm&quot;)async def show_alarm() -&gt; dict: return { &quot;alarms&quot;: alarm_list }@router.post(&quot;/alarm&quot;)async def add_alarm(alarm: dict) -&gt; dict: alarm_list.append(alarm) return { &quot;message&quot;: &quot;Your ALARM added successfully.&quot; } 위 코드를 살펴보면, 먼저 전역 alarm_list라는 빈 리스트를 실행해주고, 한 개의 GET 메서드와 POST 메서드를 만들어 준다. GET메서드의 코드부터 살펴보면, uri(/alarm)가 GET 메서드로 들어오면, (우리가 미리 작성했던 코드에서 주의할 점은 우리는 new_router.py를 만들 때, prefix=”/new” 라고 주었다. 따라서 전체 uri는 /new/alarm이 되겠다.) 아래의 show_alarm()이 실행된다. 이 함수는 우리가 미리 선언해 두었던 alarm_list를 반환하는 함수이다. POST메서드의 코드를 살펴보면, uri(/alarm)가 POST 메서드로 들어오면, 아래의 add_alarm() 함수가 실행된다. 이 함수는 인자로 받은 alarm을 alram_list에 추가하고, 성공적으로 추가 되었다는 메시지까지 반환하는 함수이다. 1-2. 테스트 해보기여기까지 작성한 코드를 테스트 해 보자. 다음의 명령어로 우리의 어플리케이션을 실행해보자. 1uvicorn main:app --port 8080 --reload 새롭게 만든 uri 로 테스트하기 위해 다음의 명령어를 사용한다. 먼저 GET 메소드에 대해서는, (1) GET 메소드 테스트 명령어 1curl -X 'GET' 'http://localhost:8080/new/alarm' -H 'accept: application/json' 아직 우리의 alarm_list에 추가된 것이 없으므로 빈 리스트로 나오는 것이 당연하다. (2) POST 메소드 테스트 명령어 이제 다음의 명령어를 통해 우리의 alarm_list에 새로운 데이터를 추가해보자. 1curl -X 'POST' 'http://localhost:8080/new/alarm' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;id&quot;: 1, &quot;alarm&quot;: &quot;You pushed the first alarm in your list!&quot;}' 성공적으로 추가된 뒤에 다시 (1)의 GET메소드를 실행해보면, 처음과는 다르게 방금 추가한 메시지가 출력되는 것을 확인 할 수 있다. 이렇게 우리는 CRUD 중 C, R을 수행하는 기능을 만들어 보았다. 2. 데이터 검증 : pydantic데이터를 수정하고 지우는 것은 API, 어플리케이션 입장에서는 매우 critical 한 기능이다. 서버를 운영하고 개발하는 입장에서는 수집된 데이터를 변경하거나 삭제하는 액션이 실행되기 때문이다. 따라서 우리는 수정하려고 하는 새로운 데이터가 기존 형식에 알맞게 수정되거나 삭제되는지 검증해야한다. 이 작업은 python 에서는 “Pydantic”이라고 하는 편한 라이브러리를 이용해 해당 데이터를 검증한다. 2-1. 모델 세우기.Web Application 에서 데이터가 어떻게 구성되고 처리되어야 하는지 미리 선언해 놓는 것을 모델이라고 한다. 우리 어플리케이션에도 model.py를 만들고 해당 파일에 다음과 같이 작성하자. 12345678910# model.pyfrom pydantic import BaseModelclass Alarm(BaseModel): id: int alarm: strclass AlarmData(BaseModel): alarm: str 우리가 다룰 Alarm이라는 클래스는 id 와 alarm이라는 내용으로 구성되고 이 형식에 맞게 데이터가 들어와야 한다는 것이다. 그 아래 AlarmData는 뒤이어 데이터 업데이트 부분에서 활용될 내용이다. 수정할 데이터가 str 형식으로 들어와야 됨을 의미한다. 2-2. model.py를 활용한 코드 수정위에 model.py 를 만들었으면 우리의 라우터에도 해당 데이터 검증 작업이 추가 될 수 있도록 코드를 수정하자. 먼저 데이터가 가장 먼저 추가 되는 @router.post(”/alarm”)부분의 함수 add_alarm(alarm: Alarm) 이다. 123456@router.post(&quot;/alarm&quot;)async def add_alarm(alarm: Alarm) -&gt; dict: alarm_list.append(alarm) return { &quot;message&quot;: &quot;Your ALARM added successfully.&quot; } 이렇게 되면 POST 되어 전달되는 데이터가 우리가 미리 작성해둔 모델(Alarm)의 id, alarm 이 각각 int이고 string 인지 검증하고 실행되게 된다. 3. 데이터 수정3-1. 새로운 router 추가새로운 라우터를 추가하여 우리가 가지고 있는 alarm_list의 데이터를 수정해보자. 123456789101112@router.put(&quot;/alarm/{alarm_id}&quot;)async def update_alarm(alarm_data: AlarmData, alarm_id: int=Path(..., title=&quot;ID to be updated&quot;)) -&gt; dict: for each_alarm in alarm_list: if each_alarm.id == alarm_id: each_alarm.alarm = alarm_data.alarm return { &quot;message&quot;: &quot;Your Alarm is successfully updated.&quot; } return { &quot;message&quot;: &quot;The ID which you gave doesn't exist.&quot; } PUT 메소드로 /alarm/alarm_id 형태로 uri 가 전달 되면, 아래의 update_alarm() 함수가 실행된다. update_alarm 함수는 alarm_data와 변경하고자 하는 alarm_id 를 인자로 받는다. 그리고 아래의 로직은 우리가 미리 갖고 있던 alarm_list를 순서대로 조회하며 인자로 주어진 alarm_id 가 우리의 리스트에 존재한다면 alarm 데이터를 변경하는 것이다. 3-2. 테스트 해보기먼저 위와 동일하게 서버를 실행해주고, 새로운 데이터 2개 를 추가한다. 1curl -X 'POST' 'http://localhost:8080/new/alarm' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;id&quot;: 1, &quot;alarm&quot;: &quot;You pushed the first alarm in your list!&quot;}' 1curl -X 'POST' 'http://localhost:8080/new/alarm' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;id&quot;: 2, &quot;alarm&quot;: &quot;You pushed the second alarm in your list!&quot;}' 다음의 명령어로 첫번째로 추가한 데이터를 수정해보자. 1curl -X 'PUT' 'http://localhost:8080/new/alarm/1' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;alarm&quot;: &quot;Your first Item is changed with this updated ONE!!!&quot;}' 수정한 뒤에 GET 메소드 테스트 명령어를 수행해 데이터가 잘 수정되었는지 확인해보자. 1curl -X 'GET' 'http://localhost:8080/new/alarm' -H 'accept: application/json' 4. 데이터 삭제4-1. 새로운 router 추가마지막으로 삭제에 대한 기능을 추가해보자. 다음과 같이 router에 추가한다. 12345678910111213@router.delete(&quot;/alarm/{alarm_id}&quot;)async def delete_alarm(alarm_id: int) -&gt; Dict: for each_index in range(len(alarm_list)): alarm = alarm_list[each_index] if alarm.id == alarm_id: alarm_list.pop(each_index) return { &quot;message&quot;: &quot;Alarm is successfully deleted.&quot; } return { &quot;message&quot;: &quot;The ID which you gave doesn't exist.&quot; } 로직은 간단하다. 전달된 id 값과 기존에 alarm_list 의 id 가 같으면 해당 데이터를 리스트에서 삭제하는 것이다. 4-2. 테스트 해보기.먼저 위와 동일하게 서버를 실행해주고, 새로운 데이터 2개 를 추가한다. 1curl -X 'POST' 'http://localhost:8080/new/alarm' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;id&quot;: 1, &quot;alarm&quot;: &quot;You pushed the first alarm in your list!&quot;}' 1curl -X 'POST' 'http://localhost:8080/new/alarm' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{&quot;id&quot;: 2, &quot;alarm&quot;: &quot;You pushed the second alarm in your list!&quot;}' 첫번째 데이터를 삭제해보자. 1curl -X 'DELETE' 'http://localhost:8080/new/alarm/1' -H 'accept: application/json' 삭제한 뒤에 GET 메소드 테스트 명령어를 수행해 데이터가 잘 수정되었는지 확인해보자. 1curl -X 'GET' 'http://localhost:8080/new/alarm' -H 'accept: application/json' 5. 정리하기이번 글에서는 Pydantic을 통한 데이터 검증 방법과 CRUD 어플리케이션을 만들어보면서 FastAPI 프레임워크에 한단계 친숙해지는 실습을 해보았다. 글을 다시 한 번 돌이켜보면, 우리가 기능을 추가할 때 하는 행동은 간단하다. 단지 Router 만 추가하면 되는 것이다! 어떤 uri (trigger)가 왔을 때, 어떤 동작을 하게끔 하는 것이 router이다. 이 router가 동작하게끔 하기 위해 부수적인 model과 pydantic 등의 기능을 추가하기만 하면 된다. 마지막으로, 오늘의 실습이 잘 동작하지 않는 사람들 위해 우리가 실습한 파일 디렉토리 구조와 main, model, router 코드 전체를 첨부하며 이번 글을 마무리 한다. 5-0. tree12345./my_first_app├── main.py├── model.py└── routers └── new_router.py 5-1. main.py123456789101112131415# main.pyfrom fastapi import FastAPIfrom typing import Dictfrom routers.new_router import routerapp = FastAPI()app.include_router(router)@app.get(&quot;/&quot;)async def helloworld() -&gt; Dict: return { &quot;message&quot;: &quot;Hello World&quot; } 5-2. new_router.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455from fastapi import APIRouter, Pathfrom typing import Dictfrom model import Alarm, AlarmDatarouter = APIRouter( prefix=&quot;/new&quot;)alarm_list = []@router.get(&quot;/alarm&quot;)async def show_alarm() -&gt; Dict: return { &quot;alarms&quot;: alarm_list }@router.post(&quot;/alarm&quot;)async def add_alarm(alarm: Alarm) -&gt; Dict: alarm_list.append(alarm) return { &quot;message&quot;: &quot;Your ALARM added successfully.&quot; }@router.put(&quot;/alarm/{alarm_id}&quot;)async def update_alarm(alarm_data: AlarmData, alarm_id: int=Path(..., title=&quot;ID to be updated&quot;)) -&gt; Dict: for each_alarm in alarm_list: if each_alarm.id == alarm_id: each_alarm.alarm = alarm_data.alarm return { &quot;message&quot;: &quot;Your Alarm is successfully updated.&quot; } return { &quot;message&quot;: &quot;The ID which you gave doesn't exist.&quot; }@router.delete(&quot;/alarm/{alarm_id}&quot;)async def delete_alarm(alarm_id: int) -&gt; Dict: for each_index in range(len(alarm_list)): alarm = alarm_list[each_index] if alarm.id == alarm_id: alarm_list.pop(each_index) return { &quot;message&quot;: &quot;Alarm is successfully deleted.&quot; } return { &quot;message&quot;: &quot;The ID which you gave doesn't exist.&quot; }@router.get(&quot;/test&quot;)async def helloworld_new( ) -&gt; Dict: return { &quot;message&quot;: &quot;new router Hello!&quot; } 5-3. model.py12345678910# model.pyfrom pydantic import BaseModelclass Alarm(BaseModel): id: int alarm: strclass AlarmData(BaseModel): alarm: str","link":"/2023/05/07/20230424-fast-api-2/"},{"title":"[Study] Markov Decision Process","text":"본 글은 David Silver의 강의를 듣고서 정리한 글이다. 매우 오래 전에 공부한 마코프 이론을 다시 한 번 상기시키기 위해 기초 강의와 함께 꼼꼼히 정리하면서 상기시켰다. 1. Markov Processes1.1 Introduction to MDPs Markov decision processes : 강화학습에서 Environment 를 묘사하는 방법 이 때, MDP 로 묘사하는 경우, environment 는 관측이 가능한 environment 인 상태입니다. (fully observable) 대부분의 RL problem은 MDP 로 표현이 가능합니다. Optimal control → continuous MDPs Partially observalble problems → MDPs Bandits → MDPs with one state 즉, 모든 RL problem의 기본원리를 이해한다면, MDP로 표현할 수 있다는 것을 확인할 수 있습니다. 1.2 Markov Property The future is independent of the past given the present = 미래는 현재에만 종속적이며, 그 이전의 과거와는 독립적입니다. $$P[S_{t+1}|S_t] = P[S_{t+1}|S1, …, S_{t}]$$ 1.3 State Transition Matrix current state $s$, successor state $s’$, the state transition probability $P_{ss’}$ $P_{ss’}$는 현재 s state 에서 $s_{t+1}=s’$ 으로 변이 되는 조건부 확률 $$P_{ss’}=P[S_{t+1}=s’|S_{t}=s]$$ State transition matrix $P$ : 위의 transition probability 를 모든 s → s’ 에 대해 모아 놓은 행렬 transition probability matrix $$P = \\begin{matrix}P_{11}…P_{1n}\\.\\.\\.\\P_{n1}…P_{nn}\\end{matrix}$$ $P_{1n}$ : 현재 state 1에서 → Next state n로 전이되는 확률 따라서, 각 행(row)의 합은 1이다. P11 + … + P1n = 1, state 1에서 다른 state 로 뻗어나가는 확률은 한번에 한 경우의 수밖에 없으므로 모든 경우의 확률의 합은 1입니다. 1.4 Markov Process Markov process 는 memoryless random process Markov Process (or Markov Chain) 는 &lt;S, P&gt; 로 표현합니다. S 는 유한한 state 들의 집합입니다. (finite set of states) P 는 transition probability matrix 1.5 Example of Markov Chain 아래 그림에서 처럼, Class 2 State 에서 다음 state 로 넘어갈 확률 0.2, 0.8 을 오른쪽 transition probability matrix 에서 확인 할 수 있습니다. state 2 → state 3 으로 가는 확률 0.8, state 2 → state sleep 0.2 를 확인 할 수 있습니다. 2. Markov Reward Processes2.1 MRP: Markov Reward Process MRP란? Markov chain 에 VALUE 가 더해진 chain Expression: Markov Reward Process → &lt;S, P, R, $\\gamma$&gt; S : states set P: transition probability matrix $P_{ss’}=P[S_{t+1}=s’|S_{t}=s]$ R: reward function , $R_{s}=E[R_{t+1}|S_{t}=s]$ $\\gamma$: discount factor, 0≤$\\gamma$≤1 2.2 Return$$G_{t }=R_{t+1}+\\gamma R_{t+2} + … = \\Sigma_{k=0}^{inf} \\gamma ^k R_{t+k+1}$$ return Gt는 현재 t 에서부터, 모든 discount 된 reward 의 합입니다. return 과 reward 헷갈리지 말아야합니다! return 은 지금부터 미래까지 합 (단, discount 그 의미는 수학적 계산편의도 있지만, 미래에 가중치를 얼마나 두느냐의 문제도 있습니다), reward 는 현재 state 와 action 이 환경으로 받은 값 왜 DISCOUNT 하는가? 2.3 Value Function Value Function : $v(s)$ -“ total reward we will get. This is the value we care about “ RL 에서 우리가 신경써야하는 최종 형태의 total reward function $$v(s)=E[G_{t}|S_{t}=s]$$ Example: 2.4 Bellman Equation for MRPs Value Function 은 다음과 같이 쪼개 질 수 있다. immediate reward $R_{t+1}$ discounted value of successor state $\\gamma v(S_{t+1})$ 지금 현재 state 에서의 reward(immediate reward) + 미래의 value(value where agent end up) $v(s) = R_{t+1}+\\gamma v(S_{t+1})$ Q) 왜 R index 가 t+1 인가? : agent 와 environment 사이에서의 경계문제. agent 가 environment 에서 활동하는 순간 time stamp 가 지나게 됨. agent 의 액션이후 environment 로부터 영향을 받고 나오면 time stamp 가 그 다음으로 찍히는걸로 정의하기에, R t+1 이라 indexing 하게됨. 추후 강의에서 더 자세히 설명. just convention 2.5 Bellman Equation in Matrix Form 위 식을 Matrix 형태로 표현 한 것입니다. 아래의 식은 각각 Vector 라고 생각합니다 $$v = R +\\gamma Pv$$ , where v = [v(1) … v(n)], R = [R1 … Rn] , P = [P11 .. P1n … P11 Pnn] (matrix) Bellman Equation 을 풀기 위해서는, 실제 작은 사이즈에서는 linear equation 을 풀기 쉽지만, 큰 규모의 문제에서 실제로는 iterative methods 를 사용한다. Dynamic programming Monte-Carlo evaluation Temporal-Difference learning 2.6 Solving the Bellman Equation 식 자체를 푸는 것은 어렵지 않다. linear equation. 손으로 풀기엔.. 그리고 연산장치를 이용한 연산 역시 작은 사이즈에선 문제되지 않는다. 다만, 사이즈가 크면 클수록 가장 마지막 식의 역행렬을 구할때 연산량이 많이 필요하다. 따라서 다른 방법이 필요하다. $$v=R+\\gamma Pv \\ (I-\\gamma P)v = R \\ v = (I-\\gamma P)^{-1}R$$ Computation을 위해선 세가지 iterative한 방법을 사용한다 Dynamic Programming Monte-Carlo Evaluation Temporal-Difference Learning 위 세가지의 자세한 내용은 추후에 등장 예정 3. Markov Decision Processes MDP가 실제로 우리가 RL 에서 자주 사용될 개념 “Actually Use in RL” MDP Expression: Markov Decision Process → &lt;S, A, P, R, $\\gamma$&gt; 3.1 Policy Policy 정의: Policy $\\pi$는 주어진 현재 state 에서 Action 에 대한 분포이다.(한국말이 더 어렵기에, distribution over actions given states) $$\\pi (a|s) = P[A_{t}=a | S_{t}=s]$$ Policy 는 agent 의 행동을 결정한다. Policy 는 현재 state (current state)에 영향을 받는다(depend on current state, not history) Policy 는 Stationary 라 가정한다.(time-independent) MDP M = &lt;S, A, P, R, $\\gamma$ &gt;, Policy = $\\pi$ 일 때, State sequnce S1, S2, S3 … : &lt;S, $P^{\\pi}$&gt; 는 Markov Process State and Reward Sequence S1, R2, S2, R2 … : &lt;S, $P^{\\pi}, R^{\\pi}, \\gamma$&gt;는 Markov Reward Process where P와 R은 다음과 같다 3.2 Value Function Value function 과 Action-Value function value fuction: how good in policy with state s action-value function: how good in policy with state s, action a 3.3 Bellman Expectation Equation 이 뒷 내용부터는 실질적으로 Equation 과 State Diagram 등이 피부에 와닿지는 않는다. 실제로 강의가 진행되면서 application 이나 본 내용이 담긴 problem을 직접 만나보고, 각 경우가 이것을 의미했던 것이구나 하며 feedback 이 있어야 더욱 잘 이해될 내용들이라고 생각된다 3.4 Bellman Expectation Equation for $V^{\\pi}$ 이 지점에서 Policy 역시 Distribution 혹은 Process(Sequence)의 형태로 개념을 확장해 간다. 다만 위의 value function 에 대한 정의에서 크게 벗어나지 않으며, 전체 state과 action 에 dependent 하다. 3.5 Bellman Expectation Equation for $Q^{\\pi}$ 3.6 Bellman Expectation Equation for $v_{\\pi}$ 3.7 Bellman Expectation Equation for $q_{\\pi}$ 3.8 Bellman Expectation Equation (Matrix Form) Bellman expectation equation 역시, 다음과 같이 표현될 수 있고, 이에 관한 풀이법 역시 linear equation 이다. $$v_{\\pi}=R^{\\pi} + \\gamma P^{\\pi}v_{\\pi}$$ $$v_{\\pi}=(I-\\gamma P^{\\pi})^{-1}R^{\\pi}$$ 3.9 Optimal Value Function optimal state-value function 은 모든 policy 에 대해서 maximum value function 을 찾는 문제이다 optimal action-value function 역시 모든 policy 에 대해서 maximum action-value function 을 찾는 문제이다. Optimal value function 은 MDP에서 best possible performance 를 찾는 문제라고 볼수 있다. 즉, MDP is “SOLVED” when we know the optimal value function (q*, v*) 3.9 Optimal Policy Optimal Policy 문제는, Best Action to MDP 를 찾는 문제이다. 3.10 Finding an Optimal Policy 3.11 Bellman Optimality Equation for $v_{*}$ 3.12 Bellman Optimality Equation for $Q^{*}$ 3.13 Bellman Optimality Equation for V* 3.14 Bellman Optimality Equation for Q* 3.15 Solving the Bellman Optimality Equation Bellman Optimality Equation 은 Non-linear 이다 따라서 Closed Form Solution 이 없다 이 역시 iterative solution 이 그 해법 Value Iteration Policy Iteration Q-learning Sarsa 위 solution 의 각 내용 역시, 추후 강의에서 진행되리라 기대한다.","link":"/2023/05/21/20230521-markov/"},{"title":"[Study] Reinforcement Learning Basic","text":"Lec1 Intro to RL1. About Reignforcement Learning1.1 다양한 분야에서의 강화학습다양한 분야에서 RL과 같은 혹은 비슷한 개념의 연구와 시도가 계속 되고 있습니다. 여기서 서로 다른 분야라 할지라도 공유되는 핵심 Key Concept은 “Decision Making” 입니다. 1.2 강화학습의 특징 No supervisor, but reward signal 덧붙이자면, 흔히 지도학습(supervised learning)에서는 우리가 제공하는 정답 데이터와 설계한 Loss Function을 이용해 모델에 Feedback을 주지만, 강화학습에서는 정답이라는 데이터를 제공하지 않은채, Agent 의 Action 에 대해 “오구 잘했어 5점”, “그건 좀 별론데? 1점” 과 같이 reward 로 feedback 을 제공합니다. Delayed Feedback, Not instantaneous Agent 의 지금의 결정(action)이 좋았는지/나빴는지가 몇 스텝 후에 나온다는 것이 특징입니다. Sequential, not i.i.d data (FYI) i.i.d : independent identical distribution (Random Variable 의 독립, 동일 확률분포) 강화학습의 데이터는 시계열적인(Sequential) 데이터 Agent’s actions affect the subsequent data Agent 의 행동이 reward와 received data 에 영향을 줍니다. EX) 로봇이 움직일 때마다 로봇이 보는 화면과 reward가 각각 달라집니다. 2. The Reinforcement Learning Problem2.1 Rewards reward $R_t$ : scalar feedback signal 시간 t 에서 agent 의 action (or 선택)이 얼마나 잘 한 것인지 나타내는 피드백 신호 agent의 목표 : 누적 reward의 최대화 (maximise cumulative reward) RL 은 reward hypothesis 위에서 이루어진다 Reward Hypothesis All goals can be described by the maximisation of expected cumulative reward 모든 목표는 누적 reward의 기댓값을 최대화 하는 것으로 잡을 수 있다. (아직 구체적으로 느낌은 오지 않음.. 과연 그런가..?) 2.2 Sequential Decision Making RL 은 결국 sequential decision making 이라고 표현 될 수 있다. sequential : 매 순간 t 에 대해서 decision making : agent 의 action 을 선택하는 과정 Agent의 Action 은 그 결과가 즉시 나오지 않을 수 있다. (may have long term consequences) Action 에 대한 Reward 역시 즉시 나오지 않을 수 있다. (reward ma be delayed) 지금, 이순간의 reward를 포기하고, long-term reward를 더 크게 하는 방향의 선택이 좋을 수 잇다. (Ex) Financial investment (take months to mature), refuelling a helipcopter (prevent a crash in several hours), blocking opponent moves (help winning chances many moves from now) 2.3 Agent and Environment ‘뇌’로 묘사되는 것이 Agent Our Goal: build on agent/algorithm Agent decides Action (EX: 모터의 Torque를 어떻게 설정할지, 로봇이 어떻게 움직일지 등) ❗️매 Step t 마다❗️ Agent는 action $A_t$ 를 수행 observation $O_t$ 를 받음 scalar reward $R_t$ 를 받음 Environment는 agent 가 수행한 action $A_t$를 받음 a에 대해 observation $O_{t+1}$ 로 반응 a에 대해 scalar reward $R_{t+1}$ 로 반응 t + 1로 다음 스텝 증가 2.4 History and State HISTORY DEFINITION: observation 과 action, rewards의 sequence $$ H_{t}=O_{1}, R_{1}, A_{1},…, A_{t-1}, O_t, R_t $$ ❓Q❓: 위의 정의에서 보면, $R_{t}, O_{t}$ 의 경우 $A_{t}$에 대한 reaction 입니다. 따라서 Ot, Rt가 나타나기 위에서는 At가 반드시 선행되어야 하는것 같은데, time step t 에서의 history Ht는 At 가 빠져있습니다. 왜일까요? Ot, Rt → At 가 순서이면 make sense 할 것 같습니다만;; Next step by current history: agent의 action environment 가 observation 과 reward를 결정 State DEFINITION: 다음 step 에 어떤 것을 할지 정하는 정보 보통, Function of History $$ S_{t} = f(H_{t}) $$ 2.5 State Environment State: $S_{t}^{e}$ David Silver “Information in the environment to determine what happens next” Environment’s private representation 보통 Environment State 는 agent 에게 보이지 않는다 Environment State 가 agent 에게 보인다 할지라도, irrelevant information 일 가능성이 크다 Agent State: $S_{t}^{a}$ $S_{t}^{a} = f(H_t)$ : Funtion of History RL algorithm에서 사용될 agent에 관한 정보 Information State (=aka Markov State) History 로부터 얻게되는 모든 유용한 정보 A state $S_{t}$ is Markov: Definition: $$ P[S_{t+1}|S_{t}] = P[S_{t+1}|S_1, …, S_{t}] $$ Markov Property의 핵심은 “미래의 State 는 현재 State에만 영향을 받는다” “미래의 State 는 과거 모든 State에 대해 독립적이다” Store ONLY current State (현재의 State가 이전의 history 정보를 담고 있으므로. RL 과 memory, Dynamic Programming 과의 연관성을 intuitively 이해할 수 있음) 헬리콥터 예제) 헬리콥터가 지금 바람을 맞을 때, 10분전 헬리콥터가 어떤 velocity 와 어떤 position 에 있었는지 중요하지 않다 2.6 Fully Observable Environments &amp; Partially Observable Environments Full observability : agent 가 directly environment state를 확인 할 수 있는 환경 environment state = agent state = information state $$ O_t=S_{t}^{a}=S_{t}^{e} $$ 보통 위 state 들은 Markov Decision Procee (MDP) Partial Observability : agent가 indirectly environment state 를 확인 할 수 있는 환경 agent ≠ environment state 보통 이를, Partially observable Markov Decision Process (POMDP) 라고 한다. 이 경우, agent 는 자신의 state representation $S_t^{a}$ 를 정해야한다. 다음은 경우에 따라 $S_t^{a}$를 정하는 방식이다. Complete History 의 경우 : $S_t^{a}=H_t$ Beliefs of environment state (Baysian Approach) : $S_t^{a} = (P[S_t^{e}]=s^1, …, P[S_t^{e}]=s^n)$ - Vector Probability에 의해 agent 의 next step 이 결정된다 Recurrent Neural Network (Probability를 사용하지 않고, 단지 agent에 숫자만 넣어주면 된다는 생각으로 network를 사용할 수 도 있다.) : $S_t^{a} = \\sigma(S_{t-1}^{a}W_{s}+O_{t}W_{o})$ MDP 와 POMDP 를 추후에 본 강의에서 다룰 수도 있겠지만, 그 내용의 중요도와 본 수업의 진행 방식에 따라 아래 강의도 함께 진행해도 좋을 것 같습니다. https://www.youtube.com/watch?v=uHEjez97BvE 3. Inside an RL Agent3.1 Major Components of an RL Agent Policy : Agent의 행동함수(behavior function) Value function : 각 state 와 action 이 얼마나 좋은지 나타내는 함수 (how much reward do we expect to get) Model : Agent 관점에서 바라보는 environment (agent’s representation) 위 세가지가 항상 모두 필요한 것은 아닙니다. 경우에 따라, 필요에 따라 구성하게 됩니다. 3.2 Policy Policy : Agent의 행동함수 Map from state to action Policy 의 종류 Deterministic Policy: $a = \\pi(s)$ - argmax Stochastic Policy: $\\pi(a|s) = P[A_{t}=a|S_{t}=s]$ 3.3 Value Function Value Function : Prediction of future Reward State 1 or 2 / Action 1 or 2 를 선택할 때의 기준이 됩니다. $v_{\\pi}(s)=E_{\\pi}[R_{t+1}+\\gamma R_{t+2}+\\gamma^{2}R_{t+3}+…|S_{t}=s]$ ($\\gamma$: discount factor - 더 먼 미래의 예측 reward 효과를 감소시키기 위함) 3.4 Model Model : Environment 의 행동을 예측 (Agent 의 관점에서의 행동방식이지, 실제 environment 의 행동방식이 아님) Transition Model $P$ : $P$ predicts the next state $$ P_{ss’}^{a} = P[S_{t+1}=s’|S_t=s, A_t=a] $$ Reward Model $R$ : $R$ predicts the next (immediate) reward $$R_s^{a}=E[R_{t+1}|S_t=s, A_t=a]$$ (Q) Trasition Model의 경우, Agent 관점에서 (Environment? ) state 를 예측 하는 것이라면, Policy 와의 역할 차이는 무엇일까? Policy와 Value Function 을 통해 agent 의 action 이 결정되고, 결정된 현재 action 에 의해 다음 state가 결정된다. 이렇게 볼때 Transition Model 과 Agent 간의 연결고리? TransitionModel과 Policy 간의 관계가 어떻게 되는지? Reward Model 도 마찬가지. 3.5 Maze Example Policy 아래 그림에서, 화살표→를 Policy라 생각할 수 있습니다. ⬜️ 를 state 라 생각할 수 있습니다. Agent 가 특정 ⬜️ 에 도착했을 때, → 를 따라 이동하는 것이 Action 이라 생각할 수 있습니다. Value Function 아래 그림은, 각 state 마다 value function 값을 적어놓은 것입니다. 특정 ⬜️ , 즉 state 에 도착했을 때, 다음 state(다음 action)을 결정 짓는 기준이 됩니다. $v_{\\pi}(s)$ Model Agent가 Modeling 한 immediate reward (실제 environment 가 아님) Dynamics : Action이 State 를 어떻게 변화 시키는지 (Q) 갑자기 어디서 튀어나온 terminology이죠? 강의 부분에서도 크게 언급을 안하였는데 Definition 처럼 표기를 해놨네요. Model 은 두가지라며… Rewards : 각 state마다 얼만큼의 reward 를 받는지 ** The Model may be IMPERFECT Grid Layout : Transition Model $P_{ss’}^{a}$ Numbers : Reward Model $R_s^{a}$ 3.6 Categorizing RL agents[Category 1] : RL Components(RL 구성요소) 중 Policy 와 Value의 저장 여부에 따라 다음과 같이 나뉩니다. Value Based No Policy Stores only Value Function Policy Based Stores only Policy No Value Function Actor Critic : Will cover Soon Stores both Policy and Value Function [Category 2] : RL Components(RL 구성요소) 중 Model의 유무에 따라 다음과 같이 나뉩니다. Model Free Policy and/or Value Function 의 유무는 크게 중요하지 않으나 (어느 하나라도 있으면 됨), No Model Model Based Policy and/or Value Function의 유무는 크게 중요하지 않으나 (어느 하나라도 있으면 됨), Model 4. Problems within Reinforcement Learning4.1 Reinforcement Learning Problem &amp; Plannning Problem Sequential Decision Making에서 2가지 Fundamental Problem이 있습니다. Reinforcement Learning Problem Environment 에 대해 알지 못함 (Agent 는 아무것도 모른채 그냥 던져짐) Agent 가 environment 와 상호작용을 함 이를 통해, Agent가 자신의 Policy를 발전시킴 Planning Problem Environment 의 Model 을 알고 있음 ( Agent 가 이 model 을 보고, Environment 에 대한 정보를 가지고 던져짐) Agent 는 위 Model 에 대해 computation 을 수행함 (그 어떤 다른 상호작용을 하지 않은채) 이를 통해, Agent가 자신의 Policy 를 발전시킴 aka deliberation (deliberative RL을 검색하니, 같은 hierarchy에 behavior-based architecture(행위 기반 에이전트구조), deliberative agent architecture(숙고형 에이전트 구조), hybrid agent architecture(혼합형 에이전트 구조)가 있으나, deliberation 이 어떤 것인지는 잘 모르겠습니다.) , reasoning, introspection, pondering, thought, search Atari Game 에서 Reinforcement Learning Problem 으로 바라볼 때, Atari Game 에서 Planning Problem 으로 바라볼 때, RL Problem 은 Agent의 Policy dependency 가 높다 → Model 을 의식하지 않고, Agent를 발전시키는 방향 Planning Problem 은 Model dependency 가 높다 → Model을 발전시키는 방향 결국 여기서, 얻을 수 있는 것은 같은 문제라 할지라도 우리가 문제정의를 어떻게 하느냐에 따라 Reinforcement Learning 연장을 사용할 때도 다양하게 해석되고, 다양한 문제 해결방식이 있는 것 같습니다. 4.2 Exploration &amp; Exploitation 결국, RL 은 trial-and-error learning 입니다. The agent 는 environment 에 대한 경험을 통해, Good Policy 를 찾고 발전시켜야합니다. 이 때의 제약 조건은 너무 오래 걸리지 않는 시간과 reward step이겠습니다. Exploration : finds more information about the environment Environment 에 관해 아무것도 알지 못하므로, environment 를 파악하기 위한 정보를 수집합니다. Exploitation : exploits known information to maximise reward 이미 알고 있는 정보 (Environment 에 관한 정보)를 바탕으로 reward를 최대화합니다. 아래 사진은 각 문제에 대해 Exploitation 관점과 Exploration 관점으로 살펴보았을 때의 그 문제 해결 방법이 달라지는 예시입니다. 4.3 Prediction and Control Prediction : Evaluate the future Given a policy Control : Optimise the future Find the best policy Agent 를 비롯한 RL system은 결국 Prediction 에서 Control 방향으로 넘어가는 개발단계를 취할 수 있습니다.","link":"/2023/06/04/20230604-rl-basic/"},{"title":"[Study] Model-Free Prediction","text":"본 글은 David Silver의 강의를 듣고서 정리한 글이다. 이번 강의는 model-free 구조를 살펴보는 강의이다. model-free?앞선 강의에서 state value를 계산하는 것들을 봤는데 이를 계산할 수 있었던 이유는 우리가 state transition probability라던지, policy라던지, reward가 어떻게 나오는지에 대한 probability를 알고 있기 때문에 가능했다. 오늘 강의에서는 우리는 주어진 environement에 대한 지식이 없고, 그저 agent가 겪게 되는 experience(episode)를 통해 주어진 environement에 대한 policy의 value를 추측하는 것이다. prediction?RL에서는 어느정도 evaluation과 interchangable하게 쓰이는 것 같다. 보통 policy evaluation을 prediction problem의 범주로 본다. ❗ problem의 범주는 보통 prediction, 그리고 control로 나누어진다. 오늘 배울 것들 Monte-Carlo (MC) Policy Evaluation Temporal-Difference (TD) policy evaluation TD($\\lambda$) policy evaluation =⇒ MC와 TD(0)의 사이 MC, TD, TD($\\lambda$), 그리고 DP와의 관계 Monte-Carlo policy evaluation특징 에피소드들로부터 배운다. ⇒ 모델을 정확히 몰라도 괜찮다.(Model-free) Complete episode들로부터 배운다. (episode가 진행되는 동안에 배우는 건 안된다.) 따라서 episode들은 terminate되어야 한다. (terminal state에 의해서든, 아니면 episode 최대 숫자를 통해서든) 여러 state transition을 겪은 reward들을 바탕으로 계산하는 평균 return을 바탕으로 value를 추정한다. 실제 evaluation 과정 주어진 policy에 따라 agent는 episode를 경험하게 된다. 이전에는 모든 경우에 수를 고려해 expected return을 구했었다면, 지금은 model에 대한 지식이 없으니 경험에 의존해서만 expected return을 구한다. 일단 episode를 시작하고, 주어진 policy에 따라 action을 취하면서 reward를 얻고, 이를 통해 $G_t$를 구할 수 있다. First-visit인지, Every-visit인지에 따라 어떤 state에 visit하면 해당 state의 count 값(N(s))을 올리고, visit할 당시의 $G_t$값을 S(s)에 누적해 준다. (First-visit이면 말그대로 처음 state에 도달했을 때만 위 계산을 해준다.) 모든 episode에 대해 위와 같은 계산을 끝마쳐주고 난 나뒤에 N(s)와 S(s)를 통해서 평균을 내준다. MC ExampleState sequence가 다음과 같이 주어졌다고 하자. (action과 reward는 생략) s1 → s2 → s3 → s4 → s2 → sF 여기서 s2의 state value를 구해보자. First Visit의 경우 Gt: (s2, s3, s4, s2, sF)를 통해 return을 구한다. N(s2)=1 Every Visit: Gt1: (s2, s3, s4, s2, sF)을 통해 return을 구한다. Gt2 : (s2, sF)을 통해 return을 구한다. s(s2) = Gt1 + Gt2 V(s2) = (Gt1 + Gt2)/2 Blackjack example솔직히 적당한 예라고는 생각되지 않지만 model-free에 대한 예제로 생각한다. Incremental MC update 우리가 어떤 값들의 평균을 구할 때, 맨 마지막에 한꺼번에 구할 수도 있지만 이전에 구해 놓은 평균을 이용해서 구할 수 있다. 마찬가지로 V(S) (return들의 평균)을 구할 때도, 이전에 구해 놓은 V(S) 값과 새롭게 얻게 된 $G_t$값을 이용해 구할 수 있다. 아래와 같이 특정 상수($\\alpha$)를 이용해서 이전에 구해놓은 평균과 새롭게 얻게 된 값을 어떤 식으로 이용할 것인지 weight를 고정해서 줄 수 있다. Temporal-difference (TD) policy evaluation특징 **(MC와 동일)**에피소드들로부터 배운다. ⇒ 모델을 정확히 몰라도 괜찮다.(Model-free) (MC와 상이) incomplete episode들로부터 학습할 수 있다. (bootstrapping) MC와 TD의 비교MC 실제 complete episode를 통해 알고 있는 $G_t$를 통해 업데이트 한다. TD(0) MC처럼 진짜 $G_t$값이 아닌 $G_t$의 estimator라고 할 수 있는 $R_{t+1}+\\gamma V(S_{t+1})$을 사용한다. $V(S_{t+1})$이 최종적인 값이 아니기 때문에 estimate인 것이다. 예전 $V(S_{t+1})$ 값을 사용할 수 있기 때문에 꼭 episode를 complete하지 않더라도 바로바로 업데이트할 수 있다. (online) ❗ TD에서 빨간 부분은 TD 뒤에 들어가는 숫자에 따라 달라진다. State value를 reward가 아닌 그 state에서부터 집까지 걸리는 예상 시간이라고 하자. MC 같은 경우에는 다음 state에서 뭐라고 새롭게 예측했던 상관없이 처음부터 끝까지 다 가본 다음, 실제 집까지 걸린 시간과, 그 state에서 예상한 걸린 시간의 차를 가지고 계산한다. TD 같은 경우에는 이전 state value를 업데이트할 때, 현재 state value만을 이용해서 업데이트한다. 현재 state value가 실제로 정확하던 아니던 상관이 없다. 반복하다 보면 맞아 갈테니까 MC vs TD (2)MC 에피소드가 끝나서 return을 알아낼 때까지 기다려야 된다. terminate가 꼭 필요하다. TD episode가 끝나지 않아도 매 step마다 업데이트가 가능 (online) 바로바로 배울 수 있으므로 꼭 episode가 끝날 필요는 없다. MC vs TD (3) - Bias/VarianceMC $G_t$=unbiased estimate of $v_{\\pi}(S_t)$ Zero bias $G_t$는 뒤에 많은 random variable이 따라오므로 variance가 높다. initial value에 덜 sensitive하다. TD “True” TD target = $R_{t+1}+\\gamma v_\\pi (S_{t+1})$=unbiased estimate of $v_\\pi (S_t)$ TD target = $R_{t+1}+\\gamma V (S_{t+1})$=biased estimate of $v_\\pi (S_t)$ TD target은 한가지 action값과 이미 정해진 V값에만 의존하므로 variance가 낮다. intial value에 sensitive하다. Random walk example 처음에 0.5로 value들이 initialize되어 있다가 계속 episode가 늘어날수록 true value(아마도 DP로 구했을 법한)로 수렴하는 것을 볼 수 있다. TD가 MC보다 더 빠르게 True value에 접근하는 것을 볼 수 있다. Batch MC and TD episode를 무한히 많이 늘리면 V(s)가 $v_{\\pi}(s)$에 가까워 지겠지만 실제로는 그렇게 할 수 없다. 그래서 finite한 k개의 episode 중에서 계속 sample해서 MC나 TD를 시행한다. AB example 보면 A의 경우에는 B가 0의 reward를 받는 episode 한가지만 겪고 있다. MC와 TD를 돌렸을 때 V(A)와 V(B)는 어떻게 될까? MC 같은 경우에는 $G_t$의 에러, 즉 episode의 전체 trace의 에러를 줄이려는 방향으로 solution을 만든다. TD 같은 경우에는 각 state의 에러를 줄이려는 방향으로 수렴하게 된다. Maximum-liklihood Markov model)을 만드는 것과 마찬가지다. (state transition probability distribution과 reward probabilty를 모델링함) Markov property를 적극 이용하는 셈: V(A) ~ R(A)+$\\gamma$V(B) Dynamic programming, Monte-Carlo, and Temproal-Differencepolicy evaluation process를 2가지 측면으로 나눠서 생각할 수 있다. Bootstrapping: estimate을 이용해서 state value를 update할 것인가 MC: 끝까지 episode를 진행한 후에 계산이 되므로 estimate를 쓰지 않음 ⇒ No bootstrapping DP, TD: 다음 번 state value esimtation을 가지고 현재 state value를 update를 한다. ⇒ Bootstrapping Sampling: 나올 수 있는 경우의 수를 전부다 쓸 것인가 그 중 하나만 sample해서 쓸 것인가 MC, TD: 나올 수 있는 모든 state transition을 고려하는 것이 아니라 episode에서 실제 발생한 것만 sample해서 쓰는 것이므로 ⇒ Sampling DP: 모든 state transition을 고려해서 update하므로 ⇒ No sampling Bootstrapping No bootstrapping No sampling DP Sampling TD MC TD($\\lambda$)n-step prediction 지금까지 봤던 TD의 경우에는 TD(0)로써 딱 현재의 step을 봤지만 여기에 변형을 주어서 n-step까지 활용하게 할 수도 있다. 이 n을 무한대로 늘려 놓은 것이 Monte-Carlo이다. 위의 그래프는 다양한 n-step을 이용했을 때의 RMS을 보여준다. 1이 TD이고, 숫자가 커질수록 MC가 된다. 주목할 점은 에러가 가장 작아지는 특정한 n이 존재한다는 점이다. Averaging n-Step returns 그렇다면 우리는 어떤 n을 써야할까? 이러한 점을 확실히 모르기 때문에 우리는 여러가지 n을 함께 써서 평균을 내는 방법으로 optimal n을 모르더라도 적당히 좋은 결과를 얻을 수 있다. 위의 에제에서는 n=2와 n=4를 함께 이용하였다. 그렇다면 몇 개의 n을 섞을 것이며 어떤 n들을 섞을 것인지 어떻게 정할 것인가? TD($\\lambda$) $(1-\\lambda), (1-\\lambda)\\lambda, (1-\\lambda)\\lambda^2, \\cdots$처럼 weight를 만들어서 각각의 Return estimate($G_t^{(n)}$)에 곱해준다. 그러면 몇개의 n-step을 섞어 넣던 weight들의 합이 1이 되게 된다. (당연히 1-step return이 가장 큰 비중을 차지하게 될 것이다.) Forward view and backward view of TD($\\lambda$) 결국 MC와 마찬가지로 TD($\\lambda$)를 계산하기 위해서는 다음 state들과 그에 해당하는 return들이 필요하다. 따라서 episode가 끝나야지만 계산할 수 있다. (이론적으로는 그렇다.) 하지만 실제로 TD($\\lambda$)를 구현할 때는 Eligibility Trace라는 것을 각 state마다 기록해서 필요한 정보가 나온 곳까지의 $G_t^{(\\lambda)}$까지 기록해준다. Eligibility trace라는 것은 위와 같이 계산할 수 있다. $\\gamma$에 의해서 episode가 진행됨에 따라 값이 서서히 줄어든다. (최근의 state visit에 더 가중치를 주는 Recency heuristic) 그리고 state visit마다 1씩 더해준다. (얼마나 자주 visit하는지에 가중치를 주는 Frequency heuristic) $\\lambda$에 따른 backward view와 forward view와의 관계 당연히 forward view는 모든 episode가 끝나야 완성이 되고, backward view와 같아지므로 onlie update일 경우에는 forward view ≠ backward view인 순간들이 있다. 위에서 쓴 Eligibility trace말고 변형을 사용하면 online일 때도 같다고 한다. 그러나 기본적으로 backward와 forward는 같아야 하고, $\\lambda=0$일 때는 TD(0), $\\lambda=1$일 때는 every visit MC와 equivalent하다.","link":"/2023/07/02/20230702-rl-model-free-prediction/"},{"title":"[Linux] AWK 간단 정리","text":"AWK 는 데이터를 다루는 사람들이라면 한번씩은 그 Command를 사용해봤을 것입니다. 저는 과거 Dataframe 을 생성해 본격적인 분석 및 연구.개발 작업이 들어가기 전에, AWK 를 통해 간단한 데이터 처리를 하는 경우, Raw Data 형식을 간단하게 정제하여 Database에 적재하는 경우에 사용해 왔습니다. 이 경우, 많이 사용하는 관용적인 구문외에는 AWK 자체를 살펴볼 기회가 적었습니다. 최근 사내에서 로그 데이터의 추출을 위해 AWK를 오랜만에 다시 사용하게 되면서, 잊었던 AWK문법을 다시 한 번 살펴보며, 이번 기회에 AWK의 간단 사용예제부터 AWK 문법 몇가지를 정리해보고자 합니다. AWK (Aho Weinberger Kernighan 오크) 스크립트 언어 텍스트 파일을 조회/필터링/가공 출력하는 프로그램 쉘스크립트 상에서 데이터를 간단히 처리할 수 있는 필수 프로그램 각 row data는 Enter(줄바꿈, newline)로 구분, column data는 공백, tab으로 구분 각 row data, 줄은 레코드(Record) 라 지칭 각 데이터, column, 단어 등은 필드(Field) 라 지칭 AWK 의 동작방식 필드 전체 : $0, 특정 필드 지칭 : $1 ~ (주의 : 0번이 첫번째가 아님!!) 기본적인 default 구분자는 **공백(Space, Tab)**이나, -F 옵션을 줌으로써 구분 기호를 지정가능 AWK command 형식 : awk {pattern} {action} filename pattern, action 둘 중 한 값만 있으면 됨 AWK 사용예제1. Column data 추출 각 Column 은 $1 와 같은 형태로 필드에 접근하여 추출 할 수 있습니다. 12345# awk {action} filename 형식awk '{print $1}' ./file_you_want.log# $0 전체 column 추출awk '{print $0}' ./file_you_want.log 2. 특정 Pattern : 정규표현식 문자열 중에 ADID 라는 글씨가 포함된 레코드를 출력해주는 커맨드입니다. 1awk '/ADID/' ./platform.log → 출력 예시 : 20211207 ADID1234556 123$456 device3 window AWK pattern에는 정규표현식을 사용할 수 있습니다. pattern내에 정규표현식 구분은 /regular expression/ (슬래쉬)로 이루어집니다. 1$ awk '/[A-Z][a-z]+/' ./system.log 3. AWK Command : if구문 특정 조건에 맞는 구문을 뽑을 때, 다음과 같이 사용할 수 있습니다. 다음은 3번 필드의 값이 1과 같을 때 전체 레코드를 뽑는 커맨드 입니다. 1awk '{if ($3 == 1) print ($0)}' ./system.log → 출력 예시 : 20211207 ADID123456 1 device3 window 20211207 ADID123654 1 device2 android 20211207 ADID654321 1 device1 ios 다음은 1번 필드가 20211206과 같고 3번 필드가 2이상인 전체 레코드를 뽑는 커맨드입니다. 이처럼, if 구문 안에 다양한 조건들과 &amp;&amp;(and) ||(or), !(not) 을 활용할 수 있습니다. 1awk '{if ($1 == 20211206 &amp;&amp; $3 &gt;= 2) print($0)}' ./system.log → 출력 예시 : 20211206 ADID123456 2 device2 window 20211206 ADID654321 3 device3 ios 20211206 ADID432561 4 device2 android ? , : 의 기능 : if-else 구문 if 구문 → $1 else $2 라는 뜻입니다. 12$ awk '{조건 ? $1 : $2}' ./system.log 4. AWK Command : for 구문 AWK 구문에서도 필요시 다음과 같이 for문을 사용할 수 있습니다. 1234awk '{for (i=0;i&lt;2;i++) print()}' 5. AWK BEGIN, END BEGIN과 END는 AWK 구문이 시작되기 전, 마친 후에 수행되는 커맨드입니다. 다음 커맨드는 {count++} 가 수행되기 전과 후에 Start, End 를 알리고, Count 를 세는 커맨드 입니다. 12345678910111213awk ' BEGIN { print(&quot;Begin Processing...&quot;) count = 0}{ count++} END { print(&quot;COUNT: &quot; count) print(&quot;End Processing&quot;)}' ./system.log' AWK 정의 변수 AWK 에서는 사용자의 편의를 위해 자체적으로 정의된 변수가 몇가지 있습니다. 미리 정의된 변수를 AWK command 안에서 다양하게 활용할 수 있습니다. 다음은 AWK에서 정의된 변수들중 많이 사용되는 몇가지를 추려보았습니다. 12345678910111213 ARGV : command line argument 배열ARGC : ARGV 배열 요소의 갯수 CONVFMT : 포맷팅 형식 (example: 숫자 포맷팅 형식) ENVIRON : 환경변수 배열 FILENAME : 파일 이름 (경로포함) FS : 필드 구분자 (default: space) NF : 필드의 갯수 NR : 현재 레코드의 순서 OFMT : 문자열 출력 형식 OFS : 필드 구분자 (default: space) ORS : 레코드 구분자 (default: newline) RLENGTH : match 함수에 의해 매칭된 문자열의 길이 RS : 레코드 구분 문자 (default: newline) 쉘파이프 안에서의 AWK 위의 사용예제들처럼 Linux CLI 환경에서 AWK command의 강력함은 확인 할 수 있었습니다. 이 외에도 쉘스크립트, 쉘파이프 안에서 AWK 를 활용하고, argument 를 전달하는지는 다음의 예제에서 확인 할 수 있습니다. AWK command 에서 argument를 넘겨 줄 때는 -v 옵션을 사용하여 넘겨 줄 수 있습니다. 123test_variable=&quot;hello&quot;$ echo | awk -v output=$test_variable '{ print &quot;TEST VARIABLE : &quot; output}'TEST VARIABLE : hello AWK command 를 상세하게 알고 싶다면, 그 동작 원리와 구조 또한 살펴볼게 많이 있습니다. 각자의 활용 정도에 따라 더욱 필요한 요소를 아래 reference 등의 자료를 통해 공부할 수 있을 것입니다. 이번 기회를 통해 짧게나마 AWK 를 정리 할 수 있었고, 활용 snippet code 를 남김으로써 다음 재사용시 빠르게 활용할 수 있을 것으로 기대됩니다. Reference AWK 내에 정의된 함수와 변수 등을 자세히 알고 싶다면, 다음 documentation 을 참조하실 수 있습니다. The GNU Awk User’s Guide 리눅스 awk 명령어 사용법. (Linux awk command) - 리눅스 파일 텍스트 데이터 검사, 조작, 출력.","link":"/2021/12/07/AWK-basics/"},{"title":"Basic Classification with Pytorch","text":"Basic Classification with Pytorch 이번 post 는 pytorch 를 활용해 기초적인 분류 모델링을 해보면서, pytorch에 익숙함을 높이는 것이 목적입니다. 123456789101112import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport numpy as npimport matplotlib.pyplot as pltimport warningswarnings.filterwarnings(&quot;ignore&quot;)%matplotlib inline%config InlineBackend.figure_format = 'retina' 1. Binary Classification Modeling Sigmoid Loss : Binary Cross Entropy 1.1 Generate Data123456789101112# plotting functiondef plot_scatter(W_, xy, labels): for k, color in [(0, 'b'), (1, 'r')]: idx = labels.flatten() == k plt.scatter(xy[idx, 0], xy[idx, 1], c=color) x1 = np.linspace(-0.1, 1.1) x2 = -W_[1] / W_[2] * x1 - W_[0] / W_[2] plt.plot(x1, x2, '--k') plt.grid() plt.show() 1234567# Generate dataW = np.array([-4./5, 3./4., 1.0])xy = np.random.rand(30, 2)labels = np.zeros(len(xy))labels[W[0] + W[1] * xy[:, 0] + W[2] * xy[:, 1] &gt; 0] = 1 1plot_scatter(W, xy, labels) 1.2 Train data Generate 한 data 로 부터, x 축 값, y 축 값, augmented term 으로 3가지 column 을 만들어 train data 로 만들어 줍니다. 또한 대응 되는 label 도 model 에 적합한 모양으로 바꾸어 줍니다. 1234x_train = torch.FloatTensor([[1.0, xval, yval] for xval, yval in xy])y_train = torch.FloatTensor(labels).view(-1, 1)print(x_train[:5])print(y_train[:5]) tensor([[1.0000, 0.0192, 0.6049], [1.0000, 0.0485, 0.2529], [1.0000, 0.2412, 0.9115], [1.0000, 0.9764, 0.1665], [1.0000, 0.9021, 0.5825]]) tensor([[0.], [0.], [1.], [1.], [1.]]) 1.3 Modeling Linear Model 형태와 Sigmoid 함수, Loss function 은 cross entropy 를 활용해 모델링을 합니다. 여기선, 내장되어있는 함수들을 되도록 사용하지 않고, Low level 로 코드를 작성해 보겠습니다. 12345678910111213141516171819202122# Low level modelingparameter_W = torch.FloatTensor([[-0.5, 0.7, 1.8]]).view(-1, 1)parameter_W.requires_grad_(True)optimizer = optim.SGD([parameter_W], lr=0.01)epochs = 10000for epoch in range(1, epochs + 1): # Prediction y_hat = F.sigmoid(torch.matmul(x_train, parameter_W)) # Loss function loss = (-y_train * torch.log(y_hat) - (1 - y_train) * torch.log((1 - y_hat))).sum().mean() # Backprop &amp; update optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1000 == 0: print(&quot;epoch {} -- loss {}&quot;.format(epoch, loss.data)) epoch 1000 -- loss 6.368619441986084 epoch 2000 -- loss 4.5249152183532715 epoch 3000 -- loss 3.654862403869629 epoch 4000 -- loss 3.122910261154175 epoch 5000 -- loss 2.7545464038848877 epoch 6000 -- loss 2.4800000190734863 epoch 7000 -- loss 2.2651939392089844 epoch 8000 -- loss 2.091233253479004 epoch 9000 -- loss 1.9466761350631714 epoch 10000 -- loss 1.8241318464279175 1parameter_W.data.numpy() array([[-16.748823], [ 16.618748], [ 17.622692]], dtype=float32) 아래 그림을 보면, Train이 잘 된 것을 알 수 있습니다. 1plot_scatter(parameter_W.data.numpy(), xy, labels) 2. Multiclass Classification2.1 Generate Data 이번에는 3개의 label 을 가지고 있는 classification 을 Modeling 해 보겠습니다. 또한, High Level 로 pytorch 의 추상 클래스를 이용해 모델링 해보겠습니다. 123456789101112def plot_scatter(W1, W2, xy, labels): for k, color in [(0, 'b'), (1, 'r'), (2, 'y')]: idx = labels.flatten() == k plt.scatter(xy[idx, 0], xy[idx, 1], c=color) x1 = np.linspace(-0.6, 1.6) x2 = -W1[1] / W1[2] * x1 - W1[0] / W1[2] x3 = -W2[1] / W2[2] * x1 - W2[0] / W2[2] plt.plot(x1, x2, '--k') plt.plot(x1, x3, '--k') plt.show() 123456789# Generate dataW1 = np.array([-1, 3./4., 1.0])W2 = np.array([-1./5, 3./4., 1.0])xy = 2 * np.random.rand(100, 2) - 0.5labels = np.zeros(len(xy))labels[(W1[0] + W1[1] * xy[:, 0] + W1[2] * xy[:, 1] &gt; 0)] = 1labels[(W2[0] + W2[1] * xy[:, 0] + W2[2] * xy[:, 1] &lt; 0)] = 2 1plot_scatter(W1, W2, xy, labels) 2.2 Train data1234x_train = torch.FloatTensor([[1.0, xval, yval] for xval, yval in xy])y_train = torch.LongTensor(labels)print(x_train[-5:])print(y_train[-5:]) tensor([[ 1.0000, 0.9641, 1.3851], [ 1.0000, -0.4445, 1.0595], [ 1.0000, 1.0854, -0.1216], [ 1.0000, 0.8707, 0.1640], [ 1.0000, 0.7043, 1.3483]]) tensor([1, 0, 0, 0, 1]) 2.3 Modeling1234567class MultiModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(3, 3) def forward(self, x): return self.linear(x) 1234567891011121314151617model = MultiModel()optimizer = optim.SGD(model.parameters(), lr=0.01)epochs = 10000for epoch in range(1, epochs + 1): y_hat = model(x_train) loss = F.cross_entropy(y_hat, y_train) optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1000 == 0: print(&quot;epoch {} -- loss {}&quot;.format(epoch, loss.data)) epoch 1000 -- loss 0.6635385155677795 epoch 2000 -- loss 0.5513403415679932 epoch 3000 -- loss 0.4890784025192261 epoch 4000 -- loss 0.44675758481025696 epoch 5000 -- loss 0.4151267111301422 epoch 6000 -- loss 0.39017024636268616 epoch 7000 -- loss 0.369760125875473 epoch 8000 -- loss 0.35262930393218994 epoch 9000 -- loss 0.3379631042480469 epoch 10000 -- loss 0.3252090811729431 2.4 Accuracy 계산 Accuracy 가 96 % 로 비교적 잘 분류 된 것을 확인 할 수 있습니다. 12accuracy = (torch.ByteTensor(model(x_train).max(dim=1)[1] == y_train)).sum().item() / len(y_train)print(&quot;Accuracy: {}&quot;.format(accuracy)) Accuracy: 0.96","link":"/2019/05/06/Basic-Classification-with-Pytorch/"},{"title":"[C++] 2.연산자(Operators)","text":"C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. 모든 연산자에 대한 리뷰보다는 조금 까다롭거나, 쉽게 잊을 수 있는 연산자 등을 위주로 정리하려고 합니다. 산술연산자(+, -, *, /, %, +=)/ : 나누기, 12345678910// 이 때, 정수와 정수간의 연산은 result 에는 2가 저장됨int result = 7 / 3;// 이 때, 나머지는 모듈러스 연산자로 계산int remain = 7 % 3;// 이 경우는, 에러는 발생시키지 않으나 warning sign 을 확인할 수 있음.// int type의 result에 float 혹은 double 형태의 연산값을 저장하기에 warning sign 발생int result = 7.0 / 3.0;// 이를 막기위해 작성자의 의도를 담아 TypeCasting 을 해주는 것을 추천int result = (int)(7.0 / 3.0); % : Modulus 나머지 연산자, Modulus는 argument 가 모두 정수여야 계산 가능. 실수간의 Modulus계산은 에러 += : a += 10 → a = a + 10 증감연산자(++, —)증감연산자는 정수의 경우 1을 더하거나 빼는 경우이지만, 포인터에서는 메모리 단위로 증가하는 것. 즉, 증감연산자는 unit 단위로 증가 또는 감소 하는 연산 ++ : a++ → a = a + 1, ++a → a = a + 1 — : a— → a = a - 1, —a → a = a-1 앞에 붙는 경우(전치)와 뒤에 붙는 경우(후치)는 연산의 우선순위가 변화. 후위는 우선순위가 가장 마지막, 전위는 우선순위가 먼저 수행. 1234567int result = 10;int a = 0;a = result++; // a=10, result=11result = 10;a = 0;a = ++result; // a=11, result=11 논리연산자(Booleans), !(not), &amp;&amp;(and), ||(or)true: 0이 아닌 모든 값, 일반적으로 1 false: 0 boolean 자료형: bool (true, false) 12bool istrue = true; // isture -&gt; trueint istrue_integer = true; //istrue_integer -&gt; 1 비교연산자(==, ≠, &lt;,&gt;, ≤,≥)== : equal ! =: not equal 삼항연산자간단한 if-else 문의 한줄 표현 1234567891011int a = 10;a == 10 ? a = true : a = false;//위 결과를 if else 문으로 표현하면 다음과 같다.if (a == 10){ a=true;}else{ a=false;}","link":"/2021/10/14/C-%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%89%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%A1-Operators/"},{"title":"[CS224n]Lecture01-WordVecs","text":"[CS224n] Lecture 1: Introduction and Word VectorsStandford University 의 CS224n 강의를 듣고 정리하는 글입니다. 1. Human Language and Word MeaningWord meaning 의 뜻 : symbol → idea or thing : Denotational Semantics 우리가 ‘의자’라는 단어를 예로 들자면, 말하는 사람과 듣는 사람 모두 의자와 관련된 특정한 이미지와 아이디어 등을 생각해 볼 수 있다. 이렇게 단어에 대해 관념적인 것을 word meaning 이라고 할 수 있다. 그렇다면 컴퓨터에서 사용할 수 있는 word meaning 은 어떤 것이 있을까? In Computer Word Representations WordNet: synonym 과 hypernyms 의 집합으로 표현 (e.g: nltk wordnet) 아주 귀한 dataset 이지만, 단점: Nuance (뉘앙스)를 담아내지 못함, 새로운 단어에 대해 사람이 직접 가공하여 추가해주어야 한다. 단어의 동의어에 대해 계산할 수 없음 Discrete Symbols: One-hot-vectors 단점 : 벡터의 차원이 우리가 가지고 있는 단어의 갯수만큼 커지게 된다. Corpus 의 구성 단어가 커질 수록 계산 해야하는 벡터 차원이 매우 커진다. 이는 컴퓨팅 자원의 부족으로 인한 현실적 구현의 어려움을 야기시킨다. One-hot-Vector 는 Vector Space 에서 모두 서로 orthogonal (직교)한다. 즉, similarity 가 모두 0으로 단어간의 관계를 알기 힘들다. By CONTEXT: Word Vecttors “You shall know a word by the company it keeps” (J.R.Firth) 어떤 특정 단어 w 가 나온다는 것은, 그 주변 단어들(context)이 있기 때문이다. Word Vectors == Word Embeddings == Word Representations == Distributed Representation 2. Word2vec IntroductionWord2vec(Mikolov et al. 2013) 은 Word Vectors 를 만들기 위한 알고리즘 중 가장 기초 뼈대를 이루는 알고리즘이다. 가지고 있는 텍스트 데이터를 구성하는 큰 CORPUS Corpus 의 모든 단어는 RandomVector 로 시작한다. 각 position t 에 대해, 중심단어 c(center) 와 주변단어 o(outside) 를 생각할 수 있다. 중심단어 c 가 주어질 때, 주변단어 o 의 확률을 구하기 위해(skip-gram)(반대로도 가능(cbow): 주변단어가 주어질 때, 중심단어의 확률을 구하는 방법), 중심단어 c 와 주변단어 o, word 벡터들에 대해 similarity를 구한다. 위의 확률을 최대화 하기 위해 word vector 를 updating 한다. 3. Word2vec objective function gradients문장의 특정 위치 t 에 대해 (t = 1, …, T), 중심단어w_j가 주어졌을때, 주변단어를 한정하는 window size m 에 대해 주변단어들을 예측하는 Likelihood 는 다음과 같습니다. likelihood 식을 해석해보면, 중심단어 w_t 에 대해 중심단어를 중심으로 window 사이즈 2m 개의 단어들의 확률을 모두 곱하고, T 개의 단어 갯수에 대해 또 다시 모두 곱합니다. $$Likelihood\\quad L(\\theta)= \\prod_{t=1}^{T}\\prod_{-m \\leq j \\leq m}P(w_{t+j}|w_{t};\\theta)$$ 목적함수는 likelihood 를 바탕으로 minimize와 average, 계산 편의를 위해 log 를 씌웠다는 것외에 likelihood 와 동일하다. $$objective function \\quad J(\\theta) = - \\frac{1}{T}logL(\\theta)=-\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{-m \\leq j \\leq m, j\\neq0}logP(w_{t+j} | w_{t};\\theta)$$ 단어가 등장할 확률을 구하는 방법은 Softmax Function 을 활용합니다. Objective Function 의 derivativeObjective Function 과 단어 확률 (Softmax) 의 미분을 구하는 과정이다.","link":"/2019/07/06/CS224n-Lecture01-Summary/"},{"title":"[CS224n]Lecture04-BackPropagation","text":"Lecture 04: Backpropagation and computation graphsStandford University 의 CS224n 강의를 듣고 정리하는 글입니다. 기본적인 computation graph 와 backpropagation 에 관한 내용은 스킵하도록 하겠습니다. 새롭고, 핵심적인 내용만 간추린 내용입니다. 1. Word Vector를 Retraining?Quetion: Retraining 에 대한 판단의 시작 예: TV, telly, television 이 pre-trained word vector 에서는 비슷한 공간에 분포되어있다고 가정할 때, training data 에는 TV 와 telly 단어만 존재하고, test data 에 television이 존재 할 때, word vector 는 어떻게 될 것인가? Answer: Training data 에 있는 TV 와 telly 에 해당하는 word vector 는 back prop을 진행하면서, 미세하게 업데이트 되며, 같은 방향으로 이동하게 된다. 반면, television에 해당하는 word vector는 weight parameter 업데이트가 일어나지 않으므로, 처음에는 비슷한 공간에 분포 했으나, TV 와 telly 와 멀어지게 된다. 1-1. Word Vector의 Retraining 여부 Word Vector가 학습 할 때는 매우 큰 데이터셋을 가지고 학습하게 된다. 따라서 매우 다양한 단어들이 Corpus 로 존재한다. Fine tuning?: 우리가 가지고 있는 training dataset 이 매우 작다면, 위에서 든 예에서 직감할 수 있듯이, pre trained vector 를 fine tuning 하게 되면, training set 에 fitting 되는 효과가 있고, 우리가 의도치 않는 weight 의 업데이트가 되거나 혹은 되지 않을 수 있다. 2. 효율적인 gradient 계산 사실 당연하게 여김에도, 우리가 손으로 계산하는 (upstream network * local gradient) 과정을 아래 식에서도 확인 할 수 있듯이, ds/dh, dh/dz term 은 중복되는 과정이다. $$\\frac{ds}{dW}=\\frac{ds}{dh}\\frac{dh}{dz}\\frac{dz}{dW}$$ $$\\frac{ds}{db}=\\frac{ds}{dh}\\frac{dh}{dz}\\frac{dz}{db}$$ 따라서 효율적인 computation을 구현하기 위해서, back propagation에서 upstream network 를 저장하고, 각 parameter 에 대한 local gradient를 구해, 동시에 곱해주어 back prop 을 진행 할 수 있다. 3. Regularization우리가 parameter 가 많아지면 많아질 수록, training error 와 test error 는 낮아지기 마련이다. 하지만, 어느 수준을 넘어가게 되면, training set 에 대해서는 매우 정확해지는 반면, test data(validate data)에 대해서는 generalization에서 실패한 그래프나 수치들을 확인할 수 있다. 따라서, 우리는 반드시 우리가 최적화 하려고 하는 Loss 에 대해 Regularization 을 해주어야만 한다. 다음은 L2 Regularization term 이 추가된 loss function 이다. 지겹도록 바왔음에도, 꼭 식을 보면 해석해야겠기에, Model parameter (weight) theta 가 제곱term 으로 너무 커지는 것을 방지하기 위해 lambda 에 비례하여 penalty term 을 추가한다. 4. Vectorization우리가 forward/backward propagation 을 진행하면서, 각 data의 계산을 looping 하여 계산한다면, 매우 비효율적인 계산 방식이 된다. 우리는 위대한 Vecor/Matrix Multiplication 방법으로, 즉, 모든 data 와 weight을 행렬로 만들어 forward/backward 계산을 진행해야한다. 또한 이렇게 진행했을 때, 가속화 도구인 GPU 활용의 이점을 사용할 수 있다.","link":"/2019/08/09/CS224n-Lecture04-Summary/"},{"title":"[C++] 1.자료형(DataTypes)","text":"C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. 1. C++ 의 주석1// 주석 2. C++ 의 자료형, DataType자료형s정수형 : char 1byte, short 2byte, int 4byte, long 4byte, long long 8byte 등 실수형 : float 4byte, double 8byte 등 평소엔 : signed int, signed 는 생략 (-128 ~ 127) MSB 0 000 0000 (2) : MSB - Most Significant Bit for sign 양의 값만 할당 : unsigned int (0 ~ 255) unsigned 값에 256 을 할당하면? bit: 1111 1111 (2) + 1 (2) = 1 0000 0000 → 0으로 생각 (overflow) unsigned 값에 -1 을 할당하면? bit: 1111 1111 (2) = 255 (10) (-1의 정의는 1을 더했을 때 0이 되는 값으로 정의하므로 1111 1111로 표현되며(2의보수법), 이는 unsigned의 컴파일 결과 255로 표현된다) 실수표현방법: 부동소수점 방식 부동소수점 방식으로 소수와 실수를 표현하는 것은 글로 정리하는 것이 오히려 혼란을 야기할 수 있으므로, 추후에 필요하다면 손으로 쓴 풀이를 정리해보겠습니다. 참고: 부동소수점 위키백과 정수와 실수의 메모리 저장 방식은 각가 다른 것이 중요 따라서 정수와 실수간의 연산 방식은 기존의 연산방식은 다름 float 과 double 을 적절히 활용하여 실수값의 범위에 따라 사용 TypeCasting(형변환)서로 다른 자료형끼리 연산은 되도록 자제해야하지만, 어쩔수 없이 수행해야만 하는 순간이 있기 마련이다. C++ 에서는 Python과 달리 compiler 에 의존하는 경우가 많기 때문에 TypeCasting 을 의식적으로 해주는 것이 코드 가독성과 예측성을 높이는 방법이다. TypeCasting 을 해주지 않아도, 실제로는 compiler 가 강제적으로 형변환하여 연산하지만, 이는 의도와 다른 결과를 만들어내 실수할 수 있는 여지를 많이 남기는 것이다. 습관처럼 예상하고 필요시 꼭 casting 하도록 하자. 1234int int_number = 5float floating_number = 3.0//Type Castingfloat result = floating_number + (float)int_number","link":"/2021/10/13/C-%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD%E1%84%92%E1%85%A7%E1%86%BC-DataTypes/"},{"title":"[CS231n]Lecture02-Image Classification Pipeline","text":"Lecture 02: Image Classification Pipeline 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. Image Classification 의 기본 TASK 위 사진을 보고, → ‘CAT’ 혹은 ‘고양이’ 라고 classification 자연스럽게 따라오는 문제는 “Sementic Gap” : 우리가 준 data (pixel 값 [0, 255]) 와 Label 간의 gap 또한, 이 과정에서 극복해야 하는 Challenges Viewpoint Variation ( 같은 객체에 대해 시점이 이동해도 robust) Illumination ( 빛, 밝기, 명암 등에도 robust) Deformation ( 다양한 Position, 형태의 변형에도 robust) Occlusion ( 다른 물체나 환경에 의해 가려지는 data 에도 robust) Background Clutter ( 배경과 비슷하게 보이는 객체에도 robust) Intraclass Variation ( 한 종류의 클랫스에도 다양한 색과 모습의 객체가 있을 수 있다.) 2. 기존의 시도와 New Era Hard Coded Algorithm 과 여러 규칙 (rule-based로 해석된다) 들을 통해서 Image를 Classify 하는 노력들이 있어왔다. 이들의 문제는, (1) 위에 언급한 문제들이 Robust 하지 않다. (2) 객체가 달라지면, (고양이, 호랑이, 비행기 등) 객체마다 다 다른 규칙을 성립해줘야 한다. 즉 한마디로 요약하자면, Algorithm의 확장성이 없다. 이런 문제에 좀더 강한 방법이 지금 우리가 공부하고 있는, Data-Driven Approach Image 와 Label pair 의 dataset 을 모은다. Machine Learning 알고리즘을 이용해 classifier 를 학습시킨다. Classifier 를 new images 에 테스트에 평가한다. 3. First Classifier : Nearest Neighbor3-1. Nearest Neighbor 의 기본 알고리즘 train set 에서의 모든 data 와 label 을 기억한다. test Image 와 가장 가까운 train Image 의 label로 test image를 predict 한다. 이 때 ‘가장 가까운’ 을 계산 할 때**, L1 distance** 와 L2 distance 가 쓰일 수 있다. 이 외에도, 다양한 distance 지표가 쓰일 수 있다. 3-2. Nearest Neighbor Classifier 의 문제 이미지 classification 에는 잘 사용되지 않는다. train 보다 predict 하는데 훨씬 오래 걸린다. train 은 train data set 의 기억만 하면 되지만, predict 할 때는 전체 train data 에 대해 거리를 측정해야하고, sorting 해야하는 문제가 발생한다. Time Complexity - train O(1), predict O(N) (N은 train data 수) 위 그림을 보면, 연두색 공간에 노란색 class 가 포함 되어 있는 것을 볼 수 있다. 이는 generalize 면에서 부족한 모델이라고 볼 수 있다. 같은 알고리즘 이지만, 이를 해결 하는 방법은 K 개의 가까운 neighbor 로 부터 majority voting 을 받은 것으로 classify 를 하는 것이다. 3-3. K-Nearest NeightborsSingle Nearest 만 보는 것이 아니라, K 개의 가까운 point 의 투표를 통해 해당 test data 의 label 을 예측한다. 이 때, Voting 하는 방법에는 majority voting ( 다수결 ) 과 weighted voting ( 가중치를 주어 투표: distance 가 가까운 것에 가중치를 준다.) 가중치를 주는 방법에는 distance 가 커지면 곱해지는 weight 을 줄이는 방법으로 1 / (1+distance) 등을 weight 을 곱해준다. 3-4. k-Nearest Neighbor on images NEVER USED 차원의 저주 문제 knn 이 잘 동작하기 위해서는 dataset 공간을 조밀하게 커버할 만큼의 충분한 training space 가 필요하다. 하지만, data 의 차원이 늘어날 수록 그 충분한 data 의 수가 exponential 하게 늘어난다. 4. Setting HyperparametersModel 최적의 hyperparameter 를 찾기 위해서는 data set 을 구분하여, unseened data 를 사용하여 성능 검증을 하고, model selection 을 해야한다. 이는 단순이 hyperparameter 를 찾는 용도 뿐만 아니라 우리가 세운 가설을 서로 비교 할 때는 data set 을 정확히 구분하고, test set 을 통해 비교하고, 선택해야한다. 그 방법에는 train, validation, test set 으로 dataset 을 나누는 방법과 cross validation 방법이 있다. 첫 번째 방법으로는, Validation set 을 통해 hyperparameter(가설)를 검증하고 선택하여, Test set 을 사용하여 Evaluate 과 Reporting 등을 한다. 딥러닝 모델링에서는 이 방법으로 많이 사용한다. 두 번째 방법은, data set 의 크기가 크지 않을 때, Train set 안에서 folds 들을 나누어 각 fold 가 돌아가며 validation set 이 되며, 이들의 평균값으로 가설을 비교한다. 이는 딥러닝 모델에서는 적합하지 않은 형태이다. 모델 자체의 연산이 많은데다가, 같은 모델에 대해 많은 validation 이 효율적이지 않기 때문이다. 또한 data가 많지 않은 상태에서 딥러닝 모델을 선택하는 것은 옳지 않다. 5. Second Classifier : Linear ClassifierLinear Classifier 는 Neural Network 의 기본 골격이다. (1) image data 와 W (parameters or weights) 을 통해 연산을 해주고, (2) function 을 통과해 Classification 을 해준다. 특히 Linear Classifier 의 경우 아래 와 같이, (1) image data 와 W 를 dot product 를 해주고 (2) linear function f 를 통과한다. $$f(x, W) = Wx$$ 6. ReferenceLecture 2 | Image Classification Syllabus | CS 231N","link":"/2019/05/13/CS231n-Lecture02-Summary/"},{"title":"[CS231n]Lecture03-LossFunction&#x2F;Optimization","text":"Lecture 03: Loss Function &amp; Optimization 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. Introduction Loss Function : 우리가 가지고 있는 W matrix 가 얼마나 안좋은지 정량화(Quantify) Optimization : 위의 Loss Function 을 minimize 해서 가장 좋은 parameter (W) 를 찾는 과정 2. Loss Function주어진 data 가 다음과 같을 때, $${(x_i, y_i)}_{i=1}^{N}$$ Loss 는 “Average of over examples” 즉, $$L = \\frac{1}{N}\\sum_{i}L_i(f(x_i, W), y_i)$$ 딥러닝 알고리즘의 General Setup W 가 얼마나 좋고, 나쁜지를 정량화하는 손실함수 만들기 W 공간을 탐색하면서 이 loss를 minimize 하는 W 를 찾기 2-1. Loss Example: Multiclass SVM LossSVM Loss 는 다음과 같다. 주어진 data example (x_i, y_i) 에 대해서, score vector s 는 다음과 같다. $$s = f(x_i, W)$$ 이 때, SVM loss는 $$L_i = \\sum_{j\\neq y_i}\\begin{cases} 0 \\quad\\quad\\quad\\quad\\quad\\quad\\quad if ;s_{y_i} \\geq s_j +1 \\ s_j - s_{y_i} + 1 \\quad\\quad otherwise \\end{cases} \\ = \\sum_{j\\neq y_i}max(0, s_j-s_{y_i}+ 1)$$ x_i 의 정답이 아닌 클래스의 score (s_j) + 1 (safety margin) 과 정답 클래스 score s_yi 를 비교하여, Loss 를 계산한다. SVM Loss 의 최대, 최솟값은 ? min : 0, max : infinite W 를 작게 초기화 하면, s 가 거의 0에 가까워 진다. 이 때, SVM Loss 는 어떻게 예상되는가? 정답이 아닌 class, 즉 class - 1 개의 score 원소들을 순회하면서 모두 더할 때, score 는 0에 가깝고, 이를 average 취하면 class 갯수 - 1 만큼의 Loss 값이 나온다. 이 특징은 debugging strategy 로 사용할 수 있다. 초기 loss 가 C-1 에 가깝지 않으면 bug 가 있는 것으로 의심해볼 수 있다. 만약 include j = y_i 이면, SVM Loss 는 어떻게 되는가? Loss Funtion 이 바뀌는 것은 아니다. 단지 전체 loss의 minimum 이 1이 될 뿐이므로 해석의 관점에서 관례상 맞지 않아 정답 class 는 빼고 계산한다. 우리가 average 를 취하지 않으면? 이 역시 바뀌는 것이 없다. 전체 class 수는 정해져 있고, 이를 나누는 average 는 scaling 만 할 뿐이다. Loss 를 max(0, s_j - s_yi + 1) ^2 를 사용하면? 이는 squared hinge function 으로 때에 따라서 사용할 수 있는 loss function 이다. 다른 Loss function 이며, 이는 위의 loss 와 다르게 해석 할 수 있다. 기존의 SVM loss 는 class score 가 각각 얼마나 차이가 나는지에 대해서는 고려하지 않는 것이라고 한다면, squared 가 들어감으로써, 차이가 많이 나는 score class 에 대해서는 좀더 가중하여 고려하겠다는 의미로 해석 할 수 있다. 2-2. Regularization만약 위 Loss Function 에 대해서, L = 0 으로 만드는 W 를 찾았다고 할때, 과연 이 W 는 유일한가? 그렇지 않다. W 일 때, L=0 이라면, 2W 역시 L=0 이다. 또한 L을 0으로 만드는 다양한 W 중에서 단지 training data 에만 fit 하는 classifier 를 원하는 것이 아니라, test data에서 좋은 성능을 발휘하는 classifier 를 찾기를 원한다. 이런 Overfitting 을 막기 위해서는 모델의 W 를 다른 의미에서 조절해줄 수 있는 Regularization term 을 추가할 수 있다. 즉, Model이 training set 에 완벽하게 fit 하지 못하도록 Model 의 복잡도에 penalty 를 부여하는 것을 말한다. Regularization 의 종류들: L2 Regularization L1 Regularization Elastic net(L1 + L2) Max norm Regularization Dropout Batch normalization, stochastic depth 2-3 Loss example: Softmax Classifier (Multinomial Logistic Regression)deeplearning 에서 훨씬 더 자주 보게 되는 loss 의 종류 중 하나이다. 위에서 살펴본 SVM loss 의 단점은 그 값 자체에 어떤 의미를 부여하기는 힘들다는 점이다. 반면에, Softmax Classifier 는 그 값 자체를 확률적 해석이 가능하기 때문이다. (cf. 콜모고로프의 공리를 통해 softmax 의 layer 의 output 이 확률로 해석 될 수 있다.) Softmax Function 은 다음과 같다. $$P(Y=k|X=x_i) = \\frac{e^{s_k}}{\\sum_j e^{s_j}},\\quad where \\quad s = f(x_i;W)$$ 3. OpitmizationOptimization 을 한마디로 요약하자면, 우리의 loss 를 최소화 하는 W 를 찾기 가 되겠다. 그 방법에는, (바보 같은 접근인: 강의표현) Random Search Gradient 를 구하는 방법 Numerical Gradient 수치적 접근 : 이 방법은 근사치를 구하는 것이며, 매우 느린 단점이 있다. 하지만, 쉽게 작성할 수 있다는 장점이 있다. Analytic Gradient 해석적 접근 : 미분식을 구해야하는 단점이 있다. 하지만 빠르고 정확하다. 실제로는, Analytic Gradient 방법을 사용한다. 하지만 debugging 을 위해 numerical gradient 를 사용한다. 이를 gradient check이라 한다. 3-1. Gradient Descent &amp; Stochastic Gradient DescentGradient Descent 를 방법을 이용해서 optimization 을 진행할 수 있다. 하지만 데이터의 숫자와 차원이 매우 큰 경우, parameter (W) 를 update 하는데 그 연산량이 매우 큰 단점과 위험이 있다. 이를 해결하기 위해 minibatch 를 사용하여 확률적 접근을 사용한다. 4. Image Feature ExtractionCNN 등이 등장하기 전에 Image 에서 Feature 를 뽑아내는 방법에 대해 소개한다. Feature를 뽑아내는 개념으로 생각할 수 도 있지만, Feature Transform 이라는 표현을 사용한다. Color Histogram : 이미지의 color distribution 을 사용하여 해당 이미지의 feature 로 사용할 수 있다. (출처: wikipedia ) For digital images, a color histogram represents the number of pixels that have colors in each of a fixed list of color ranges, that span the image’s color space, the set of all possible colors. Histogram of Oriented Gradients (HoG) : CNN 이 등장하기 전, 매우 인기있는 Image Feature 중 하나라고 알고 있다. Edge 를 검출하는 방법이다. pixel 사이에, 값의 gradient 가 가장 큰 neighbor 가 edge 일 것이다라는 개념을 사용하여 edge 를 검출한다. 사진을 8 x 8 patch 를 만들어, 각 patch 마다 9 directional oriented gradients 를 계산하여, 이를 feature 로 사용하는 방법이다. Bag of Words : NLP 에서도 자주 사용되는 개념인 BoW 에서 차용한 개념으로, 이미지 데이터들에서 일정 크기의 patch 를 모아 clustering 을 통해 visual words (codebook) 을 만든다. 그리고 feature 뽑아내고 싶은 image 를 patch 형태로 바꾸고, codebook 에서 찾아 histogram 을 만들어 이를 feature 로 사용한다. 5. ReferenceLecture 3 | Loss Functions and Optimization Syllabus | CS 231N","link":"/2019/05/16/CS231n-Lecture03-Summary/"},{"title":"[CS231n]Lecture05-CNN","text":"Lecture 05: Convolutonal Neural Networks 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. Convolution Layer1-1. Fully Connected Layer 와 Convolution Layer 의 비교32 x 32 x 3 image 가 있다고 하자. network 에 주입하기 위해, 1 x 3072 로 핀 data 를 상상해 보자. Fully Connected Layer 의 경우, 아래 그림 처럼, Weight 과 dot product 가 수행되어, activation 값이 나오게 된다. 이 때, activation 의 갯수는 W 의 크기에 따른다. Fully Connected Layer 의 경우, 사진이라는 공간적 구조(Spatial Structure) 가 중요한 data 에 대해, 공간적인 정보를 다 잃어버리는 문제가 발생한다. 공간적 정보를 보존하기 위해 Convolution Layer 를 사용한다. 1-2. Convolution Layer Overview 이 때, 실제 convolution 계산은 image 의 filter 크기 만큼의 matrix 를 vectorize 한 후, filter vector 와 dot product 로 수행한다고 한다. 따라서 이 때 헷갈리지 않도록 할 것은, 한번의 Convolution 연산 결과는 하나의 scalar value 가 된다. 따라서, 하나의 filter 가 이미지 한 장을 훑어 내려간다면, 원본 이미지보다는 조금 작은 depth 가 1인 activation map 이 결과로 나온다. 따라서 activation map 의 깊이(channel 수)는, filter 의 갯수 와 동일하다. 여러개의 필터는 이미지의 각기 다른 특징을 추출하려는 의도에서 사용된다. 그 후, 이 Convolution 의 결과인 activation map 을 비선형 함수(ReLU 등)에 통과 시킨다. 여러 유명한 ConvNet 들은 이렇게, Convolution Layer 와 비선형함수를 반복적으로 나열 한 Network 라고 볼수 있다 1-3. Convolution Layer 의 결과물이렇게 여러 계층의 Convolution Layer를 쌓는 것은, 가장 아래 Layer 부터 높은 Layer 까지 단순한 feature → 복잡한 feature 를 뽑아 내는 것으로 볼 수 있다. 1-4. Convolution Layer 연산 filter 가 이미지를 훑고 지나가면서 convolution 연산을 한 후, 나온 결과는 원본 이미지보다 그 크기가 작아지게 된다. 그 정도는 filter 의 크기와 filter 가 훑고 지나가는 간격인 stride 에 따라 바뀌게 된다. $$output ;size = (N-F)/stride + 1$$ 문제점: convolution 연산의 문제는 이미지의 모서리에 있는 정보는 가운데에 있는 이미지의 정보보다 적게 추출 되는 문제가 있다.(filter 가 모서리를 넘어서는 이동 할 수 없으므로) convolution layer 를 반복적으로 지나가다 보면, map의 크기가 매우 빠르게 작아지게 된다. 이를 위해 적용하는 것이 Padding 이다. 1-5. Padding모서리에 정보를 얻기 위해 이미지이 외곽에 숫자를 채워 주는 방법. 이 때, 많이 사용하는 방법은 zero-padding. zero-padding 외에도 다양한 방법이 있다. 2. Pooling LayerParameter 의 갯수를 줄이기 위해, 우리가 ConvLayer 를 통해 뽑아낸 image 를 작게 만드는 Layer 이다. 즉, Downsampling 을 위한 것. Maxpooling 의 intuition : 앞선 layer filter 가 각 region 에서 얼마나 활성 되었는지 보는 것이다. 3. Typical Architecture[[(Conv → RELU) * N → Pool] * M → (FC → RELU) * K ] → SOFTMAX N : ~ 5 M : Large K : 0 ~ 2 ResNet, Google net 등은 이 방식을 훨씬더 뛰어넘음 4. ReferenceLecture 5 | Convolutinoal Neural Networks Syllabus | CS 231N","link":"/2019/05/20/CS231n-Lecture05-Summary/"},{"title":"[CS231n]Lecture07-Training Neural Networks part2","text":"Lecture 07: Training Neural Networks part2 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. Fancier Optimization1-1. Problems with SGD Loss function 의 gradient 방향이 고르지 못해, 지그재그 형태로 업데이트가 일어나고, 그 업데이트가 느리게 발생된다. 고차원으로 갈수록, 자주 만날 수 있는 문제. Local Minima &amp; Saddle point: 높은 차원에서 생각해보면, Local Minima 는 고차원의 모든 gradient 방향에 대해 전부 loss 가 증가하는 방향이므로, 이 경우보다는 Saddle point 문제가 훨씬더 빈번하게 발생한다. Saddle point 의 경우 그 포인트 자체도 문제지만, 그 근처에서 gradient 가 매우 작기 때문에 update 를 해도 매우 느린 문제가 있다. SGD 의 S - stochastic! : 미니 배치의 loss 를 가지고 전체 training loss 를 추정하는 것이므로, 노이즈가 포함된 추정일 수 밖에없다. 1-2. 다양한 최적화 알고리즘 기법최적화 알고리즘은 간단하게 정리한다. SGD, SGD + Momentum, Nesterov Momentum : 진행방향과 그 gradient (Momentum) 을 더해 실제로 업데이트 될 방향을 정한다. AdaGrad : 이전에 진행했던 gradient 를 제곱하여, 업데이트가 진행 될 수록 학습률을 작게해, 세밀하게 업데이트한다. RMSProp : AdaGrad 가 gradient 를 제곱할 때, 학습의 후반부에 갈수록 gradient 가 0 에 가까워 지게 되므로, 제곱하는 term 의 비율을 설정해 0으로 가는 것을 막는다. Adam : Momentum 방법과 AdaGrad를 합친 방법으로써, 학습률을 조절하면서, 속도를 조절하는 방법이다. 2. Regularization2-1. Dropout앞선 강의에서 다양한 Regularization 방법들을 살펴 보았었다.L2, L1, Elastic Net 등. 이번 강의에서는 신경망에서 자주 사용되는 dropout 방법을 살펴본다. Dropout 이란 forward 진행시, 일부 뉴런을 0으로 만들어 버리는 것을 말한다. dropout layer 는 우리가 그 dropout rate 을 설정하므로써, 어떤 확률로 꺼질지 설정할 수 있다. dropout 은 먼저 각 뉴런이 서로 동화되는 것을 방지함으로써 다양한 표현방식을 지닐 수 있게 한다. 또한, dropout 은 여러 sub model 을 앙상블 하는 효과를 낼 수 있다. Dropout Layer 를 사용할 시 주의 할 점은 evaluation, inference 시, 네트워크의 출력에 dropout 확률을 곱해주어야 한다는 점이다. 혹은 test 시에는 기존 출력을 그대로 사용하고, train 할 때 dropout확률로 나눠주는 방법이다. (keras 에는 후자로 구현되어있는 듯 하다.) p.s. Batch Normalization 에 regularization 의 효과가 있으므로, 일반적으로 BN 과 dropout 을 같이 사용하지는 않는다. 하지만 dropout 에는 우리가 조절할 수 있는 dropout rate 이 있는 장점이 있다. 2-2. Data Augmentation신경망은 기본적으로 데이터가 많으면 많을 수록 학습에 유리한 이점이 있다. 따라서 우리가 가지고 있는 데이터를 조금씩 변형하여, 학습 데이터를 늘려주는 방법을 사용할 수 있다. horizontal flip이나, 사진에 일부분을 자르는 방법, Color jittering(이미지의 contrast, brightness 를 변형해준다) 2-3. Drop ConnectActivation 이 아닌, weight 을 확률적으로 0을 만들어 주는 방법 2-4. Fractional Max Pooling고정된 Pooling window 를 랜덤으로 정하는 방법. 자주 사용되지는 않는다. 3. Transfer Learning유명한 모델과 깊은 네트워크는 대부분 많은량의 데이터와 많은 하드웨어 Resource와 시간이 투입되서 구축된다. 우리가 이 모델구조를 가져와 우리의 목적에 맞게 사용하려고 보면, 우리가 가지고 있는 데이터와 자원의 한계로 학습에 실패하거나 그 시간이 매우 오래 걸리곤 한다. Transfer Learning 은 기존에 학습되어있는 모델 구조와 그 weight 을 가져와, 마지막 Fully Connected Layer 를 우리의 task 에 맞게 수정하고 이 부분만 학습하는 개념을 말한다. 4. ReferenceLecture 7 | Training Neural Networks II Syllabus | CS 231N","link":"/2019/07/22/CS231n-Lecture07-Summary/"},{"title":"[CS231n]Lecture04-Backprop&#x2F;NeuralNetworks","text":"Lecture 04: Backpropagation and Neural Networks 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. Backpropagation1-1. 핵심Backprop의 한줄요약: 각 parameter 에 대해 Loss Function 의 gradient 를 구하기 위해 사용하는 graphical representation of ChainRule 언뜻 보면 어려울 수 도 있지만, just ChainRule 위의 그림을 예를 들어 살펴 보면, y 에 대한 f의 gradient 는 q에 대한 f의 gradient * y 에 대한 q 의 gradient 으로 볼 수 있다. 이를 해석하자면, f 에게 미치는 y 의 영향 = f 에게 미치는 q의 영향 * q 에게 미치는 y 의 영향으로 볼 수 있다. Backpropagation 의 가장 중요한 특징!! gradient 를 구하기 위해 node 를 기준으로 앞과 뒤만 보면 된다. 또한, 위 그림을 보게 되면, Forward passing 과 마찬가지로, Backprop 시에도, 이전 노드에서 전달 되는 Gradient 를 node 에서 local gradient 와의 연산으로 다음 Node 에 gradient 를 전달해 줄 수 있다. 1-2. Back prop 시, 각 node 의 역할 Add gate : gradient distributor add gate 를 기점으로, 각 입력(forward 방향의 입력)의 gradient로 local gradient 를 구하면 1이므로, 전달 되는 gradient 와 각각 1씩 곱해져 전달 되게 된다. 이 현상을 보게 되면 동등하게 나눠주는 역할을 하므로 gradient distributor 라고 볼 수 있다. Max gate : gradient router Max gate 는 gradient 를 한쪽에는 전체, 다른 쪽에는 0 을 준다. 해석적으로 보자면, max 연산을 통해 forward 방향에서 영향을 준 branch 에게 gradient 를 전달해 주는 것이 합적 $$max(x, y) = \\begin{cases} x \\quad\\quad if \\quad x &gt; y \\\\ y \\quad\\quad if \\quad x &lt; y \\end{cases}$$ 수식으로 보자면, x 에 대한 gradient, y 에 대한 gradient 가 각각 (1, 0), (0, 1) 로 local gradient 가 계산되기 때문이다. gradient 가 전달될 길을 결정해주는 면에서, 네트워크에서 path 를 설정해 주는 router의 기능과 비슷하다. Mul gate : gradient switcher + scaler 곱셈연산의 gradient 의 경우, x 에 대한 gradient 는 y 가 되므로, 서로 바꿔주는 역할을 한다. 이 때, forward 상에서의 결과 값으로 곱해주므로, scale 역할까지 함께 하게 된다. 2. Neural Networks강의에서는 Neural Network 에 대한 intuition 을 위해, biological neuron 과 비교하였다. 모델 architecture 로서의 neuron 과 biological neuron 의 공통점은 다음과 같다. input impulse input axon → dendrite (cell body)activation &amp; activation function output axon 이러한 비교는, 나의 개인적인 Neural Network에 대한 공부와 이해에 도움이 되지 않기에 큰 감동은 없다. 4강에 대한 핵심 사항은, Backpropagation 에 대한 수식적 이해와 그 이해를 통해 Backpropagation 이 gradient를 구함에 있어, 얼마나 편한 representation 인지이다. 공부하며 어려웠던 것은, backprop in vectorized 에서, Jacobian Matrix 의 표현이 scalar backprop 때와는 달리 한번에 머릿속으로 상상되지 않았기에, 손으로 써가며 따라 갔어야만 했다. 3. ReferenceLecture 4 | Introduction to Neural Networks Syllabus | CS 231N","link":"/2019/05/18/CS231n-Lecture04-Summary/"},{"title":"[CS231n]Lecture09-CNN Architectures","text":"Lecture 09: CNN Architectures 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 이번 강의에서는 최초의 CNN 모델부터, ImageNet 대회에서 역대 좋은 스코어를 기록한 유명한 convnet 구조에 대해 살펴본다. 강의 summary 는 강의 내용 중심과 수업 중 궁금한 사항을 따로 찾아본 내용 위주로 정리한다. 해당 모델의 자세한 내용은 논문을 참조했다. 1. AlexNetLenet 이후, 가장 처음으로 나온 large scale convnet model 이다. Architecture 는 다음과 같다. 수업시간에는 CONV1 과 Max Pooling layer 에 대해서만 각 layer 의 output volume size 와 parameter 갯수를 확인했으나, 연습과 공부를 위해 전체 layer 에 대해 계산해본다. Architecture CONV1 MAX POOL1 NORM1 CONV2 MAX POOL2 NORM 2 CONV3 CONV4 CONV5 MAX POOL3 FC6 FC7 FC8 Input 이 227 x 227 x 3 image 가 들어갈 때, CONV1 (96 11x11 filter, stride 4)의 output volume size ? (227 - 11) / 4 + 1 = 55 이므로, 55 x 55 x 96 Conv1 의 weight 갯수 ? filter size 11 * 11 * 3 (channel) * 96 (filter 갯수) = 34,849개 MAX POOL (3 x 3 filter, stride 2) output volume size? (55 - 3) / 2 + 1 = 27 27 x 27 x 96 MAX POOL 의 weight 갯수? Pooling 은 weight 이 없으니까, 낚이지말자. (낚일 수 없는 낚시지..) NORM Layer 는? Normalization 만 해주는 것이므로 output size 는 27 x 27 x 96 으로 동일 CONV2 layer (256 5 x 5 filters, stride 1, padding 2) 의 output volume size 와 parameter 갯수? (27 - 5 + 4) / 1 + 1 = 27 output volume size : 27 x 27 x 256 parameter 갯수: 5 * 5 * 96 (channel) * 256 (filter 갯수 ) = 614,400 MAX POOL2 ( 3 x 3 filters, stride 2) output volume size? (27 - 3) / 2 + 1 = 13 output volume size: 13 x 13 x 256 CONV3 layer ( 384 3 x 3 filters, stride 1, padding 1)의 output volume size 와 parameter 갯수? (13-3+2) / 1 + 1 = 13 ouput volume size = 13 x 13 x 384 parameters: 13 * 13 * 256(channels) * 384 = 16,613,376 CONV4 layer (384 3x3 filters stride 1, padding 1) (13 - 3 + 2) / 1 + 1 = 13 output volume size = 13 x 13 x 384 parameters: 13 * 13 * 384(channels) * 384 = 24,920,064 CONV5 layer (256 3x3 filters stride 1 , padding 1) (13 - 3 + 2) / 1 + 1 = 13 output volume size = 13 x 13 x 256 parameters: 13 * 13 * 384 * 256 = 16,613,376 MAX POOL3 (3 x 3 filters strides 2) (13 - 3) / 2 + 1 = 6 output volume size: 6 x 6 x 256 AlexNet 의 특이점 당시 GPU 메모리의 부족으로, CONV1 layer 의 경우 depth 가 96이었으나, 48 개씩 (반반) 다른 GPU 에 올려져 계산이 진행되었다. 이는 서로가 데이터를 바라볼수 없다는 것을 의미한다. 마찬가지 의미로, CONV2, CONV4, CONV5의 경우 서로 다른 gpu 상에 올라가 있는 feature map 을 볼수 없다. 반면, CONV3, FC6, FC7, FC8 에서 서로 cross 됨으로써 feature map 을 바라볼수 없는 문제를 완화하였다 2. VGGVGG 는 AlexNet 과 비교하여, 조금더 깊은 convnet 을 가지고 있다. 이는 filter size 를 작게 가져감으로써 얻을 수 있는 이익이었다. 7x7 conv layer 1개와 3x3 conv layer 가 3개를 비교해본다. 7x7 conv layer 1개의 원본 이미지로부터 얻는 receptive field 는 7x7 영역이다. 3개의 3 x 3 conv layer가 쌓였을 때, 3번째 layer 입장에서, 원본이미지의 7 x 7 만큼의 receptive field, 즉 같은 양의 receptive field 를 얻을 수 있다. 같은 receptive field 영역을 커버하지만, layer 의 수가 증가함으로써, 더 많은 non-linearity feature map을 얻을 수 있다. 또한, 각 layer 의 parameter 수를 살펴 보면, 7x7 conv layer 는 C(이전 layer 의 channel 수)77C = 49 * C^2만큼의 parameter를 가지고 있고, 3 layer 3x3 conv layer 는 333C*C = 9 * C^2 만큼의 parameter 를 가지고 있다. 작은 filter size로 layer 수를 늘리는 것이 parameter 의 갯수 관점에서도 큰 이득을 가져다 준다. cf) 네트워크가 깊어질수록 computation양을 일정하게 유지하기 위해 각 레이어의 입력을 downsampling 한다. &amp; Spatial Area 가 작아질수록 filter 의 depth 를 조금씩 늘려준다. 3. GoogLeNetGoogLeNet 의 특이점GoogleNet 은 깊은 신경망 모델에 대해, 계산량의 이점을 가져다주기 위해 고안되었다. 이는 Inception Module 을 설계하여, 이를 연속해 쌓는 방식의 구조이다. Inception Module 의 모양은 다음과 같다. 다음과 같이 구성할 때, conv layer 를 거친 output 을 depth 방향으로 concatenate 한다. spatial dimension 은 stride 등을 조절한다. feature map 을 뽑기 위해 각 layer 의 filter 갯수를 조절할텐데, 효과적인 feature map 을 뽑기 위해 filter 갯수를 늘리게되면, 전체 Inception Module 이 쌓이면 쌓일 수록, parameter 수가 지수배 증가하는 단점이 발생한다. 여기서 GoogleNet 의 핵심 idea가 등장하는 듯 하다. 1x1 convolution layer! 1x1 convolution layer를 통해 spatial dimension 은 보존하면서, depth 는 줄인다. 즉 이 convolution layer 를 bottle neck 이 되는 conv layer 앞단에 구성하여, 입력을 더 낮은 차원으로 보낸다. 또한 google net 은 parameter 가 많이 필요한 fc layer 를 제거하므로써 computational 이득을 취했다. 또한 Inception Module 이 쌓이면서, 깊게 쌓일 수록 loss 의 grdient 전파가 소실 되는 효과를 보완하기 위해 추가적인 classifier 를 곁가지에 닮으로써 gradient 를 추가적으로 update 한다. 4. ResNetResNet 은 conv layer 를 깊게 추가하는 것이 성능에 이득을 주는지에 대한 의문으로 시작한다. 즉, 답은 깊게 쌓는 것이 성능이 좋아지지 않는다는 것이다. 위 그림의 test error 그래프를 보더라도, 성능면에서 conv layer 의 증가가 좋은 성능을 가져다 주지 않는 것이 아니다. test error 그래프만 본다면, overfitting 된 것이 아닌가? 라는 생각을 할 수 있으나, training error 그래프를 보면, 학습 조차 잘 되지 않았음을 확인 할 수 있다. 즉, 깊이가 깊은 모델이 어느 순간부터는 얕은 모델보다 성능이 안좋아 질 수 있는 문제가 발생한다. 이 문제를 degradation 문제라고 한다. ResNet 의 특이점ResNet의 구조적 특이점은 바로 skip connection 이다. skip connection 은 이렇게, layer 의 입력과 출력이 더해져, 다음 layer 에 대한 입력으로 이루어 지는 구조를 의미한다.기존의 Neural Net 의 구조를 remind 해본다. 기존 뉴럴넷은 입력 x 가 들어갈 때, 출력 y 를 얻기 위한 H(x)를 찾아내는 과정이다. H(x)가 y 에 최대한 가깝게 하기 위한 즉, H(x) - y 가 0 이 될 수 있도록 최소화 과정을 거쳐 H(x) 를 찾아낸다. 이에 반해 ResNet 은 layer 를 거친 F(x) 와 x 가 더해진 F(x) + x 를 H(x)로 보고 이를 H(x) - x 를 최소화한다. 이는 residual 로 볼 수 있는 F(x)를 최소화한다는 의미이다. 5. ReferenceLecture 9 | CNN Architectures Syllabus | CS 231N","link":"/2019/07/26/CS231n-Lecture09-Summary/"},{"title":"[CS231n]Lecture06-Training Neural Networks part1","text":"Lecture 06: Training Neural Networks part1 이 글은, Standford University 의 CS231n 강의를 듣고 스스로 정리 목적을 위해 적은 글입니다. 1. One time setup1-1. Activation FunctionsActivation Function 마다 각 특성과 trade off 가 있다. 많이 사용되는 activation function 이 있지만, LU 계열의 activation function 은 모두 실험의 parameter가 될 수 있다. (1) Sigmoid $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ sigmoid function 의 경우, 수식의 특성상 실수 space 에 있는 값들을 [0, 1] 범위 내로 좁혀 주는 기능을 해, 역사적으로 오래된 activation function 이다. 하지만 다음과 같은 단점이 있다. 단점 일정 범위(Saturated 되는 범위)부터 gradient가 0에 가까워진다. sigmoid 의 출력 결과가 zero-centered 가 되지 않는다. minor 한 단점이지만, exponential 의 계산이 비효율적이다.(비싸다고 표현) 왜 zero-centered 가 중요한가? $$f(\\sum_iw_ix_i+b)$$ 강의에서 설명해준 직관적인 방법이 매우 도움이 되었다. Backpropagation 을 생각해 보게 되면, Neuron(Node) 안에서 local gradient 와 loss 에서 부터 오는 upstream gradient 가 곱해지게 된다. 위 식에서 w 에 대해 local gradient 를 구하면 x_i 가 되는 것을 확인 할 수 있다. 만약 xi 가 모두 양수라고 가정한다면, f()의 gradient 는 항상 양수 또는 음수이고, 이는 w 가 모두 같은 방향으로 움직인다는 것을 의미한다. 즉, 비효율적인 gradient update 라고 할 수 있다. (2) hyper tangent : Tanh(x) $$tanh(x)=\\frac{e^{2x}-1}{e^{2x}+1}$$ 위와 같은 zero-centered problem 을 해결하기 위해 tanh(x) 를 사용할 수 도 있다. (추가적으로, 수업시간에 언급은 없었으나, tanh의 등장배경을 설명하는 또다른 한가지는 sigmoid 와 tanh 의 gradient의 최댓값이 4배 차이가 나므로, backpropagation 에서 gradient vanishing 현상을 방지하는 기대효과로 설명하기도 한다.)하지만, 이 역시 sigmoid 처럼 saturate 되는 부분에서 gradient 가 0이 되는 현상이 아직 남아있다. (3) ReLU $$f(x) = max(0, x)$$ ReLU 의 경우, 가장 우리가 많이 볼 수 있는 activation function 이다. 다음과 같은 장점이 있다고 설명한다. 장점 양수인 구간에서는 gradient 가 0이 되지 않고 계산이 효율적이다. sigmoid 와 tanh 에 비해 실제로 6배 빠른 converge 성능을 보여준다. 단점 zero-centered output이 아니다. 0보다 작은 구간에서는 gradient 가 0이 된다. (4) Leaky ReLU $$f(x) = max(0.01x, x)$$ 0보다 작은 구간에서 ReLU 처럼 Saturate 되는 단점을 없애고자, 0보다 작은 구간에서 작은 gradient 를 주는 것이 Leary Relu 이다. 장점 양수 구간 뿐만아니라 음수 구간에서 gradient 를 작게 주어 gradient 가 0 이 되지 않게 한다. ReLU function 과 마찬가지로, 계산이 효율적이고 sigmoid 와 tanh 에 비해 빠르게 수렴한다. Parametric Rectifier(PReLU) 라는 이름으로, 좀더 generalize 된 형태도 사용한다. $max(\\alpha x, x)$ 형태로써, alpha 를 고정시키지 않고 학습시키는 형태이다. (5) Exponential Linear Units (ELU) $$f(x)=\\begin{cases}x \\quad\\quad\\quad\\quad if \\quad x&gt;0 \\\\alpha(exp(x) -1) \\quad if \\quad x\\leq 0 \\end{cases}$$ (6) Maxout Neuron ReLU function 의 Generalize 된 형태라고 생각할 수 있다. $$max(w_1^{T}x + b_1, w_2^Tx + b_2)$$ 하지만, 이 형태는 각 뉴런마다 두 배의 parameter를 가지고 그 output 값 간의 비교를 하므로, 연산량이 두배가 많아지는 단점이 있다. (6) Summary ReLU 를 사용한다! Leaky ReLU, Maxout, ELU 를 실험해볼 수 있다. tanh 도 실험할 수 있지만, 큰 효능을 기대하기 힘들다 Don’t Use sigmoid 1-2. Data Preprocessing앞서 살펴 보았던 것 처럼, 입력 데이터에 있어서 zero-centered 가 매우 중요한 preprocessing key 라고 생각 할 수 있다. 머신러닝에서 처럼 다양한 normalized 기법과 whitening 기법들이 있지만, 뉴럴넷, 특히 이미지 데이터에 대해서는 zero-centered 까지만 전처리 해준다. 이는 모든 차원의 데이터가 같은 범위안에 있게 함으로써 각 차원이 equally contribute 하게 하기 위함이다. 1-3. Weight Initialization우리가 설정하는 각 layer 의 weight 을 어떻게 초기화 해줄 것인가의 문제도 뉴럴넷의 학습과 성능에 영향이 있을 수 있다. 작은 gaussian random number 로 모든 weight 을 초기화 해 줄 경우, layer 를 지날 수록 activation function 을 거친 작은 output 과 초기화 된 작은 w 가 곱해져, 점차 그 분산이 작아 지는 것을 확인 할 수 있다. 따라서, 이런 가우시안 랜덤으로 초기화 해주는 것이 아닌 다른 초기화 방법이 등장하였다. Xavier Initialization &amp; He Initialization 개인적으로 Xavier Initialization 과 He Initialization 을 간단하게 실험해 본 내용은 나의 github에 올려두었다. 비교군 설정에 있어, 미흡하지만 직관적으로 이해하기 쉽게 실험해 본 내용이다. 간단한 api 를 통해 구현하였기에, 자세한 수식과 개념은 해당 논문을 읽어보고, 정리해봐야겠다. github: Xavier vs He experiment 1-4. Batch Normalization결국 우리는 모든 activation 이 unit gaussian form 이길 원한다. 위에서도 살펴 보았듯이, activation function 에 들어가기 전에 모든 fully connected layer 의 출력이 saturate 구간에 있게 하고 싶지 않은 것이다. 따라서, 주로 Batch Normalization 은 Fully Connected Layer 이후 비선형함수 전 또는 Convolution Layer 다음 에 들어가게 된다. 이 때, 주의 해야할 점은 Convolution Layer 다음에 들어가는 batch normalize 는 activation map 으로 나온 channel 별로 수행해주게 된다. batch mean 과 variance 는 각 차원별로 계산해 준다. Normalize $$\\hat{x}^{(k)} = \\frac{x^{(k)}-E[x^{(k)}]}{\\sqrt{Var[x^{(k)}]}}$$ 앞서, batch normalization 의 목적은 network의 forward, backward pass 시 saturation 이 일어나지 않게 하기 위함이었습니다. 하지만 반면에, 이렇게 batch normalization 을 해준 이후에도 우리는 network 이 얼마나 해당 activation 을 얼마나 saturate 시킬지까지 학습 할 수 있다면 얼마나 좋을까요? 따라서 우리는 normalize 이후에 scaling factor 와 shifting factor 를 추가시켜, 얼마나 saturate 시킬지까지 학습할 수 있는 parameter 를 추가합니다. $$y^{(k)} = \\gamma^{(k)}\\hat{x}^{(k)} + \\beta^{k}$$ Batch Noramlization 에 대한 pseudo 알고리즘이다. 또한, 우리는 이렇게 학습한 batch mean 과 variance 를 학습 때 사용하며, testing (inference) 시에는 다시 계산하지 않는 것을 유의해야한다. testing 시에는 training 시 running average 등의 방식으로 고정된 mean과 variance 등을 사용할 수 있다. 2. Training Dynamics2-1. Babysitting the Learning Process Preprocess the data Build Model Sanity check for model (e.g. weigh이 작을ㄹ 때, loss가 negative log likelihood 와 비슷한지, regularization term이 추가될때 loss 가 증가하는지 등) (regularization term 을 사용하지 않고) 매우 작은 데이터에 대해서, train 을 돌렸을 때, loss 가 떨어지고, 금방 overfitting 되는지 확인 여기까지가 sanity check 이라면, 이제 본격적인 training!! 간단한 몇가지 실험을 통해 learning rate 을 정한다. 큰 값, 작은 값을 넣어보고, epoch 을 10까지 정도로 주었을 때, loss 가 주는 지 확인하여 대략적인 범위를 정한다. Coarse search: learning rate 과 다른 hyper parameter 를 uniform 등과 같은 distribution 을 통해 random search 한다. 강의에서 말했던, 주의사항 : 범위의 양 끝에 가장 좋은 score 가 뿌려져 있다면, 다시 범위를 설정해야한다. 내가 처음 설정한 범위 끝단에 존재한다면 그 주변에서 다시 최적의 값이 존재 할 수 있기 때문이다. Finer search: 최적의 값을 찾기 위해 세세하게 튜닝한다. 2-2. Hyperparameter Optimization 많은 양의 Cross Validation 을 통해 성능을 비교, 검증하며 최적의 hyper parameter 를 찾아야한다! Grid Search &lt;&lt; Random Search Random Sampling 을 통해 좀더 중요한 parameter 의 분포를 찾아 낼 수 있어, Random search 가 효과적 3. ReferenceLecture 6 | Training Neural Networks I Syllabus | CS 231N","link":"/2019/07/18/CS231n-Lecuture06-Summary/"},{"title":"Classification Metrics","text":"Classification Metrics: 분류 성능 지표Kaggle Classification 의 Evaluation 에 자주 사용되는 ROC-AUC를 정리해보면서, 이번 기회에 분류모델에서 자주 사용되는 성능지표(Metric)을 간단하게 정리해봅니다. Confusion Matrix 에서 비롯되는 Metric 들은 이를 이미지로 기억하는 것이 효율적입니다. Confusion Matrixconfusion matrix 는 해당 데이터의 정답 클래스(y_true) 와 모델의 예측 클래스(y_pred)의 일치 여부를 갯수로 센 표입니다. 주로, 정답 클래스는 행으로(row), 예측 클래스는 열로(columns) 표현합니다. (정의하기에 따라 다르지만) 일반적으로, class 1 을 positive로, class 0 을 negative 로 표기합니다. 우리가 예측한 클래스를 기준으로 Positive 와 Negative 를 구분합니다. 그리고 정답과 맞았는지, 틀렸는지를 알려주기 위해 True 와 False 를 각각 붙여줍니다. Accuracy: 정확도 전체 데이터에 대해 맞게 예측한 비율 $$\\frac{TP+TN}{TP+FN+FP+TN}$$ Precision: 정밀도 class 1 이라고 예측한 데이터 중, 실제로 class 1 인 데이터의 비율 $$\\frac{TP}{TP+FP}$$ 우리의 모델이 기본적인 decision이 class 0 이라고 생각할 때, class 1 은 특별한 경우를 detect 한 경우 일 것입니다. 이 때 class 1 이라고 알람을 울리는 우리의 모델이 얼마나 세밀하게 class를 구분 할 수 있는지의 정도를 수치화 한 것입니다. Recall: 재현율 실제로 class 1 인 데이터 중에 class 1 이라고 예측한 비율 = Sensivity = TPR $$\\frac{TP}{TP+FN}$$ 제가 기억하는 방식은, 자동차에 결함이 발견되서 recall 이 되어야 하는데 (실제 고장 데이터중) 얼마나 recall 됐는지로 생각합니다. Fall-out: 위양성율 실제로 class 1 이 아닌 데이터 중에 class 1이라고 예측한 비율 낮을 수록 좋음 = FPR = 1 - Specificity Specificity = 1 - Fall out $$\\frac{FP}{FP+TN}$$ 실제로 양성데이터가 아닌 데이터에 대해서 우리의 모델이 양성이라고 잘못 예측한 비율을 말합니다. 억울한 데이터의 정도를 측정했다고 생각 할 수 있습니다. 각 Metric 간의 상관관계우리 모델의 decision function 을 f(x) 라 할 때, 우리는 f(x)의 결과와 threshold (decision point)를 기준으로 class를 구분합니다. Recall vs Fall-out : 양의 상관관계 Recall은 위의 정의에 의하듯이, 실제로 positive 인 클래스에 대해 얼마나 positve 라고 예측했는지의 비율입니다. 우리가 Recall 을 높이기 위해서는 고정되어있는 실제 positive 데이터 수에 대해 예측하는 positive 데이터의 갯수 threshold 를 낮춰 늘리면 됩니다. 이에 반해 threshold 를 낮추게 되면, 실제로 positive 가 아닌 데이터에 대해 positive 라고 예측하는 억울한 데이터가 많아지므로 Fall-out 은 커지게 되고 둘은 양의 상관관계를 갖게 됩니다. Recall vs Precision : 대략적인 음의 상관관계 위에 설명한 것처럼 threshold 를 낮춰 우리가 예측하는 positive 클래스의 숫자를 늘리게 되면, recall 은 높아지는 반면, 예측한 positive 데이터 중 실제 positive 데이터의 비율은 작아 질 수 있습니다. F-beta score precision 과 recall의 가중 조화평균 $$(\\frac{1}{1+\\beta^2}\\frac{1}{precision} + \\frac{\\beta^2}{1+\\beta^2}\\frac{1}{recall})^{-1}$$ 이처럼, 다양한 Metric 에 대해 우리가 초점을 맞추는 것에 따라 모델의 성능은 다르게 바라 볼 수 있습니다. 따라서 모델에 대해 성능을 평가하고 최종 모델을 선택함에 있어, 서로 다른 Metric 을 동시에 비교해야합니다. 이를 위해 precision 과 recall 을 precision 에 beta^2 만큼 가중하여 바라보는 스코어가 F beta score 입니다. 이 중 beta=1 일 때, score 가 우리가 자주 보는 f1 score 입니다. $$F_1=\\frac{2precisionrecall}{precision+recall}$$ ROC Curve: Receiver Operator Characteristic Curve Recall vs Fallout 의 plot (TPR vs FPR) 위의 예시 처럼, 우리가 클래스를 판별하는 기준이 되는 threshold (decision point) 를 올리거나 내리면서, recall 과 fall out 은 바뀌게 됩니다. 이렇게 threshhold 를 변화 해 가면서, recall 과 fall out 을 plotting 한 것이 ROC curve 입니다. sklearn.metrics.roc_curve() 의 documentation (ROC-)AUC: Area Under Curve 위에서 그린 ROC Curve 의 넓이를 점수로써 사용하는 것이 AUC 입니다. AUC 의 유의미한 범위는 class 를 50%의 확률로 random 하게 예측한 넓이인 0.5 보다는 클 것이고, 가장 최대의 AUC 의 넓이는 1 일 것이므로 0.5≤AUC≤1 의 범위를 갖는 score 입니다. ROC 커브와 AUC score 를 보고 모델에 대한 성능을 평가 하기 위해서, ROC 는 같은 Fall out 에 대해 Recall 은 더 높길 바라고, 같은 Recall 에 대해서는, Recall 이 더 작길 바랍니다. 결국, 그래프가 왼쪽 위로 그려지고, AUC 즉 curve 의 넓이는 커지는 것이 더 좋은 성능의 모델이라고 볼 수 있습니다.","link":"/2019/06/03/Classification-Metrics/"},{"title":"[Book] Summary of Digital Image Processing Chapter 03","text":"Chapter 3: Intensity Transformations and Spatial FilteringRafael C.Gonzalez and Richard E.Woods. Digital Image Processing. PEARSON 을 다시 한번 읽어보며, 개인적으로 정리한 글입니다. 3.1 Background3.1.1 The Basics of Intensity Transformations and Spatial Filtering 모든 spatial domain process 에서 operator 와 input image f(x,y), output image g(x, y) 로 표현된다. $$g(x, y) = T[f(x, y)]$$ 3.2 Some Basic Intensity Transformation Functions3.2.1 Image Negatives Negative transformation 이미지 반전 효과 $$s = L-1-r$$ 3.2.2 Log Transormations$$s=c*log(1+r)$$ c : constant, assumed r ≥ 0 low intensity value of input → wider range of output levels 3.2.3 Power-Law(Gamma) Transformations$$s = cr^\\gamma=c(r+\\epsilon)^\\gamma$$ c, gamma: positive constants gamma 의 값에 따라서, intensity의 어떤 부분이 강조되는지가 다르다. Original Image 와 monitor 에 비추는 이미지간의 차이를 중요하게 다룰 때, gamma correction 을 사용하게 된다. 일반적인 contrast를 다룰 때 중요하게 사용되기도 한다. MRI 사진 sample 예 3.2.4 Piecewise-Linear Transformation Functions1. Contrast stretching Low-contrast image 은 sensing 면에서 떨어질 수 있으므로, intensity range를 연장하여, 큰 범위의 intensity 를 사용할 수 있도록 하는 방법 (input_intensity, output_intensity)→ (r1, s1) 과 (r2, s2)의 관계를 조절하여 contrast transform 형태를 조절한다. 극단적으로 r1=r2, s1=0, s2=L-1 이면, binary image 를 생성한다.(thresholding function) 2. Intensity-level slicing 관심있는 영역의 Intensity-level 외에는 모두 0으로 처리하거나, 관심있는 영역은 특정 intensity level 로 두고, 나머지 level 은 그대로 두는 형태등이 있을 수 있다. 3. Bit-plane slicing 8bit 의 이미지 슬라이드 중, significant order의 bit slide 중 특정 부분을 slicing 3.3 Histogram Processing3.3.1 Histogram Equalization Assume monotonic transformation: one-to-one mapping or many-to-one mapping output pdf ps, input pdf pr $$p_s(s) = p_r(r)|\\frac{dr}{ds}|$$ 이 식은? $$s=T(r)=(L-1)\\int_{0}^{r}{p_r(w)dw}$$ histogram equalization, histogram linearization $$s_k=T(r_k)=(L-1)\\sum_{j=0}^{k}p_r(r_j) = \\frac{L-1}{MN}\\sum_{j=0}^{k}{n_j}$$ output image 의 p_s, distribution 이 uniform 되게 하는 형태 결과적으로, 같은 이미지 형태이지만, 밝기와 contrast 가 모두 다르더라도 일정한 historgram 이 되도록 transform 해준다. 3.3.2 Histogram Matching(Specifiaction) Uniform historgram이 항상 좋은 것은 아니다. histogram matching, histogram specification : The method used to generate a processed image that has specified histogram (1) histogram p_r(r) 을 계산, s_k 를 구하기 위해 histogram equalization transformation 식을 계산 (2) 원하는 p_z(z) 를 이용하여, function G 를 계산 (3)(2)에서 계산한 G를 이용해 z_k (k=0, 1, 2, …L-1) 까지 계산 (4) inverse of G 계산 (5) r → z trasnformation 계산 3.3.3 Local Histogram Processing 이 전 두가지 histogram processing model 은 global 한 영역에서 진행, 즉 전체 이미지에 대해 intensity distribution 을 확인하고, 이를 이용해 transformation 을 진행 하였다. 이러한 modeling 스킬을 Local enhancement 에 사용가능 Local enhancement 는 neighborhood 를 정하고, 중심을 이동해가며, neighborhood 안에서의 histogram equalization 이나 histogram specification transformation 등을 이용할 수 있다. 계산을 줄이기 위해, nonoverlapping region 을 사용하여 위 방법을 동일하게 사용할 수 있으나, blocky effect 를 발생시킬 수 있음 blocky effect (p.161) 3.3.4 Using Histogram Statistics for Image Enhancement3.4 Fundamentals of Spatial Filtering3.4.1 The mechanics of Spatial FIltering Neighborhood (typically a small rectangle) 2. predefined operation 3.4.2 Spatial Correlation and Convolution correlation, convolution: 180 degree 반전 3.4.3 Vector Representation of Linear Filttering$$R=\\sum_{k=1}^{9}w_kz_k=\\boldsymbol{w}^T\\boldsymbol{z}$$ 3.4.4 Generating Spatial Filter Masks mn mask Average value of masked values → image smoothing 위치에 따른 gaussian filter 예 (standard deviation?(p.173)) 3.5 Smoothing Spatial Filters smoothing for blurring, noise reduction blurring : removal of small details from an image prior to object extraction, bridging of small gaps in lines or curves noise reduction: blurring by linear or non-linear filtering 3.5.1 Smoothing Linear Filters averaging filters == lowpass filters Replace the value of every pixel in an image by the average of the intensity levels in neighborhood defined by the filter mask → reduced “sharp” transitions in intensity box filter : all coefficient are euqal in filter 3.5.2 Order-Statistic(Nonlinear) Filters median filter (popular): effective in impulse noise-reduction (salt-pepper noise) implement sort values of neighborhood determine their median assign the value to filtered image 3.6 Sharpening Spatial Filters highlight transitions 3.6.1 Foundation3.6.2 Using the Second Derivative for Image Sharpeing—The Laplacian capture intensity discontinuities in an image and deemphasize $$g(x, y)=f(x, y) + c[\\triangledown^2f(x,y)]$$ 3.6.3 Unsharp Masking and Highboost Filtering unsharp masking Blur the original image Subtract the blurred image from the original (the resulting difference is called the mask) Add the mask to the original $$g_{mask}(x,y)=f(x,y)-\\bar{f}(x,y)$$ $$g(x,y) = f(x, y) + k*g_{mask}(x, y), \\quad k&gt;=0$$ k&gt;1 , highboost filtering k&lt;1, de-emphasizes unsharp mask 3.6.4 Using First-Order Derivatives for (Nonlinear) Image Sharpening—The gradient Using the magnitude of the gradient, magnitude M(x, y) $$M(x, y)=mag(\\triangledown f)=\\sqrt{g_x^2+g_y^2}=|g_x|+|g_y|$$","link":"/2019/08/26/DIP-chapter3/"},{"title":"DeepSeekMoE 요약","text":"논문 DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models를 읽고 주요 contribution 내용과 개인적으로 꼭 기억할 내용을 요약하여 정리해본다. Abstract문제 정의 최근 LLM이 발전하면서 더 많은 파라미터를 활용할 수록 성능이 향상 → but, 그에따른 연산 비용 급격히 증가 → 이를 해결하기 위해 Mixture-of-Experts (MoE) 아키텍처 등장 MoE: 여러 개의 전문가 모델 (Experts) 을 두고, 입력 데이터에 따라 일부 전문가만 활성화하여 계산하는 방식 이 방식은 전체 모델 크기는 증가할 수는 있으나, 한 번의 inference에서 사용되는 연산량을 줄일 수 있다. 기존의 대표적인 MoE 아키텍처 GShard(구글) 방식은 다음과 같은 문제점이 있다. Spicialization 문제 : GShard에서는 N개의 전문가(Experts) 중 K개를 선택 (Top-K Routing)하여 활성화하지만, 특정 Expert 들이 중복된 지식을 학습하는 문제가 있을 수 있고, 각각의 Expert가 전문화(specialization)되지 않는 문제가 발생할 수 있음 즉, 모델이 각 전문가를 “고유한, 특별한 역할”을 가진 전문가로 만들지 못하고 일부 전문가가 과하게 중복된 역할을 수행하는 비효율성이 있다. Key Idea 본 논문에서는 DeepSeekMoE라는 새로운 MoE 구조를 제안 목표는 각 Expert를 Specialization을 극대화하기 위함 두 가지 핵심 전략 소개 Expert Segmenting(전문가 세분화) 및 Activation 방식 개선 기존 GShard는 N개의 전문가 중 K 개만 선택하는 방식이었으나, DeepSeekMoE에서는 각 전문가를 더 작은 단위로 세분화 ($mN$개 전문가)하여, $mK$개의 전문가를 Activate 하는 방식을 사용 이를 통해 더 다양한 조합의 Expert들을 활성화할 수 있으며, Expert간의 Knowledge 중복을 줄이고, 유연한 조합이 가능 Shared Experts (공유 전문가(?)) 도입 일부 Expert ($K_{s}$)를 Shared Experts로 따로 분리 이 Shared Expert는 일반 상식, 지식 (Common Knowledge) 학습 나머지 Expert들은 특정한 역할을 수행하는 것으로 특화 이렇게 함으로써 각 전문가가 중복 없이 고유한 정보를 학습할 수 있으며, 동시에 일반 상식은 Shared Expert가 담당하므로 불필요한 중복 연산을 줄일 수 있다. Experiment DeepSeekMoE의 효과성을 검증하기 위해, 기존 모델들과 성능 비교 2B 크기 DeepSeekMoE 2B와 기존 Gshard 2.9B와 비교하여 1.5배 적은 Expert parameter와 연산량을 사용하면서도 동일한 성능을 보임 16B 크기 DeepSeekMoE 16B는 기존의 llama2 7B와 비슷한 성능, but 40% 정도의 연산량만 사용 더 적은 연산량으로도 동일한 성능을 유지할 수 있음을 보임 145B 크기 DeepSeekMoE 145B는 Gshard 보다 우수한 성능, DeepSeek 67B 모델과 비교해서 비슷한 성능, but 연산량은 DeepSeek 67Bdml 28.5%(혹은 최소 18.2%)만 사용 마찬가지로 기존 방식 대비 연산량을 대폭 줄이면서도 높은 성능을 유지할 수 있음을 보임 Preliminaries: 트랜스포머의 MoE 트랜스포머 기반의 언어 모델은 기본적으로 $L$개의 standard transformer 블록을 쌓아서 구성된다. 각 블록은 다음과 같이 표현될 수 있다.$$u_{1:T}^{l} = Self-Att(h_{1:T}^{l-1}) + h_{1:T}^{l-1}$$$$h_{t}^{l} = FFN(u_{t}^{l})+u_{t’}^{l}$$ 위 식에서 $T$는 시퀀스 길이 $Slef-Att$ : 셀프 어텐션 모듈 $FFN(\\cdot)$ : feed forward network $u_{1:T}^{l} \\in R^{T \\times d}$ 는 $l$ 번째 어텐션 모듈을 거친 후의 모든 토큰의 hidden state $h_{t}^{l} \\in R^{d}$ 는 $l$ 번째 트랜스포머 블록을 통과한 후 $l$ 번째 토큰의 출력 hidden state 수식에서 Layer Normalization은 생략 MoE 언어 모델을 구성하는 일반적인 방법은 트랜스포머 내에서 특정 간격마다 $FFN$ 을 MoE 레이어로 대체하는 것 MoE 레이어는 여러 Experts로 구성되며, 각 Expert는 구조적으로 Feed Forward Network와 동일한 형태를 갖는다. 이후 각 토큰은 하나의 Expert에 할당 될 수도 있고, 두 개의 Expert에 할당될 수도 있다. 만약 $l$번째 FFN 이 MoE레이어로 대체된다면, 해당 레이어에서의 output hidden state $h_{t}^{l}$ 은 다음과 같으 계산됨$$h_{t}^{l} = \\Sigma_{i=1}^{N}(g_{i, t}FFN_{i}(u_{t}^{l})) + u_{t}^{l}$$이 식을 추가적으로 설명하면 각 Expert $FFN_{i}$ 가 입력 $u_{t}^{l}$을 입력 받아 가중치 g와 곱해서 더한다. 입력 ut와 더하는 것은 residual connection (잔차 연결)로 볼 수 있음$$g_{i,t} = s_{i, t} \\quad or \\quad 0 \\quad where \\quad s_{i, t} \\in Topk(&lt;!–swig￼0–&gt;e_{i}^{l})$$각 Expert에 대한 가중치 $s_{i, t}$ 값은 Softmax로 계산됨. 그림 (a)는 Top-2 Routing 하는 moe 레이어그림 (b)는 Fine-grained expert segmentation 전략그림 (c)는 shared expert isolation 전략, DeepSeekMoE 아키텍처 DeepSeekMoE 아키텍처 DeepSeekMoE는 2가지를 제시 Fine-grained Expert Segmentation (세분화된 expert 분할) Shared Expert Isolation (공유 전문가 분리) 이 두가지 전략 모두 각각의 Expert의 전문성을 더욱 강화하는 것을 목표로 함 Fine-Grained Expert Segmentation 기존 MoE 구조에서 전문가의 수가 제한적이면, 각 전문가에게 할당된 토큰들이 다양한 종류의 지식(Knowledge)을 포함할 가능성이 높아짐 결과적으로, 하나의 전문가가 너무 많은 종류의 지식을 학습해야 하며, 이러한 지식들은 동시에 효과적으로 활용되기가 어려움 이를 해결하기 위해 각 토큰이 더 많은 전문가에게 라우팅될 수 있다면, 각 전문가가 더 세분화된 특정 지식만을 학습할 수 있도록 조정할 수 있음 이렇게 하면 전문가가 더욱 집중된(특화된) 지식을 학습할 수 있으며, 결과적으로 각 전문가 간의 역할이 더욱 명확하게 분배 구체적으로, 기존 MoE 아키텍처(그림 (a))에서 각 전문가의 FFN을 𝑚개의 더 작은 전문가로 분할한다.이때, 각 전문가의 FFN의 중간(hidden) 차원을 원래 크기의 $\\frac{1}{m}$로 줄인다. 각 전문가가 작아진 만큼, 활성화되는 전문가의 수를 $𝑚$배 증가시켜, 전체 연산 비용을 동일하게 유지할 수 있도록 조정합니다 (그림 (b)). Shared Expert Isolation 기존의 라우팅 전략에서는, 서로 다른 전문가에게 할당된 토큰들이 공통적인 지식이나 정보를 필요로 할 수 있음. 그 결과, 여러 전문가들이 동일한 지식을 학습하게 되어 파라미터 중복이 발생함. 그러나, 특정 전문가를 공유 전문가로 지정하여 여러 문맥에서 필요한 공통 지식을 담당하도록 하면,다른 전문가들의 중복 학습이 줄어들어 모델이 더욱 효율적인 구조를 가질 수 있음. 이는 전문가 specialization를 강화하고, 모델이 적은 파라미터로도 효과적인 성능을 내도록 만듦. 이를 위해, 세분화된 전문가 분할(Fine-Grained Expert Segmentation) 전략과 함께 $𝐾ₛ$개의 전문가를 공유 전문가로 따로 분리함. 이때, 라우터 모듈과 관계없이 모든 토큰은 항상 이 공유 전문가들에게 배정됨. 연산 비용을 일정하게 유지하기 위해, 다른 전문가들에게 라우팅되는 활성 전문가 수를 𝐾ₛ만큼 감소시킴. 그림 (c) 참고","link":"/2025/03/19/DeepSeekMoE-%EC%9A%94%EC%95%BD/"},{"title":"Docker, 깔끔하고 빠른 분석.연구.개발 환경 세팅","text":"부제 : 데이터사이언티스트의 도커 사용기 이번 글에서는 저를 포함하여, 도커를 처음 접하는 사람들을 위해 도커(Docker)와 도커 이미지, 도커 컨테이너의 개념에 대해 살펴봅니다. 간단한 도커파일 작성 예제를 통해, 자신에게 맞는 환경 세팅을 따라 해 볼 수 있습니다. 123오픈 소스 A 돌리려면, X, Y, Z 버전의 개발 언어와 라이브러리가 필요하다는데?오픈 소스 B 돌리려면, X1, Y2, Z3 버전의 라이브러리인데?왜 내 맥북에서는 잘 도는데, 서버로 옮기면 왜 안돼? 여러분들은 분석, 연구, 개발 환경 세팅을 어떻게 하시나요? 다양한 방법이 있을 수 있겠고, 무엇보다 자신에게 가장 편한 방법이 제일 좋은 방법일 것 입니다. 본격, 업무 시작 전 책상을 정리하고 키보드와 마우스를 한번씩 털어주는 습관이 있는 저는 제 개인 맥북과 업무 PC, 분석 및 개발서버의 환경을 깔끔(?)(단, 오로지 제 관점에서의 깔끔)하게 하는 취향이고, 세 가지의 다른 OS 환경임에도 불구하고 동일한 환경세팅을 하고 싶었습니다. 이 니즈를 해결해 줄 도커. 도커내 이미지와 컨테이너의 개념을 살펴보겠습니다. ❗️Caution❗️ 초보 도커er, 데이터사이언티스트 관점에서의 도커 활용기이기에, 오정보와 더욱 효율적인 방법이 있을 수 있습니다. 댓글을 통한 피드백을 주시면 매우 감사하겠습니다! 0. 도커 이전에 저는.도입부에서 말씀드렸다시피, 환경의 가상화 및 추상화는 프로젝트 단위로 환경을 관리하고 깔끔(?)한 환경 세팅을 위한 필수요소입니다. 이를 위해 제 개인 맥북과 PC 에서는 Python 을 위한 Pipenv, Virtualenv, Autoenv C, C++ 를 위한 Compile 옵션과 Visual Studio의 project 단위 관리를 활용해 깔끔을 떨었습니다. 도커를 통해 이제 System level 까지 환경 추상화를 도전해보려고 합니다. 1. 도커(Docker)란? 도커를 한마디로 정의하면, 컨테이너 단위로 우리의 서비스와 환경을 패키징하고, 애자일(Agile)하게 동일한 환경을 제공 할 수 있게 하는 오픈 소스 프레임워크 입니다. 도커 컨테이너의 패키징 기능은 우리가 사용하는 개발 언어, 라이브러리 뿐만 아니라, 코드, 런타임, 시스템 설정, 커널 및 OS 까지 한 가지 혹은 몇 가지의 컨테이너로 패키징 할 수 있게 합니다. 도커를 사용하면, 분석가 및 데이터사이언티스트들은 다음과 같은 이점을 활용할 수 있습니다. 분석 및 개발 환경을 컨테이너를 통해 추상화하여, 동일한 환경을 제공 한 서버내에서 여러 인원이 작업을 수행할 때, VM과 같은 기존 가상환경보다 더욱 효율적인 리소스를 활용 여러 프로젝트를 진행하지만, 각각 다른 환경에서 수행되어야 할 때 컨테이너 단위로 각 환경을 관리 개발 환경과 배포 환경을 동일하고 빠르게 환경 설정 오픈소스와 라이브러리를 많이 사용하는 분석, 모델링 업무 특성상 OS 마다 다른 설치 방법을 고민할 필요 없음! 2. 도커 컨테이너(Docker container)란? 귀여운 도커 컨테이너 도커 컨테이너는 도커를 이루는 가장 기본 단위입니다. 위에서도 살펴보았듯이, 우리가 감싸려고 하는 어플리케이션, 개발환경을 패키징하는 추상 객체입니다. 기존 시스템 OS와 독립된 공간에서 모든 프로세스가 진행될 수 있게끔하는 가상화 기술입니다. 도커 컨테이너가 기존의 Virtual Machine 과 다른 점은 전체 호스트 OS를 가상화하여 활용할 수 있다는 점입니다. Virtual Machine 은 게스트 OS(가상화한 사용자)가 호스트 OS 위에 올라가 동작하여, 시스템 리소스를 제한적으로 사용할 수 밖에 없는 단점이 있는 반면에, 도커의 경우 호스트 OS 전체를 사용하여 (게스트 OS 개념이 없음) 시스템 리소스를 전부 사용 할 수 있습니다. 가상환경을 사용했을 때 시스템구조, 이미지 출처 : docker.com 도커를 사용했을 때 시스템구조, 이미지 출처 : docker.com 3. 도커 이미지(Docker Image)란? 이미지 출처: https://kimck.tistory.com/entry/Docker-File-Docker-Image를-만들기-위한-명세서 도커 이미지는 도커 컨테이너의 설계도입니다. 도커 이미지를 통해 컨테이너 내부에 어떤 환경을 포함하여 패키징 할 것인지 계획을 세웁니다. 도커 이미지 생성 방법은 (1) DockerHub 를 활용해 Github처럼 공개된 이미지 소스를 활용하는 방법이 있고, (2) Dockerfile 을 통해 도커 이미지를 빌드하는 방법이 있습니다. 다음 예제에서 간단한 Dockerfile 작성을 통해 이미지를 만들고 Python과 jupyter 환경을 컨테이너화 해보겠습니다. 4. 일단 만들어보자!도커를 설치하는 자세한 방법은 이 글에서는 생략하도록 하겠습니다. 다음과 같은 방법으로 쉽게 설치 할 수 있으니, 자신의 환경에 맞게 설치하시고 다음을 진행해주세요! Linux : yum, apt 등 OS 에 맞는 방법으로 설치해주세요. Mac : Intel chip과 Apple M1 chip 에 따라 각각 설치해주세요. Window : Docker Desktop for Windows 를 설치해주세요 (Window os 종류에 맞게 WSL, Hyper-V 기반에 맞는 docker 설치를 진행해 주세요) 본 실습 예제의 결과물은 Docker 환경에서 (1) Python3.7 , (2) Jupyter Notebook , (3) Numpy, Pandas 라이브러리 설치 (4) 호스트 파일시스템과 도커 파일시스템을 연결 설정까지 이루어지겠습니다. 4.1 도커 실행 도커가 정상적으로 설치 되었으면, 도커의 실행 여부를 확인하고 도커를 켜고 끄는 방법을 알아봅니다. 12345678# 도커 실행 여부 확인$ systemctl status docker# 도커 실행$ sudo systemctl start docker# 도커 종료$ sudo systemctl stop docker 4.2 Dockerfile 작성먼저, 다음과 같이 작성하고 현재 실습 디렉토리에 Dockerfile 로 저장해 줍니다. 1234567891011# DockerfileFROM python:3.7RUN pip install --upgrade pipRUN pip install jupyterRUN pip install numpyRUN pip install pandasEXPOSE 8888CMD tail -f /dev/null FROM : DockerHub 에 공개되어 있는 오픈 이미지를 우리 이미지의 base 로 하는 의미입니다. python3.7 버전의 오픈 이미지를 바탕으로 우리 이미지를 빌드할 것입니다. RUN : 도커 이미지가 빌드되고, 수행되는 명령절입니다. Python 기반의 분석, 개발환경 세팅을 위하는 것인 만큼 pip를 활용해 해당 패키지를 설치해 줍니다. EXPOSE : 우리는 jupyter 환경을 설치할 예정이므로, jupyter 가 사용하는 8888 번 포트를 개방해줍니다. CMD : 컨테이너 내부 shell에서 수행되는 커맨드입니다. 배포 및 운용을 위한 컨테이너라면 CMD python3 ~~~.py 를 해주겠죠. 다만, 우리는 컨테이너를 계속 실행된 상태에서 분석 및 개발을 위한 환경이기 때문에 컨테이너 동작 이후 종료 되지 않아야 합니다. 따라서 /dev/null page 를 계속 읽어드리는 명령을 통해 환경 유지를 할 수 있습니다. 4.3 Docker image 빌드위에서 작성한 Dockerfile을 바탕으로 아래 명령어를 통해 도커 이미지를 빌드해 줍니다. 12# $ docker image builld -t 이미지명:태그명 Dockerfile경로$ docker image build -t python-jupyter:stable . -t : 생성될 이미지에 태그를 붙여줍니다. 태그를 생략하게 되면, :latest 가 default 로 붙습니다. Dockerfile 경로 : docker image build 명령은 default 로 현재 디렉토리의 Dockerfile 을 찾습니다. 파일 디렉토리와 파일명이 다른 도커파일을 지정하고 싶다면, -f 을 통해 경로/파일명을 다르게 설정할 수 있습니다. 4.4 Docker container 실행Docker image 를 바탕으로 도커 컨테이너를 실행해 줍니다. 도커 컨테이너 실행시 주의할 점이 몇가지 있습니다. 먼저 도커는 안정적인 배포와 운영을 위해 한번 실행된 컨테이너의 설정과 환경을 변경하기 쉽지 않습니다. 아니, 설정과 환경을 변경할 수 없습니다. (시도하지 마세요. 저처럼 너무나 고생하게 됩니다.) 따라서 컨테이너를 실행 할 때, 고려하는 요소를 모두 포함하여 실행시켜주는 것이 중요합니다. 123# $ docker run (각 종 옵션) DockerImage명$ docker run -d --name python-jupyter-stable -p 8888:8888 -v \\/home/user-name/workspace:/home/user-name/workspace python-jupyter:stable -d : Docker container 실행을 백그라운드에서 실행하는 옵션입니다. 도커는 안정적인 운영을 위해 foreground 실행을 하게 되면 커맨드lock 이 걸리게 됩니다. —-name : 실행되는 컨테이너의 이름 설정 -p : 호스트 서버의 포트와 컨테이너 포트 연결. 우리는 jupyter notebook 이 사용할 8888번 포트를 서로 연결해 줍니다. -v : 이 옵션을 통해 컨테이너 내부에서 저장되는 파일시스템과 호스트 서버의 파일시스템을 연결해 줍니다. 호스트 파일시스템을 컨테이너에 마운트 시킨다는 개념으로 생각합니다. 호스트서버파일시스템:컨테이너내부파일시스템 python-jupyter:stable : 위에서 생성한 이미지명:태그 4.5 Docker container shell 접속Docker container 가 정상적으로 만들어졌다면, container 내부로 들어가 jupyter notebook 을 실행해 주어야 합니다. container 내부 shell 에 접속하는 방법은 다음과 같습니다. 1$ docker exec -it python-jupyter-stable bash 위 커맨드를 이용해 컨테이너 내부에 접속해, jupyter notebook 을 실행해부면 됩니다. 1$ jupyter notebook --allow-root &amp; #background에서 jupyter notebook 실행 5. 마치며간단한 실습 예제를 통해 다양한 OS 환경에서도 동일한 분석 및 개발 환경 세팅에 대해 알아보았습니다. 위에서 작성한 Dockerfile 만 있다면, 제가 어느 환경에서 작업하더라도 docker image build, docker run 을 통해 안정적인 분석과 연구 개발을 진행 할 수 있습니다. 본 글을 통해, 도커의 필요성과 도커의 개념을 이해하고, 도커를 처음 접하는 분들에게 본격적인 도커의 소개가 되었으면 하는 바램입니다. 저 역시, 앞으로 도커를 이용해 더욱 Agile하고 고급 환경구축을 시도해 볼 것이며, 새롭게 알게 되는 내용들은 알기쉽게 정리하여 본 블로그와 PAP 커뮤니티를 통해 소개해드릴 예정입니다.","link":"/2021/11/28/Docker/"},{"title":"DeepSeek-V3 Technical Report 정리","text":"논문 DeepSeek-V3 Technical Report를 읽고 주요 contribution 내용과 개인적으로 꼭 기억할 내용을 요약하여 정리해본다. 1. Introduction Open Source 모델, DeepSeek 시리즈, LLaMA 시리즈, Qwen 시리즈, Mistral 시리즈 등 오픈소스 모델과 비공개 소스 모델들과의 격차를 줄이기 위해 노력중 본 논문에서는 오픈소스 모델을 더욱 확장하기 위해 모델 크기 확장 (Scale up)하고 , Mixture-of-Experts를 도입한다. Deepseek V3는 총 6710억(671B)개의 파라미터를 가지고 있으며, 그 중 370억(37B) 개가 각 토큰에 대해 활성화 된다. 성능 향상도 중요하지만, 모델 성능과 경제적인 비용을 동시에 추구하고 있다. 이를 위해 아키텍쳐 적으로, 효율적인 추론을 위해 Multi-head Latent Attention (MLA) 구조를 채택하고 비용 효율적인 학습을 위해 DeepSeekMoE 구조를 채택하고 있다. 이 두가지 아키텍처는 이미 DeepSeek V2에서 검증 되었음 여기에 두 가지 추가 전략을 도입해 V3가 나옴 Auxiliary Loss (보조 손실)이 없는 부하 분산 전략 (Auxiliary-loss-free load balancing)을 적용 - 부하 분산을 유도하는 과정에서 발생할 수 있는 모델 성능 저하를 최소화 하는 것을 목표로함 (추가설명) 일반적으로 MoE에서는 모든 Expert들의 작업을 고르게 분배하기 위해 보조 손실을 추가하지만, 이로 인해 성능 저하 현상이 있었다. V3에서는 이러한 보조 손실 없이도 부하 분산을 달성하려는 새로운 전략을 시도하는 것 Multi-token 예측을 학습 목표로 사용 - 여러 벤치마크에서 전반적인 성능 향상 관측 (추가설명) 한 번에 하나의 다음 단어를 예측하는 방식이 아니라, 여러 개의 토큰을 동시에 예측하도록 학습시키는 방식. 이 방법을 통해 더 빠르고 정확한 문장 생성을 가능하게 하며, 결국 전체적인 성능 향상 (벤치마크 비교)에 기여 효율적인 학습을 위해, FP8 mixed precision training을 수행하고, 학습 프레임워크 전반에 걸쳐 최적화를 수행 low -precision training은 효율적인 학습을 위해 좋은 해결책으로 뜨고 있으며, 이는 하드웨어 성능 향상과 밀접한 관련이 있음 V3에서는 FP8 mixed precision 학습 프레임워크를 도입하였고, 이를 초거대 모델에 처음으로 적용하여 그 효율성을 입증하였음. FP8 연산 및 저장을 지원함으로써, 이는 학습 속도를 향상시키고, 적은양의 GPU 메모리를 사용하여 학습을 시키는데 성공하였음 (추가설명) FP8, FP16, BF16은 부동소수점(Floating Point) 숫자를 표현하는 방식이다. CS 내용이지만, 간단하게 설명하면 FP 16 FP 16의 구성은 이와 같다. 1비트 부호 + 5비트 지수 + 10비트 가수 = 총 16비트 - 가수 (소수 부분을 뜻하는거에요) 기존의 FP32에 비해 표현할 수 있는 수의 범위가 작다. 수의 범위가 작게 되면, 정밀도(precision)가 낮다고 표현하는데 이는 매우 작은 수나 매우 큰 수를 정확하게 표현할 수 없다는 뜻이다. 이런 것을 underflow (매우 작은수) / overflow(매우 큰수)현상이라고 한다. BF 16 (brain float 16) 구성 : 1비트 부호 + 8비트 지수 + 7 비트 가수 = 총 16비트 구글에서 개발했는데, 뉴럴 네트워크 학습 목적으로 만든 새로운 자료형이다. 목적은 지수 비트의 수를 키워서 수의 표현범위가 FP32와 동일하게 만드려고 하는 것이다. 기존의 FP 16에 비해 같은 비트수를 사용하면서도, 수의 범위는 FP32와 같은 숫자를 표현하기 때문에 더 좋은 표현력을 가지고 있음. 단점으로는 가수가 적어서 정밀도는 FP16에 비해 낮다고 생각할 수 있지만 실제 사용상에는 큰 문제가 없음 FP 8 1비트 부호 + 4비트 지수 + 3비트 가수 당연히 수의 범위가 작지만 메모리는 적게 차지하는 장점이 있지만, 뉴럴네트워크에서 해당 숫자로 표현하면 너무 잃어버리는 정보가 많이 있음 그래서 이 논문 V3가 주장하는 것은 FP8로 학습시켜도 충분하게 표현할 수 있는 방법을 제시하는 것임. 사전 학습(pre-training) 14.8조(14.8T)개의 고품질, 다양성 있는 토큰들로 학습시켰음 사전학습 과정은 매우 안정적이었음 : 복구불가능한 loss spike (손실 급증), roll back 할 상황이 없었음 그 다음엔 V3의 context 길이를 두 단계에 걸쳐 확장하는 작업을 수행했음 1단계 : 최대 context 길이를 32000(32K) 토큰까지 확장 2단계 : 이를 128000토큰(128K)까지 더 확장하였음 이후 V3 base 모델을 기반으로 post-training (후속 학습)을 수행. 지도 학습 기반의 미세조정 (Supervised Fine Tuning, SFT) 강화 학습 (Reinforcement Learning, RL) distiliation 이 Post-training은 모델을 인간의 선호 (human preferences)에 더 잘 맞추고, 모델의 잠재력을 더욱 끌어내기 위함 후속 학습 단계에서는 DeepSeek R1 시리즈 모델로부터 추론 능력 (reasoning capability)을 distillation하였고, 동시에 모델의 정확도와 생성되는 응답 길이 사이의 균형을 유지할 수 있게하였다. (추가설명) context length extension 이란 context 길이는 모델이 한 번에 처리할 수 있는 텍스트 길이를 의미. 예를 들어 GPT 2,3는 2000~4000 token 길이이고, GPT-4 Turbo는 128000(128K). (확인필요) V3에서 128K까지 확장했다는 것은 매우 긴 문서를 한 번에 처리할 수 있다는 뜻 (추가설명) Post-training SFT란 정답이 있는 데이터를 기반으로 정확한 응답을 생성하도록 미세 조정 학습. 보통 RL 이라고 하면, RLHF 를 의미했는데 여기서는 다른 의미일 수도 있음 (더 읽어봐야함) (추가설명) Distillation 큰 모델을 선생님으로 두고 선생님의 답을 따라하도록 작은 모델이 학습하는 방법 V3 base 모델은 오픈소스 모델 중 벤치마크 성능이 가장 뛰어났으며, 코드와 수학 분야에서 특히 좋은 성능을 보였음 V3 chat 버전 역시 다른 오픈소스 모델보다 뛰어난 성능을 보임 GPT-4o, Claude 3.5 Sonnet과 견줄 수 있는 성능, open-ended 벤치마크에서 비슷한 성능 Deepseek V3는 학습 비용면에서 경제적임을 강조. 사전학습 (pre-training) 단계에서, V3를 1조 (1T) 토큰을 학습시키는 데 18만(180K) 시간의 H800 GPU 시간이 필요했음 이는 2048개의 H800 GPU 클러스터 기준 3.7일 만임 결과적으로 전체 사전 학습은 두 달도 안걸리게 완료되었으며, 총 266만 4천 (2.664M) GPU 시간이 소요 context length extension에는 11만 9천 (119K) GPU 시간, post-training에는 5천(5K) GPU 시간이 걸림 최종적으로 V3를 학습에 소요된 총 시간은 278만 8천 (2.788M) GPU 시간 H800 GPU 임대 비용이 시간당 $2로 가정하면, 전체 학습 비용은 약 557만 6천 달러 ($5.576M) 이 비용은 V3 학습만 포함된 것이며, 아키텍처, 알고리즘, 데이터에 대한 연구, 실험에 드는 비용은 포함되지 않음 이후 다룰 내용 먼저, DeepSeek-V3 모델 아키텍처에 대한 상세한 설명을 제시합니다 (2장). 이어서, 우리의 인프라 구조를 소개합니다. 이에는 컴퓨팅 클러스터, 학습 프레임워크, FP8 학습 지원, 추론 배포 전략, 그리고 미래 하드웨어 설계에 대한 제안이 포함됩니다. 다음으로, 우리의 사전 학습 과정을 설명합니다.여기에는 학습 데이터 구성, 하이퍼파라미터 설정, 긴 문맥 처리 기법(long-context extension techniques), 관련 평가 및 논의가 포함됩니다 (4장). 그 다음으로는, 후속 학습(post-training)에 관한 설명이 이어집니다.지도 미세조정(SFT), 강화 학습(RL), 그에 따른 평가 및 논의가 포함됩니다 (5장). 마지막으로, 우리는 본 연구를 정리(conclude)하고,DeepSeek-V3의 현재 한계점에 대해 논의하며, 향후 연구를 위한 방향을 제안합니다 (6장). 2. Architecture DeepSeek-V3 기본 아키텍처 소개 효율적인 Inference를 위한 Multi-head Latent Attention (MLA) 경제적인 Training을 위한 DeepSeekMoE 학습 목표(objective) : Multi-Token Prediction - 이거 해봤더니 모델 성능이 향상되더라 그 외의 설정과 구조는 V2를 따름 2.1 Basic Architecture V3 기본 unit은 여전히 Transformer 구조를 쌓아 올린 것 다시 한번 정리하지만, MLA와 DeepSeekMoE는 V2에서 검증이 되었음, V2와 비교했을 때 한 가지 예외적인 차이점은 DeepSeekMoE에서 auxiliary-loss-free (보조 손실이 없는) 부하 분산 전략을 새롭게 도입하여, load balance를 맞추는 과정에서 발생할 수 있는 성능 저하를 완화하고자 하였음 2.1.1 Multi-Head Latent AttentionDeepSeek-V3는 attention 구조로 MLA(Multi-head Latent Attention) 아키텍처를 채택합니다.• $d$는 임베딩 차원(embedding dimension),• $n_h$는 attention head의 개수,• $d_h$는 각 head당 차원,• $h_t \\in \\mathbb{R}^d$는 해당 attention layer에서 t번째 토큰의 입력 벡터를 나타냅니다. MLA의 핵심은 attention key와 value를 위한 저차원(low-rank) joint compression, 추론 시 Key-Value(KV) 캐시 사용량을 줄이는 데 목적이 있습니다$$ \\begin{aligned} c_{t}^{kv} = W^{DKV}h_{t} \\ [k_{t,1}^{c};k_{t,2}^{c};…;k_{t,n_{h}}^{c}]=k_{t}^{c}=W^{UK}c_{t}^{KV}, \\ k_{t}^{R} = RoPE(W^{KR}h_{t}), \\ k_{t,i} = [k_{t,i}^{C};k_{t}^{R}], \\ [v_{t,1}^{C}; v_{t,2}^{C};…;v_{t, n_{h}}^{C}] = v_{t}^{C} = W^{UV}c_{t}^{KV} \\end{aligned} $$• 여기서 $c_t^{KV} \\in \\mathbb{R}^{d_c}$는 key와 value의 압축된 잠재 벡터(latent vector)입니다.$d_c$는 KV 압축 차원이며, $d_h \\cdot n_h$보다 훨씬 작습니다 ($d_c \\ll d_h n_h$).• $W^{DKV} \\in \\mathbb{R}^{d_c \\times d}$는 입력 벡터 $h_t$를 저차원으로 압축하는 다운 프로젝션 행렬입니다.• $W^{UK}, W^{UV} \\in \\mathbb{R}^{d_h n_h \\times d_c}$는 각각 압축된 벡터를 다시 키와 밸류로 복원하는 업 프로젝션 행렬입니다.• $W^{KR} \\in \\mathbb{R}^{d_h^R \\times d}$는 RoPE용 decoupled key를 생성하는 데 사용되는 행렬입니다.• $\\text{RoPE}(\\cdot)$는 Rotary Positional Embedding을 적용하는 연산입니다.• $[\\cdot ; \\cdot]$은 벡터 합치는 것(concatenation)을 의미합니다. 중요한 점: MLA에서는 파란색 박스로 강조된 벡터($c_t^{KV}$와 $k_t^R$)만을 생성 중에 캐시(cache)하면 되므로, 기존 MHA보다 캐시 메모리를 획기적으로 절감하면서도 유사한 성능을 유지할 수 있습니다. MLA구조에서 Query에 적용되는 저차원 압축 (low-rank) compression 방식과 그 수식을 설명하는 부분이다. Attention Query에 대해서도 V3에서는 low-rank compression을 수행하며 이는 학습 중 활성화되는 메모리 (activation memeory)를 줄일 수 있다. $$\\begin{aligned} c_{t}^{Q} = W^{DQ}h_{t} \\ [q_{t, 1}^{C};q_{t,2}^{C};…;q_{t,n_{h}}^{R}] = q_{t}^{C}=W^{UQ}c_{t}^{Q},\\ [q_{t, 1}^{R}; q_{t, 2}^{R};…; q_{t, n_{h}}^{R}] = q_{t}^{R}=RoPE(W^{QR}c_{t}^{Q}), \\ q_{t,i}=[q_{t,i}^{C}; q_{t,i}^{R}] \\end{aligned}$$• 여기서 $c_t^Q \\in \\mathbb{R}^{d_c{\\prime}}$는 Query를 위한 압축된 잠재 벡터(latent vector)입니다.• $d_c{\\prime} \\ll d_h \\cdot n_h$는 Query 압축 차원을 나타내며, 전체 Query 차원보다 훨씬 작습니다.• $W^{DQ} \\in \\mathbb{R}^{d_c{\\prime} \\times d}, W^{UQ} \\in \\mathbb{R}^{d_h n_h \\times d_c{\\prime}}$는 각각 Query용 다운 프로젝션 및 업 프로젝션 행렬입니다.• $W^{QR} \\in \\mathbb{R}^{d_h^R n_h \\times d_c{\\prime}}$는 RoPE를 적용할 decoupled Query를 생성하는 행렬입니다. (추가설명) 1단계 : 압축 (down-projection) $c_t^Q = W^{DQ} h_t$ 입력 벡터 $h_t \\in \\mathbb{R}^d$를 Query 전용의 저차원 공간 $d_c{\\prime}$로 압축합니다. 목적: 메모리 절약 및 연산 효율 향상 2단계 : Query 벡터 생성 $q_t^C = W^{UQ} c_t^Q$ 압축된 latent vector $c_t^Q$를 통해 Query vector를 복원(업 프로젝션)합니다. 생성된 $q_t^C \\in \\mathbb{R}^{d_h \\cdot n_h}$는 head별 Query 컴포넌트로 나뉩니다 $q_t^C = [q_{t,1}^C; q_{t,2}^C; \\ldots; q_{t,n_h}^C]$ 3단계 : RoPE를 적용을 위한 Query 생성 $q_t^R = \\text{RoPE}(W^{QR} c_t^Q)$ 위치 정보를 부여하기 위해, 같은 $c_t^Q$에 별도 행렬 $W^{QR}$을 적용하고, 결과에 RoPE(Rotary Positional Embedding)을 적용하여 위치 정보를 포함한 Query $q_t^R$ 생성 마찬가지로 head별로 나눌 수 있음: $q_t^R = [q_{t,1}^R; q_{t,2}^R; \\ldots; q_{t,n_h}^R]$ 4단계 : 최종 Query 구성 $q_{t,i} = [q_{t,i}^C; q_{t,i}^R]$ 각 head의 최종 Query는 내용 기반 컴포넌트 $q_{t,i}^C$와 위치 정보 컴포넌트 $q_{t,i}^R$를 결합(concatenation)한 벡터입니다. 정리하면, 기존 Transformer은 $h_{t}$로 부터 Query, key, value를 직접 만들지만 MLA에서는 이를 압축하고 복원함으로써 1. 학습 중 메모리 사용량을 줄이고, 2. 효율적 계산 구조를 유지한다. 특히 Query까지 압축하는 것은 Training에 중점을 둔 최적화 과정이고, Key, Value 캐싱은 Inference 효율성 향상에 중점이 있다.(추가설명) RoPE란? 2023년 Zhipu AI에서 발표한 논문으로 ROPEformer: Enhanced Transformer with Rotary Position Embedding 이라는 논문에서 처음 등장 transoformer에서 positional \bembedding 방법 중 하나면서, 사실상 표준이 된 방식 original transformer에서는 absolute positional embedding (위치 벡터 자체)를 더하는 방식이었는데 이 보다 연산적으로 유리한 측면이 있으며 위치를 표현하는데 좀더 정교하다는 장점이 있음 가장 핵심은 벡터의 각 차원에 위치 정보인 회전행렬 (rotation matrix)로 주입하는 것이다. 다시 쉽게 말하면, 위치에 따라 임베딩 벡터를 살짝씩 회전시켜서 상대적인 거리 정보를 간접적으로 표현할 수 있도록 하는 것이다. $$\\begin{aligned} x_{t,2i}^{\\text{RoPE}} &amp;= x_{2i} \\cos(\\theta_i t) - x_{2i+1} \\sin(\\theta_i t) \\ x_{t,2i+1}^{\\text{RoPE}} &amp;= x_{2i} \\sin(\\theta_i t) + x_{2i+1} \\cos(\\theta_i t) \\end{aligned}$$ 더 자세한 내용은 여기 참조 2.1.2. DeepSeekMoE with Auxiliary-Loss-Free Load BalancingDeepSeekMoE의 기본 아키텍처V3는 FFN(Feed-Forward-Networks)에 대해 DeepSeekMoE 아키텍처를 채택하였다. 기존의 MoE 구조인 GShard와 비교했을 때 DeepSeekMoE는 세분화된 전문가(finer-grained experts)를 사용하고 일부 전문가들은 공유 전문가(shared experts)로 독립적으로 구분하여 사용한다. 토큰 $t$에 대한 FFN 입력을 $u_{t}$ (입력 임베딩)라 할 때, FFN의 출력 $h_{t}^{‘}$는 다음과 같이 계산된다. $$h^{‘}{t} = u{t} + \\Sigma_{i=1}^{N_{s}}FFN_{i}^{(s)}(u_{t}) +\\Sigma_{i=1}^{N_{r}}g_{i, t}FFN_{i}^{(r)}(u_{t})$$ $h_{t}^{‘}$ : 최종 FFN 출력 $u_{t}$ : 입력 임베딩 $FFN_{i}^{(s)}$ : 공유 전문가 (shared expert) $FFN_{i}^{r}$ : routed 전문가 $g_{i, t}$ : routed 전문가 $i$의 게이팅 값 (gating value) - weight 이라고 생각 (추가 수식 설명) 원래 입력 + 모든 공유 전문가의 출력 + 라우팅 된 전문가의 출력의 가중합$$g_{i, t} = \\frac{g_{i, t}^{‘}}{\\Sigma_{j=1}^{N_{r}}g_{j, t}^{‘}}$$ (추가 수식 설명) 임시 게이팅 점수 / 정규화된 최종 게이팅 값 $$g_{i, t}^{‘} = s_{i, t}, \\quad s_{i, t} \\in Topk({s_{j, t}|1 \\leq N_{r}, K_{r}}), \\quad 0 \\quad otherwise$$ $s_{i,t}$​: 토큰 $t$와 전문가 $i$의 친화도(affinity score) $Topk(⋅,K_{r}​)$: 가장 상위 $K_r$​개의 전문가만 선택 (추가 수식 설명) 즉 상위 $K_r$개의 expert만 선택해 $g_{i, t}^{‘}=s_{i,t}$ 이고 나머지는 0 $s_{i, t} = Sigmoid(u_{t}^{T}e_{i})$ $e_{i}$ : 라우팅 expert $i$의 중심 벡터 (centroid vector) $u_{t}^{T}e_{i}$ : 토큰과 expert 간의 내적 (=유사도) Sigmoid는 결과를 0 ~ 1 범위로 조절 (추가 수식 설명) Affinity score s는 입력 벡터와 expert vector 간의 유사도를 sigmoid로 변환한 값 여기서, $N_{s}$와 $N_{r}$은 각각 공유 전문가와 라우팅 전문가의 갯수를 나타낸다. $FFN_{i}^{(s)}(\\cdot)$ 와 $FFN_{i}^{(r)}(\\cdot)$ 은 i 번째 공유전문가와 i 번째 라우팅 전문가 $K_{r}$은 활성화되는 라우팅 전문가의 수를 의미 $Topk(\\cdot, K)$는 토큰 $t$에 대해 계산된 모든 친화도 중에서 상위 $K$개의 점수로 이루어진 집합을 의미 Auxiliary-Loss-Free Load Balancing MoE 모델에서 Expert 부하 balancing이 불균형해지면, routing collapse (라우팅 붕괴)가 발생하여 expert가 병렬 처리 할 때 계산 효율성이 저하되게 된다. 기존의 해결책으로는 auxiliary loss (보조 손실)에 의존하여 이러한 불균형을 방지하였었다. 그러나 보조 손실이 너무 커지면 모델의 본래 성능을 저해할 수 있다. V3에서는 성능과 부하 balancing사이에 더 나은 대안을 위해 보조 손실 없는 부하 분산 전략을 새롭게 제안한다. 구체적으로 각 expert 마다 bias (편향) 항 $b_{i}$를 도입하여, 이 $b_{i}$를 각 전문가의 친화도 점수 $s_{i, t}$에 더한 뒤 상위 Top-K 라우팅을 결정한다. $$g_{i, t}^{‘} = s_{i, t}, \\quad s_{i, t}+b_{i} \\in Topk({s_{j, t}+b_{j}|1 \\leq j \\leq N_{r}}, K_{r}), \\quad 0 \\quad otherwise$$ $s_{i,t}$: 토큰 $t$과 expert $i$의 affinity score (기존과 동일) $b_{i}$ : expert $i$에 대한 bias term (편향값) : 이 값은 학습 과정에서 동적으로 업데이트 됨 $g_{i, t}^{‘}$ : 임시 게이팅 점수 (Top-K) 선택시 사용→ 즉, 편항이 적용된 친화도 $s_{i,t} + b_{i}$를 기준으로 Top-K expert를 선택하되, 선택된 이후 실제 게이팅 값은 원래의 $s_{i,t}$를 사용.결국 $b_{i}$는 routing 용도에만 결정을 미치고 실제 weighted sum에서는 사용되지 않음 (추가 설명) bias (편향) term $b_{i}$의 업데이트 방식 각 훈련 스텝마다 전체 배치에서 expert 부하를 모니터링함 특정 expert가 과부하 (overloaded) 상태라면 → $b_{i}$를 감소 특정 expert가 과소활용 (underloaded) 상태라면 → $b_{i}$를 증가 즉 이를 수식으로 표현하면, $$\\begin{aligned} b_{i} ← b_{i} - γ, if \\quad overloaded\\ b_{i} ← b_{i} + γ, if \\quad underload \\end{aligned}$$ γ : bias update speed 라는 하이퍼파라미터이다.","link":"/2025/03/24/DeepSeek-V3-Technical-Report-%EC%A0%95%EB%A6%AC/"},{"title":"Generative Model","text":"확률론적 생성모형 (Generative Model)확률론적 생성모형의 기본 개념 우리가 궁금한 것은 $ x $ (features) 들이 있을 떄, $ y $가 어떤 Class 인지 맞추는 것이다. 맞추기 위해서는 training set 으로 부터 각 Class 마다 $ P(y \\mid x) $의 모형을 알아내야 한다. 베이즈 정리를 이용하여, $ y=C_k $일 때의 조건부 확률을 구할 수 있다.$$P(y = C_k \\mid x) = \\dfrac{P(x \\mid y = C_k); P(y = C_k)}{P(x)}$$ 이 때, $ P(x \\mid y = C_k) $ == Likelihood == y가 k라는 클래스 일 때, x의 확률을 구하는 것이 관건 Likelihood 추정의 알고리즘 $ P(x \\mid y = C_k) $ 가 ** 어떤 ** 확률분포를 따를 것이다라고 가정 x의 특성에 따라 우리가 알고 있는 특정 확률분포를 따른다! 라고 가정 Class k 를 만드는 data들을 통해 이 확률분포의 모수값을 구한다. 모수값을 안다 == $ P(x \\mid y = C_k) $ 의 pdf 를 알고 있다. test set x 가 들어오면 $ P(x \\mid y = C_k) $ 를 구할 수 있다.","link":"/2018/12/05/Generative-Model/"},{"title":"[Lecture] 딥러닝을 이용한 자연어 처리 Section A, B","text":"Section A, B - Summary이 글은 edwith(https://www.edwith.org/)의 조경현 교수님의 딥러닝을 이용한 자연어 처리 (https://www.edwith.org/deepnlp/joinLectures/17363)강의를 듣고 정리한 글입니다. Section A. Introduction 알고리즘의 정의 : 문제를 해결하기 위한 instruction 의 sequence Machine Learning Algorithm 문제 정의 (optional) : 문제를 specific 하게 정의 하는 것 자체가 쉽지 않다. ex) 얼굴을 detection 할 때, 어떤 범위까지 얼굴이라고 정의할 것인지 Example들이 주어진다 → 데이터들 문제를 해결 할 수 있는 Train된 Machine Learning Model Section B. Basic Machine Learning: Supervised Learning0. Supervised Learning 제공되는 것들: N 개의 pair 로 된 training set $$D = {(x_1, y_1), …, (x_N, y_N)}$$ Data 별 loss function Loss function 은 필요에 따라서 우리가 디자인 해야 할 때도 있다. $$l(M(x), y) \\geq 0$$ Evaluation sets: Validation set과 test set 기존에 보지 못한 dataset 에도 trained model 이 잘 작동 하는지 확인하는 것이 필수 우리가 결정해야 하는 것들: Hypothesis sets: H1, H2 … : 모델, hyper parameter들이 다른 모델, 여러가지 실험 해보고 싶은 것들이 될 수 있다. 가설을 잘 설정하는 것이 최종의 모델을 결정하는데 중요한 기초 작업 Optimization Algorithm 어떤 방법론으로 최적화를 진행 할지 역시 매우 중요한 문제 결국, 우리가 해야 하는 것은 주어진 Training set 에서, hypothesis set 안의 각 Hm 마다 가장 좋은 모델을 찾는다. Trained Hm 중에서, Validation set 에서 가장 좋은 한 가지 모델을 결정한다. Reporting 을 위해 test set 에서 얼마나 좋은 성능을 나타내는지 확인한다. [Three points to Consider both in research and in practice]1. 어떻게 Hypothesis set 을 설정하는가? Hypothesis Set 자체가 infinite 하다는 문제 Neural Network 에서 국한되서 보자면, 어떤 Network Architecture 를 사용하여 모델을 구성할 것인지, 각 모델마다 hyper parameter 를 어떻게 설정할 것인지 등 hypothesis set 이 매우 다양하다. 이 중, 좋은 한가지 모델을 한가지 찾는 방법이 어렵다. 강의 표현 중 이를 찾는 것은 Science ——— Magic 사이에 어느 한 점인, 거의 Art 에 가깝다고 하셔서 매우 웃겼다. 개인적으로 이 부분이 가장 공부하면서도 어렵고, 그 모델을 찾는 것이 매우 추상적인 느낌이다. 그리고 개인적으로 진행하는 프로젝트에서 과연 내가 찾은 모델보다 더 좋은 성능을 가지는 모델혹은 파라미터는 없을까(무조건 있을 것인데..라고 생각하는 경우가 훨씬 많지만..)라고 생각하며 분석과 모델링의 열정을 높이곤한다. Network Architectures Neural Network 는 Directed Acyclic Graph이다!! Inference : Forward Computaion 만으로, 쉽게 trained neural network를 사용할 수 있다. 이를 구성하는데 있어, high-level 로 abstraction 된 라이브러리를 oop , functional programming 을 활용해 쉽게 구현할 수 있다. (pytorch, tensorflow…) 2. Loss Function 관점의 이동: 어떤 주어진 data x 에 대하여 y 는 무엇일까? 를 생각하는 모델이 아니라, $$f_\\theta(x) = ? $$ 주어진 x 에 대해 y가 어떤 case 혹은 값일 확률로 생각한다. $$p(y=y’|x) = ?$$ Distribution based loss functions Binary Classification : Bernoulli distribution → Sigmoid Multiclass Classification : Categorical distribution → Softmax Linear Regression : Gaussian distribution Multimodal linear Regression : Mixture of Gaussians 결국 Loss Function 은 다음과 같이 표현될 수 있다. Maximize logp $$argmax_\\theta \\sum_{n=1}^{N} logp_\\theta(y_n|x_n)$$ = minimize L(theta): $$L(\\theta) = \\sum_{n=1}^{N} l(M_\\theta(x_n), y_n)= -\\sum_{n=1}^{N} logp_\\theta(y_n|x_n)$$ 3. Optimization Optimization 방법 Optimization 방법에는 GD, SGD, Newton Method 등 다양한 방법이 있지만, Nerual Network 에서는 Gradient Descent 방법을 위주로 사용한다. 이 강의에서는 다루지 않았지만, Gradient Descent 방법 외의 다른 알고리즘들은 전제되는 가정들이 많고, Nerual Network 의 고차원에서는 그 가정을 만족하기가 쉽지 않다. (예를 들어, Newton Method 에서의 Hessian 행렬이 구해지기 위한 가정, computation 양 또한 매우 많다.) 이런 이유에서 Gradient Descent 방법을 사용한다. Backward Computation : Backpropagation Loss function 의 gradient 를 구하는 방법은 쉽지 않다. Neural Network는 Automatic differentiation (Autograd) 를 사용하여, weight 과 bias term 에 대해 쉽게(?) gradient 값을 구할 수 있다. library 덕분에 우리가 loss function 의 gradient 를 직접 구하지 않아도 된다.","link":"/2019/05/03/Lecture-%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF-%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB-%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5-%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5-Section-A-B/"},{"title":"Linear Regression with Pytorch","text":"Linear Regression through Pytorch 이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다. Import Library12345678910import torchimport torch.optim as optimimport matplotlib.pyplot as pltimport numpy as npimport warningswarnings.filterwarnings(&quot;ignore&quot;)%config InlineBackend.figure_format = 'retina'%matplotlib inline Generate Toy Data$ y = \\frac{1}{3} x + 5 $ 와 약간의 noise 를 합쳐 100 개의 toy data를 만들겠습니다. 12345# Target Functionf = lambda x: 1.0/3.0 * x + 5.0x = np.linspace(-40, 60, 100)fx = f(x) 123plt.plot(x, fx)plt.grid()plt.show() 123456# y_train data with little noisey = fx + 10 * np.random.rand(len(x))plt.plot(x, y, 'o')plt.grid()plt.show() 1. Gradient Descent Model (hypothesis) 를 설정합니다.(여기선, Linear Regression 이므로, $y = Wx + b$ 형태를 사용합니다.) Loss Function 을 정의합니다. (여기선, MSE loss 를 사용하겠습니다.) gradient 를 계산합니다.(여기선, Gradient Descent 방법으로 optimize 를 할 것이므로, optim.SGD() 를 사용합니다.) parameter 를 update 합니다. 1234x_train = torch.FloatTensor(x)y_train = torch.FloatTensor(y)print(&quot;x_train Tensor shape: &quot;, x_train.shape)print(&quot;y_train Tensor shape: &quot;, y_train.shape) x_train Tensor shape: torch.Size([100]) y_train Tensor shape: torch.Size([100]) 1234567891011121314151617181920212223242526# train code# parameter setting &amp; initializeW = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)# optimizer settingoptimizer = optim.SGD([W, b], lr=0.001)# total epochsepochs = 3000for epoch in range(1, epochs + 1): # decide model(hypothesis) model = W * x_train + b # loss function -&gt; MSE loss = torch.mean((model - y_train)**2) optimizer.zero_grad() loss.backward() optimizer.step() # 10 epoch 마다 train loss 를 출력합니다. if epoch % 500 == 0: print(&quot;epoch: {} -- Parameters: W: {} b: {} -- loss {}&quot;.format(epoch, W.data, b.data, loss.data)) epoch: 500 -- Parameters: W: tensor([0.3709]) b: tensor([5.6408]) -- loss 22.728315353393555 epoch: 1000 -- Parameters: W: tensor([0.3467]) b: tensor([7.9427]) -- loss 11.399767875671387 epoch: 1500 -- Parameters: W: tensor([0.3368]) b: tensor([8.8829]) -- loss 9.51008415222168 epoch: 2000 -- Parameters: W: tensor([0.3327]) b: tensor([9.2669]) -- loss 9.194862365722656 epoch: 2500 -- Parameters: W: tensor([0.3311]) b: tensor([9.4237]) -- loss 9.142287254333496 epoch: 3000 -- Parameters: W: tensor([0.3304]) b: tensor([9.4878]) -- loss 9.133516311645508 12345plt.plot(x, y, 'o', label=&quot;train data&quot;)plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label='fitted')plt.grid()plt.legend()plt.show() 2. Stochastic Gradient Descent Model (hypothesis) Setting Loss Function Setting 최적화 알고리즘 선택 shuffle train data mini-batch 마다 W, b 업데이트 12345678910111213141516# batch 를 generate 해주는 함수def generate_batch(batch_size, x_train, y_train): assert len(x_train) == len(y_train) result_batches = [] x_size = len(x_train) shuffled_id = np.arange(x_size) np.random.shuffle(shuffled_id) shuffled_x_train = x_train[shuffled_id] shuffled_y_train = y_train[shuffled_id] for start_idx in range(0, x_size, batch_size): end_idx = start_idx + batch_size batch = [shuffled_x_train[start_idx:end_idx], shuffled_y_train[start_idx:end_idx]] result_batches.append(batch) return result_batches 12345678910111213141516171819# trainW = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)optimizer = optim.SGD([W, b], lr=0.001)epochs = 10000for epoch in range(1, epochs + 1): for x_batch, y_batch in generate_batch(10, x_train, y_train): model = W * x_batch + b loss = torch.mean((model - y_batch)**2) optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 500 == 0: print(&quot;epoch: {} -- Parameters: W: {} b: {} -- loss {}&quot;.format(epoch, W.data, b.data, loss.data)) epoch: 500 -- Parameters: W: tensor([0.0890]) b: tensor([9.5399]) -- loss 162.1055450439453 epoch: 1000 -- Parameters: W: tensor([0.3672]) b: tensor([9.5366]) -- loss 12.424881935119629 epoch: 1500 -- Parameters: W: tensor([0.3560]) b: tensor([9.5097]) -- loss 7.826609134674072 epoch: 2000 -- Parameters: W: tensor([0.3375]) b: tensor([9.5556]) -- loss 13.15934944152832 epoch: 2500 -- Parameters: W: tensor([0.2462]) b: tensor([9.5157]) -- loss 11.582895278930664 epoch: 3000 -- Parameters: W: tensor([0.3097]) b: tensor([9.5111]) -- loss 9.991677284240723 epoch: 3500 -- Parameters: W: tensor([0.2497]) b: tensor([9.5532]) -- loss 20.481367111206055 epoch: 4000 -- Parameters: W: tensor([0.4388]) b: tensor([9.5390]) -- loss 20.827198028564453 epoch: 4500 -- Parameters: W: tensor([0.1080]) b: tensor([9.4959]) -- loss 140.0277862548828 epoch: 5000 -- Parameters: W: tensor([0.3188]) b: tensor([9.4829]) -- loss 6.635367393493652 epoch: 5500 -- Parameters: W: tensor([0.2553]) b: tensor([9.5017]) -- loss 25.45773696899414 epoch: 6000 -- Parameters: W: tensor([0.2490]) b: tensor([9.5489]) -- loss 9.580666542053223 epoch: 6500 -- Parameters: W: tensor([0.3189]) b: tensor([9.5347]) -- loss 12.585128784179688 epoch: 7000 -- Parameters: W: tensor([0.3026]) b: tensor([9.4874]) -- loss 8.298829078674316 epoch: 7500 -- Parameters: W: tensor([0.3507]) b: tensor([9.6815]) -- loss 13.348054885864258 epoch: 8000 -- Parameters: W: tensor([0.1423]) b: tensor([9.5220]) -- loss 32.567440032958984 epoch: 8500 -- Parameters: W: tensor([0.7147]) b: tensor([9.5182]) -- loss 75.97190856933594 epoch: 9000 -- Parameters: W: tensor([0.5170]) b: tensor([9.5289]) -- loss 39.07848358154297 epoch: 9500 -- Parameters: W: tensor([0.3748]) b: tensor([9.5590]) -- loss 10.358983993530273 epoch: 10000 -- Parameters: W: tensor([0.2958]) b: tensor([9.6088]) -- loss 7.410649299621582 Stochasitic 하게 loss의 gradient 를 계산하여, parameter update를 하므로, loss 가 굉장히 oscilation 이 나타나며 감소하는 것을 볼 수 있다. 12345plt.plot(x, y, 'o', label=&quot;train data&quot;)plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label='fitted')plt.grid()plt.legend()plt.show() 1","link":"/2019/05/03/Linear-Regression-with-Pytorch/"},{"title":"Linear Model with Pytorch","text":"Linear Model with Pytorch 이 글의 목적은, 지난 Linear Regression 에서 좀더 나아가서, 다양한 Regression 예제들을 Linear Model (WX) 형태로 pytorch 를 이용해 풀어 보는 것입니다. Pytorch 를 사용하여 Modeling 과 loss function 등을 class 형태, 내장 loss 함수등을 사용해보겠습니다. 12345678910import torchimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Fimport numpy as npimport warningswarnings.filterwarnings(&quot;ignore&quot;)%config InlineBackend.figure_format = 'retina'%matplotlib inline 1. Quadratic Regression Model$$f(x) = w_0 + w_1x + w_2x^2$$ 12345678x = np.linspace(-10, 10, 100)y = x**2 + 0.7 * x + 3.0 + 20 * np.random.rand(len(x))plt.plot(x, y, 'o')plt.grid()plt.xlabel('x')plt.ylabel('y')plt.show() 12345x_train = torch.FloatTensor([[each_x**2, each_x, 1] for each_x in x])y_train = torch.FloatTensor(y)print(&quot;x_train shape: &quot;, x_train.shape)print(&quot;y_train shape: &quot;, y_train.shape) x_train shape: torch.Size([100, 3]) y_train shape: torch.Size([100]) 1234567891011121314151617W = torch.zeros(3, requires_grad=True)optimizer = optim.SGD([W], lr=0.0001)epochs = 10000for epoch in range(1, epochs + 1): hypothesis = x_train.matmul(W) loss = torch.mean((hypothesis - y_train) ** 2) optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1000 == 0: print(&quot;epoch: {} -- Parameters: W: {} -- loss {}&quot;.format(epoch, W.data, loss.data)) epoch: 1000 -- Parameters: W: tensor([1.1738, 0.4943, 1.0699]) -- loss 85.30189514160156 epoch: 2000 -- Parameters: W: tensor([1.1581, 0.4949, 2.0311]) -- loss 76.05414581298828 epoch: 3000 -- Parameters: W: tensor([1.1437, 0.4949, 2.9105]) -- loss 68.31205749511719 epoch: 4000 -- Parameters: W: tensor([1.1305, 0.4949, 3.7151]) -- loss 61.83049011230469 epoch: 5000 -- Parameters: W: tensor([1.1185, 0.4949, 4.4514]) -- loss 56.4041862487793 epoch: 6000 -- Parameters: W: tensor([1.1075, 0.4949, 5.1250]) -- loss 51.86140060424805 epoch: 7000 -- Parameters: W: tensor([1.0974, 0.4949, 5.7414]) -- loss 48.058231353759766 epoch: 8000 -- Parameters: W: tensor([1.0882, 0.4949, 6.3054]) -- loss 44.8742790222168 epoch: 9000 -- Parameters: W: tensor([1.0798, 0.4949, 6.8214]) -- loss 42.20869445800781 epoch: 10000 -- Parameters: W: tensor([1.0721, 0.4949, 7.2935]) -- loss 39.97709655761719 12345plt.plot(x, y, 'o', label='train data')plt.plot(x, (x_train.data.matmul(W.data).numpy()), '-r', linewidth=3, label='fitted')plt.grid()plt.legend()plt.show() 2. Cubic Regression Model$$f(x) = w_0 + w_1x + w_2x^2 + w_3x^3$$ 2.1 Generate Toy data 100개의 data 를 생성합니다. 12x = np.linspace(-1, 1, 100)y = 3*x**3 - 0.2 * x ** 2 + 0.7 * x + 3 + 0.5 * np.random.rand(len(x)) 12345plt.plot(x, y, 'o')plt.grid()plt.xlabel('x')plt.ylabel('y')plt.show() 2.2 Define Model x_train과 y_train 을 만들어줍니다. 123x_train = torch.FloatTensor([[xval**3, xval**2, xval, 1]for xval in x])y_train = torch.FloatTensor([y]).view(100, -1)y_train.shape torch.Size([100, 1]) 이번에 Model을 nn.Module 추상 클래스를 상속 받아, class 형태로 모델링 해보겠습니다. 1234567class CubicModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(4, 1) def forward(self, x): return self.linear(x) 1model = CubicModel() train 시킬 때, loss 역시 nn.functional 에 있는 내장 mse loss 를 사용하여 보겠습니다. 12345678910111213141516171819optimizer = optim.SGD(model.parameters(), lr=0.001)epochs = 15000for epoch in range(1, epochs + 1): hypothesis = model(x_train) # define loss loss = F.mse_loss(hypothesis, y_train) # Backprop &amp; update parameters optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1500 == 0: print(&quot;epoch: {} -- loss {}&quot;.format(epoch, loss.data)) epoch: 1500 -- loss 0.22306101024150848 epoch: 3000 -- loss 0.11560291796922684 epoch: 4500 -- loss 0.09848319739103317 epoch: 6000 -- loss 0.08879078179597855 epoch: 7500 -- loss 0.08104882389307022 epoch: 9000 -- loss 0.07452096790075302 epoch: 10500 -- loss 0.06889640539884567 epoch: 12000 -- loss 0.06398065388202667 epoch: 13500 -- loss 0.05964164435863495 epoch: 15000 -- loss 0.055785566568374634 12345plt.plot(x, y, 'o', label='train data')plt.plot(x, model(x_train).data.numpy(), '-r', linewidth=3, label='fitted')plt.grid()plt.legend()plt.show() 3. Exponential Regression Model$$f(x) = e^{w_0x}$$ $$g(x) = \\ln f(x) = w_0x$$ Exponential 의 경우, Linear Model 형태를 만들어 주기 위해, log 를 씌워 주워 train 을 시킨후, 다시 exponential 을 양변에 취해주는 형태로 modeling 을 하여야 한다. 3.1 Generate Toy data123np.random.seed(20190505)x = np.linspace(-1, 1, 50)y = np.exp(2 * x) + 0.2 * (2 * np.random.rand(len(x)) - 1) 12345plt.plot(x, y, 'o')plt.grid()plt.xlabel('x')plt.ylabel('y')plt.show() 3.2 Define Model123x_train = torch.FloatTensor([[xval, 1] for xval in x])y_train = torch.FloatTensor([np.log(y)]).view(50, -1)y_train.shape torch.Size([50, 1]) 1234567class ExpModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(2, 1) def forward(self, x): return self.linear(x) 이번에는 optimize algorithm 중 Adam 을 사용해 보겠습니다. Adam 은 adaptive 하게 learning rate 를 조정해 주는 algorithm 입니다. 1234567891011121314151617model = ExpModel()optimizer = optim.Adam(model.parameters())epochs = 15000for epoch in range(1, epochs + 1): hypothesis = model(x_train) loss = F.mse_loss(hypothesis, y_train) optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1000 == 0: print(&quot;epoch: {} -- loss {}&quot;.format(epoch, loss.data)) epoch: 1000 -- loss 1.4807509183883667 epoch: 2000 -- loss 0.6568859815597534 epoch: 3000 -- loss 0.2930431365966797 epoch: 4000 -- loss 0.1839657723903656 epoch: 5000 -- loss 0.1683545857667923 epoch: 6000 -- loss 0.16775406897068024 epoch: 7000 -- loss 0.16775156557559967 epoch: 8000 -- loss 0.16775153577327728 epoch: 9000 -- loss 0.16775155067443848 epoch: 10000 -- loss 0.16775155067443848 epoch: 11000 -- loss 0.16775155067443848 epoch: 12000 -- loss 0.16775155067443848 epoch: 13000 -- loss 0.16775153577327728 epoch: 14000 -- loss 0.1677515208721161 epoch: 15000 -- loss 0.1677515208721161 12345plt.plot(x, y, 'o', label='train data')plt.plot(x, np.exp(model(x_train).data.numpy()), '-r', linewidth=3, label='fitted')plt.grid()plt.legend()plt.show() 4. Sine &amp; Cosine Regression$$f(x) = w_0\\cos(\\pi x) + w_1\\sin(\\pi x)$$ 4.1 Generate Toy data12x = np.linspace(-2, 2, 100)y = 2 * np.cos(np.pi * x) + 1.5 * np.sin(np.pi * x) + 2 * np.random.rand(len(x)) - 1 12345plt.plot(x, y, 'o')plt.grid()plt.xlabel('x')plt.ylabel('y')plt.show() 4.2 Modeling123x_train = torch.FloatTensor([[np.cos(np.pi*xval), np.sin(np.pi*xval), 1] for xval in x])y_train = torch.FloatTensor(y).view(100, -1)y_train.shape torch.Size([100, 1]) 1234567class SinCosModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(3, 1) def forward(self, x): return self.linear(x) 1234567891011121314151617model = SinCosModel()optimizer = optim.Adam(model.parameters())epochs = 10000for epoch in range(1, epochs + 1): hypothesis = model(x_train) loss = F.mse_loss(hypothesis, y_train) optimizer.zero_grad() loss.backward() optimizer.step() if epoch % 1000 == 0: print(&quot;epoch: {} -- loss {}&quot;.format(epoch, loss.data)) epoch: 1000 -- loss 1.1333037614822388 epoch: 2000 -- loss 0.45972707867622375 epoch: 3000 -- loss 0.36056602001190186 epoch: 4000 -- loss 0.3566252291202545 epoch: 5000 -- loss 0.3566077649593353 epoch: 6000 -- loss 0.3566077947616577 epoch: 7000 -- loss 0.3566077649593353 epoch: 8000 -- loss 0.3566077947616577 epoch: 9000 -- loss 0.3566077947616577 epoch: 10000 -- loss 0.3566077649593353 12345plt.plot(x, y, 'o', label='train data')plt.plot(x, model(x_train).data.numpy(), '-r', linewidth=3, label='fitted')plt.grid()plt.legend()plt.show()","link":"/2019/05/04/Linear-Model-with-Pytorch/"},{"title":"Mysql","text":"MySQL1. Install MySQL https://dev.mysql.com/downloads/mysql/5.7.html#downloads 에서DMG 파일 다운로드 시스템 환경설정에서 MySQL -&gt; Start MySQL Server : server 시작 1$ cd usr/local/mysql/bin 위 경로에서 MySQL 서버에 접속 1$ sudo ./mysql -p 1mysql &gt; 패스워드 변경 123mysql&gt;ALTER USER 'root'@'localhost' IDENTIFIED BY '바꾸고싶은 비밀번호';mysql&gt;FLUSH PRIVILEGES;mysql&gt;quit; 2. MySQL Shell Command(1) DATABASE 생성, 접속, 삭제 현재 상태 보기1mysql&gt; STATUS DB 목록 보기1mysql&gt; SHOW DATABASES; DB 만들기1mysql&gt; CREATE DATABASE DBNAME DB 접속하기1mysql&gt; USE DBNAME; 현재 접속중인 DB 확인하기1mysql&gt; SELECT DATABASE(); DB 지우기1mysql&gt; DROP DATABASE DBNAME; (2) TABLE 생성, 추가, 삭제 table 만들기1234567CREATE TABLE table_name( column_name_1 column_data_type_1 column_constraint_1, column_name_2 column_data_type_2 column_constraint_2, . . .) column_constraint 는 Optional 이다. (unique 와 같은 제약조건) user 라는 table에 name, email, age 컬럼 생성 example1 : constraint 가 없을 떄,12345mysql&gt; CREATE TABLE user( name CHAR(20), email CHAR(40), age INT(3)) example2 : constraint가 있을 때,1234567mysql&gt; CREATE TABLE user2( user_id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(20) NOT NULL, email VARCHAR(30) UNIQUE NOT NULL, age INT(3) DEFAULT'30', rdate TIMESTAMP) (3) 수정(3)-1. DATABASE 수정 DATABASE 의 encoding 수정 현재 문자열 encoding 확인1mysql&gt; SHOW VARIABLES LIKE &quot;CHARACTER_SET_DATABASE&quot;; mydb 데이터베이스의 문자열 인코딩을 utf8 로 변경1mysql&gt; ALTER DATABASE mydb CHARACTER_SET = utf8; user 데이터베이스의 문자열 인코딩을 ascii 로 변경1mysql&gt; ALTER DATABASE user CHARACTER_SET=ascii (3)-2. TABLE 수정 user 테이블에 tmp라는 컬럼명, TEXT 데이터 타입 컬럼을 추가1mysql&gt; ALTER TABLE user ADD tmp TEXT;","link":"/2018/11/01/MySQL/"},{"title":"NGINX","text":"Nginx0. What is nginx? client 가 외부 IP와 그 포트를 통해 server 에 접근하면, 그 때부터는 request 를 내부 IP 와 port 로 연결을 해주어야 한다. 일종의 proxy server 역할을 해주는 것이 nginx 1. Install Nginx12$ sudo apt-get update$ sudo apt-get install nginx 2. Manage the Nginx Process nginx Process1234567891011121314#start Nginx$ sudo systemctl start nginx#stop nginx$ sudo systemctl stop nginx#restart nginx$ sudo systemctl restart nginx#check status nginx$ sudo systemctl status nginx# reload nginx$ sudo systemctl reload nginx 3. Structure /etc/nginx Nginx의 설정에 관련된 directory /etc/nginx/nginx.conf nginx의 기본설정 파일, global설정은 이 파일에서 /etc/nginx/sites-available/ 포트 접속시 개별 설정하는 directory 여기 안에 default 파일 변경 4. Nginx Configuration4.1 static file serving/etc/nginx/sites-available/default 파일 수정 123456789server { location / { root /path/to/html ; } location /images/ { root /path/to/image; }} 4.2 proxy server port 별로 설정이 가능하다12345678server { # default 는 80 port (http default) # 8080 port 에 대해서 listen 8080; location / { proxy_pass http://localhost:8080; }} 여러개의 포트를 연결 server { listen 8080; listen 80; location / { proxy_pass http://localhost:8080; } }","link":"/2018/11/29/NGINX/"},{"title":"Pillow","text":"Pillow 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. Pillow 는 Python에서 이미지를 핸들링 하기위한 라이브러리이다. 스크린 샷, 이미지 크롭, 썸네일 등을 만들 수 있다. 또한, 다양한 이미지 확장자를 다룰수 있다. (예, jpg, png) Pillow install1pip install Pillow 1. Import Convention Pillow 를 사용하기에 앞서, Import 해야한다.1from PIL import Image 2. Pillow 메소드(1) open() 이름 그대로, 경로와 파일 이름을 적어주면, 해당 이미지리턴하여 Variable 에 할당한다. 1image = Image.open(&quot;imagefile_name&quot;) (2) crop() 이름 그대로, image 를 잘라준다. 이 때 Parameter 는 box형태로 들어가게 된다. box 는 (left, upper, right, lower) 로 들어가게 된든데, pixel 단위로 들어가면 된다 이미지의 가장 왼쪽과 위쪽 라인을 기준으로, left px 만큼 upper px 만큼 (왼쪽을 기준으로) right px 만큼 (위쪽을 기준으로) bottom px 만큼 잘라, box 로 만들어 준다. 123box = (10, 10, 110, 110)image.crop(box)### 이렇게 되면 가로세로 100px 만큼의 이미지가 만들어진다. (3) thumbnail() 썸네일을 만들어준다. 썸네일의 활용 방안은 한 가지 사진을 어플리케이션 곳곳에서 사용한다고 할 때, 데이터 사이즈가 큰 원본 사진을 계속 해서 들고 다니며 사용하면 어플리케이션에 따라 메모리 낭비, 서버용량 낭비, 트래픽 낭비 등으로 이어질 수 있다. 따라서, 이미지의 데이터 크기와 해상도를 낮춰 사용할 수 있다.12image.thumbnail((pixel, pixel))#thumbnail 메소드를 사용하여, 원하는 pixel 수로 줄일 수 있다.","link":"/2018/10/25/Pillow/"},{"title":"Provision","text":"Server Provisioning &amp; Terraform Provisioning 이란, 한정된 자원을 최적의 효율을 위해 제공하는 기술적 개념을 말한다. 유저의 요청에 맞게 자원을 미리 세팅해두고, 유저의 요청에 따라 준비된 자원들을 목적과 효율에 맞게 제공하는 개념이다. 특정 분야에서 한정되어 사용하는 개념이 아니라 다양한 분야에서 응용되어지는 주제이다. (IT 분야만으로 한정되지도 않는다) IT 분야의 Provisioning의 예시로는, Server Provisioning, Storage Provisioning, Telecommunication Provisioning 등이 있다. 여기서는 Terraform 을 활용한 AWS 서버 프로비져닝에 관해 다룬다. ## AWS EC2 AWS EC2를 활용하기 위해서는 3가지의 기본적인 세팅이 필요하다. 키페어 (Key pair) 보안그룹 (Security Group) 인스턴스 (Instance) 이 세가지를 Terraform 을 활용해 생성하는 코드를 정리한다. 1. 키페어 생성 (Key pair)1-1. Key 만들기- 자신의 email로 ssh key 를 생성하여, key_name 이름으로 .ssh 폴더에 저장 ssh-keygen -t rsa -b 4096 -C “email” -f “$HOME/.ssh/key_name” -N “” - 이렇게 생성된 key 는 /key_name/ 과 /key_name.pub/로 private key 와 public key가 생성된다. 1-2. Key pair 생성- `main.tf` 파일 생성 123456789`provider “aws” { # 이 region 은 seoul 을 의미한다 region = “ap-northeast-2”}Resource “aws_key_pair” “resource_name” { # keygen 으로 생성한 key_name key_name = &quot;key_name&quot; public_key = &quot;${file(&quot;~/.ssh/key_name.pub&quot;)}&quot;} - apply 를 실행해, aws 키페어를 생성 123$ terraform init$ terraform plan$ terraform apply - destroy 를 실행해, aws 키페어를 삭제 $ terraform destroy 2. 보안그룹 생성 (Security Group)- 보안그룹은 생성될 인스턴스의 정책을 설정하는 부분이다. 가장 대표적인 기능은 인바운드와 아웃바운드 port 를 설정할 수 있다. - 필요에 따라 port number 를 열어주면 된다. - `ingress` 는 인바운드, `egress` 는 아웃바운드 태그이다. - `from_port` 와 `to_port` 는 말 그대로 from 부터 to 까지의 번호를 지정한다. - 대표적인 포트번호에 관한 설명 - 22 : ssh 접속을 위한 포트 - 80 : http의 기본포트 - 8888 : Jupiter notebook 사용을 위한 포트 - 27017 : MongoDB 사용을 위한 포트 - 3306 : MySQL 사용을 위한 포트 ( /여기서는 DB의 경우, 다른 서버를 두고 사용하고 있으므로, 열어주지 않는다/ ) - `main.tf` 파일 생성 123456789101112131415161718192021222324252627provider &quot;aws&quot; { region = &quot;ap-northeast-2&quot;}resource &quot;aws_security_group&quot; &quot;resource_name&quot; { name = &quot;보안그룹 이름&quot; description = &quot;보안그룹의 설명&quot; ingress { from_port = 22 to_port = 22 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } ingress { from_port = 80 to_port = 80 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } ingress { from_port = 8888 to_port = 8888 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] }} 마찬가지로, init, plan, apply 를 활용하여 보안그룹을 생성하고, destroy 로 제거한다. 3. 인스턴스 생성- 대망의 인스턴스 생성! - 여기선, EC2 중, linux ubuntu 18.04 버젼 을 활용한다. AWS 내에서 다른 종류의 인스턴스를 사용할 경우, ami 를 다른 값으로 사용하면 된다. - 또한, 다양한 인스턴스 유형중, t2.nano를 사용한다. 인스턴스 유형도 필요에 따라 다르게 설정하면 된다. - `main.tf` 파일 생성 12345678910111213141516171819provider &quot;aws&quot; { region = &quot;ap-northeast-2&quot;}data &quot;aws_security_group&quot; &quot;resource1&quot; { name = &quot;security_group_name&quot;}resource &quot;aws_instance&quot; &quot;resource2&quot; { ami = &quot;ami-06e7b9c5e0c4dd014&quot; instance_type = &quot;t2.nano&quot; key_name = &quot;key_name&quot; vpc_security_group_ids = [ &quot;${data.aws_security_group.resource1.id}&quot; ] tags { Name = &quot;dss_instance&quot; }} - `init`, `plan`, `apply` 를 활용하여 인스턴스를 생성하고, `destroy` 로 제거한다. 4. 생성된 인스턴스 확인ssh -I ~/.ssh/key_name ubuntu@외부ip 로 생성된 인스턴스를 확인하고, 활용할 수 있다.","link":"/2019/01/10/Provision/"},{"title":"Queue","text":"Queue 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. Queue의 특징 내가 버스정류장에 서있다고 생각해보면, 버스 전용차선으로 버스가 줄지어 들어온다. 아무리 뒷차가 손님을 다 태웠다고해서, 앞에 버스가 아직 손님을 태우고 있으면 뒷 버스는 출발 하지 못한다. 이것이 바로 QUEUE FIFO : First In First Out == 선입선출 or 후입후출 front와 rear 라는 index가 각각 구조의 맨 앞과 뒤를 가리키고 있다. Data는 rear로 들어가고, front 에서 나온다. ADT empty() 라는 메소드로 Queue 에 data가 있는지 없는지 확인하게 한다. empty 이면 True, not empty 이면, False 를 return 한다.Queue.empty() returns Boolean enaueue(data) 메소드로 Queue의 rear 가 가리키고 있는 data 뒤에 data를 넣는다.Queue.enqueue (data) returns None dequeue() 메소드로 Queue의 front가 가리키고 있는 data를 반환하면서 삭제 된다.Queue.dequeue() returns data peek() 메소드로 Queue의 front가 가리키고 있는 data를 반환한다. peek은 어디까지나 확인하는 메소드 이므로, data가 삭제되지 않는다.Queue.peek() returns data 구현 1 : by python list Queue 구조를 Python에 내장 되어 있는 list를 container 로 구현한다. 123456789101112131415161718192021class Queue: def __init__(self): self.container=list() def empty(self): # ADT 를 따라서, 비어 있으면 return True 비어있지 않으면 return False if not self.container: return True return False def enqueue(self, data): # list 를 활용했으므로, list.append(data)를 활용할 수 있다. self.container.append(data) def dequeue(self): # pop 역시 list.pop()을 활용할 수 있다. return self.container.pop(0) def peek(self): # peek은 단지 front 에 어떤 데이터가 있는지 확인 하는 것 뿐이므로, 현재 리스트의 가장 앞 부분에 있는 data 를 확인하면 된다. return self.container[0] 구현 2 :","link":"/2018/10/22/Queue/"},{"title":"회귀 모델 성능평가지표 : MAE, MSE, RMSE, R2 Score","text":"회귀모델의 대표적인 성능 지표를 알아보는 글입니다. 회귀 모델에서는 얼마나 정확하게 그 값을 예측하는 지가 중요합니다. y값의 형태는 낙찰가격처럼 연속된 실수형태이기 때문에, 그 값을 정확하게 예측하거나 가장 근사치로 예측하는 것이 가장 중요합니다. 따라서 회귀모델에서의 성능평가 지표는 실제y값과 예측y값을 비교합니다. 대표적인 성능평가 지표에는 다음과 같은 4가지 종류가 있습니다. MAE (Mean Absolute Error) MSE (Mean Squared Error) RMSE (Root Mean Squared Error) R2 Score (Coefficient of Determination) : 결정 계수 1. MAE (Mean Absolute Error) MAE 계산 순서 오차 = 실제값 - 예측값 절댓값 오차 : |오차| 모든 데이터의 오차를 구해야 하므로 시그마를 취함 오차의 전체 분포 파악을 위해 평균을 취함 위 계산 순서를 수식으로 표현하면 다음과 같습니다. $$MAE = \\frac { { \\Sigma |y_{true}-y_{pred} | } } {n}$$ MAE의 특징 Error의 절대값을 취하기 때문에, 에러의 크기가 그대로 반영됨 평균값이기 때문에, 개별 데이터의 에러의 평균 통계량을 의미 에러에 따른 Loss 가 선형적으로 올라갈 때 적합 이상치가 많을 때 주로 사용 2. MSE (Mean Squared Error) MSE 의 계산 순서 오차 = 실제값 - 예측값 오차의 제곱 모든 데이터의 오차를 구해야하므로 시그마를 취함 오차의 전체 분포 파악을 위해 평균을 취함 수식 표현 $$MSE = \\frac { { \\Sigma (y_{true}-y_{pred})^2 } } {n}$$ MSE 의 특징 MAE 는 Loss 에 대해 그대로 반영하는 반면, MSE 는 에러의 제곱을 해주므로, 해당 Loss 를 좀더 강력히 제재하는 효과를 가집니다. 따라서 이상치가 있는 경우, 에러가 크게 측정되는 경향 이를 모델에 활용 다만 이 에러의 영향을 크게 하여, 모델 성능을 높이려는 목적 3. RMSE (Root Mean Squared Error) RMSE 계산 순서 오차 = 실제값 - 예측값 오차의 제곱 모든 데이터의 오차를 구해야하므로 시그마를 취함 오차의 전체 분포 파악을 위해 평균을 취함 평균값에 루트 수식표현 $$RMSE = \\sqrt { \\frac { {\\Sigma (y_{true}-y_{pred})^2} } {n}}$$ RMSE 의 특징 MSE 의 값은 오차를 제곱해 계산하는 식으로, 그 값이 매우 커지는 경향이 있음 이를 보완하기 위해, Root 를 씌움 또한 성능평가 수치가, y 예측 값과 그 단위가 같으므로 직관적인 에러수치 에러에 따른 Loss 가 기하 급수적으로 올라가는 상황에서 쓰기 적합 MAE 와 함께 가장 일반적으로 많이 쓰이는 회귀모델 성능분석지표 4. R2 Score (Coefficient of Determination : 결정계수) R2 Score 는 실제 y의 변동량 대비 모델 예측 y의 변동량을 의미 즉, 실제 y값의 분산에 비해, 예측 y의 분산이 얼만큼인지 비교 해당 회귀 모델이 주어진 데이터에 얼마나 적합한지를 평가하는 지표 상관관계가 높을수록 1에 가까워짐 (해석 예시) r2 score=0.4라면, 40%의 설명력을 가진다고 해석 MAE, MSE, RMSE 는 에러에 대한 수치이므로, 그 수치가 작을 수록 좋은 지표 R2 Score 는 1에 가까울 수록 성능이 좋음 R2 Score 계산 $$R^2 Score=1-\\frac {SSE} {SST} = 1- \\frac {MSE} {Var(y) }$$ $$SSE=\\frac {1} {n} \\Sigma (y_{true}-y_{pred})^2$$ $$SST=\\frac {1} {n} \\Sigma (y_{true}-y_{mean})^2$$","link":"/2022/02/10/Regression-Score/"},{"title":"SPARK BASIC 1","text":"Apache Spark Basic 1 SPARK 를 공부하면서 실습 과정을 정리해서 남깁니다. 실습환경 CentOS Spark 2.4.3 Hadoop 2.7 1. Spark-shell1-1. Introductionshell의 spark home directory 에서 다음 명령어를 통해 spark shell 을 진입할 수 있습니다. $ cd /spark_home_directory/ $ ./bin/spark-shell sc : spark context spark : spark session spark context 와 spark session 의 경우, spark shell에 띄우면서 내부적으로 선언된 변수명이다. $ jps // jps 명령어를 통해 현재 돌고 있는 spark process 를 확인할 수 있다. // spark processor 가 jvm 을 바탕으로 돌기 때문에, jvm 프로세스가 도는 것을 확인하므로써 // 확인 할 수 있는 것이다. http://localhost:4040, 즉 해당 서버의 ip:4040 포트를 통해서 드라이버에서 제공되는 웹 UI 를 확인할 수 있다. 이 웹 UI 를 통해 현재 작동하는 프로세서와 클러스터들을 관리 할 수 있다. 1-2. RDDspark는 data를 처리할 때, RDD 와 Spark SQL 을 통해서 data object 를 생성하고 이를 바탕으로 다양한 pipeline 으로 동작 할 수 있다. RDD 를 처음 접해보는 실습. //scala shell val data = 1 to 10000 val distData = sc.parallelize(data) distData.filter(_ &lt; 10).collect() data 가 RDD sc.parallelize의 return 형 역시 parallelize 된 RDD, 즉 distData 도 RDD 마지막 command line 은 10보다 작은 data 에 대해 filtering 하고 각 executor 에서 실행된 자료를 collect() spark 의 특징은 .collect() 와 같은 action api 가 실행될 때 모든 것이 실행되는 **Lazy Evaluation (RDD)**으로 동작한다. 드라이버 웹 UI 를 통해 이를 확인 할 수 있다. 이전 command line 에서는 아무 동작도 일어나지 않다가 collect() action api 수행을 통해 실제로 command들이 수행되는 것을 확인 할 수 있다. local 에서 default 로 동작하기 때문에 2개의 partition 으로 동작하며, 어떤 shuffling 도 일어나지 않았기 때문에 1개의 stage 임을 확인 할 수 있다. // scala shell // sc.textFile 을 통해 textfile, md 파일등을 읽어드릴 수 있다. val data = sc.textFile(&quot;file_name&quot;) // rdd 의 .map api 를 통해서 rdd 의 element 마다 val distData = data.map(r =&gt; r + &quot;_experiment!!&quot;) // 앞선 map 이 수행되고, 각 element(data) 갯수를 세개 된다. distData.count 여기서는 .count 가 action api 이므로, .count 가 수행될 때, 앞선 command 들이 수행되게 된다. sc.textFile() 의 경우 ‘\\n’, newline 을 기준으로 element 를 RDD 에 담게 된다. RDD.toDebugString 를 통해 해당 RDD 의 Lineage 를 확인 할 수 있다. 가장 왼쪽에 있는 | 를 통해 stage 정보 역시 확인 할 수 있다. shuffle 이 일어나게 되면, stage가 바뀌므로, 서로 다른 stage 에 있는 command 의 경우, 다른 indent에 있게 된다. RDD.getNumPartitions 를 통해 해당 RDD의 Partition 갯수 (=Task 의 갯수), 즉 병렬화 수준을 확인 할 수 있다. Shuffle!!suffle 이 일어나는 경우는 api 마다 다양할 수 있다. 가장 기본적으로, 우리가 default partition 갯수를 변경하므로써 shuffle 이 일어나는 것을 확인 할 수 있다. val data = sc.textFile(&quot;file_name&quot;) data.getNumPartitions // Partition 의 숫자를 확인해보면, default 이므로 2 인 것을 확인 할 수 있다. val newData = data.repartition(10) newData.getNumPartitions // Partition 갯수가 10로 변경된 것을 확인 할 수 있다. newData.toDebugString // newData 의 Lineage 를 확인하면, repartition 이 일어나면서 shuffle 이 되고, // shuffle 로 인해 stage 가 2개가 되는 것을 확인 할 수 있다.(indentation) newData.count // action api 를 수행하여 앞선 command 를 모두 수행 위 command line 에 대한 DAG 를 웹 UI 를 통해 확인하면, 다음과 같이 stage 가 repartition을 기점으로 나누어 지는 것을 확인 할 수 있다. 총 Partition의 갯수 (Task의 갯수)를 확인해 보면, default 로 수행된 partition 2 개와, 우리가 설정해준 Partition 의 갯수인 10개를 합하여 12개인 것을 확인 할 수 있다. 여기서 한 스텝을 더 들어가보면, spark 만의 특이한 특징을 확인 할 수 있다. // 위 코드에 이어서, newData 에 대해 // newData RDD를 collect 해서 cli에 찍는 command 를 수행해보자. newData.collect.foreach(println) collect api 와 RDD의 element를 print 를 하는 action api 를 수행할 때, 지금까지 공부한 것으로 생각해 보면, text를 읽어서, 2개의 Partition 을 나누고, 다시 10개의 Partition 을 나누는 작업으로 이전의 12 개의 Task 와 다를게 없을 것 같은 느낌이다. 하지만 UI 를 통해 확인해보면, 10개의 Partition 으로 2개가 skipped 되었다고 확인할 수 있다. DAG 에서도, skipped 된 stage에 대해서 회색으로 확인된다. 이는 spark 에서 이 커맨드라인을 수행할 때, process 간 통신이 file 을 기반으로한 통신을 했기 때문이다. 제일 처음 newData 에 대해서 수행 될 때, 첫 stage 에서 shuffle 이 수행 될 때, 해당 파일을 각 executor 에서 shuffle write 을 하고 저장해두었다가, 두번째 stage 에서 shuffle 이 수행 될때, shuffle read 를 하는 방식으로 file을 기반으로 processor 가 통신하게 된다. 따라서, spark 가 같은 command line 을 수행하게 되면 미리 shuffle write 된 file 을 읽기만 함으로써 앞선 stage 의 동일한 반복 작업을 수행하지 않게 되는 것이다. UI 를 확인 해보아도, shuffle read 만 수행 되었다. SaveFile!!!RDD.saveAsTextFile(&quot;directory_name&quot;) api 를 활용하여, 어떤 처리가 끝난 RDD 를 저장할 수 있다. 이 때 주의 할 점은 parameter 에 들어 가는 것이 directory_name 이라는 것이다. 또한 partition 별로 파일이 저장된다. (e.g. 10개의 partition 이라면, 10개의 file이 저장된다.) Cache!!!spark가 자랑하는 가장 큰 특징은, data(RDD) 를 memory에 cache 함으로써 처리의 속도가 매우 빠르다는 점이다. RDD.cache api 를 통해 memory 에 캐시할 수 있다. // distData RDD 에 이름을 부여 distData.name = &quot;myData&quot; // cache! distData.cache // action : 5 개의 data 를 가져옴 distData.take(5) // action : collect distData.collect distData.take(5) 까지 한 결과를 UI 에서 cache 를 살펴보면, 다음과 같다. 우리가 설정 한 것 처럼, RDD 의 이름이 myData 로 들어간것을 확인 할 수 있고 cache 역시 확인 할 수 있다. 하지만, Cached 된 비율을 확인하면 전체 RDD 에서 50% 만 된 것을 확인 할 수 있다. 반면에, distData.collect action 을 취하게 되면, Fraction Cached 가 100% 가 된 것을 확인 할 수 있다. 이는 우리의 action 에 따라 cache 할 용량이 달라 질 수 있기 때문이다. spark 입장에서 take(5) api 는 전체 RDD 중 5개의 element data 만 가져오면되고, 이 때 2개의 Partition 중 하나의 Partition 만 cache 해도 충분하기 때문에 Fraction Cached가 50%라고 나오는 것이다. 반면 collect api 는 collect 자체가 각 executor 에 있는 data 를 driver 로 모두 가져오는 것이므로 100% cache 하게 된다. Cache 에서 중요한 것은, 각 executor 의 cache 를 위한 가용 메모리 공간이 해당 Partition의 용량보다 작을 경우, 저장 할 수 있는 용량만큼 저장되는 것이 아니라, 해당 Partition 은 아예 저장이 안되게 된다. 이 점은 Cache를 할 때, Partition 의 용량과 해당 Executor 의 가용 메모리 공간을 미리 파악하여, 설계해야 한다. Word Count 예제!!!우리가 데이터 분석을 할 때, 가장 basic 한 방법은 해당 데이터의 갯수를 세어 보는 것이다. 본 예제에서는 텍스트 파일을 읽어, 띄어쓰기를 바탕으로 word token을 나누고, 이를 세어보자. WordCount 예제는 매우 basic 한 코드이므로, 어떤 로직으로 돌아가는지 완벽한 이해와 코드작성이 필수라고 생각한다. val originalDataRDD = sc.textFile(&quot;text-file&quot;) val wordcountRDD = originalDataRDD.flatMap(line =&gt; line.split(&quot; &quot;)) .map(word =&gt; (word, 1)).reduceByKey(_ + _) wordcountRDD.collect.foreach(println) originalDataRDD 에서 text-file을 읽고, line 마다 띄어쓰기를 기준으로 split 하고 이를 .flatMap 을 통해, flatten 하게 됩니다. 그리고 .map 을 통해 (word, 1) tuple 형태로 mapping 합니다. .reduceByKey 를 통해 같은 word 에 대해 그 counting 갯수를 더하게 된 것을 RDD 로 return 하게 됩니다.","link":"/2019/05/31/SPARK-BASIC-1/"},{"title":"Selenium","text":"Selenium 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. 자동화 할 수 있는 프로그램 [ Install Selenium ] chrome driver 다운로드 1$ mv ~/Download/chromedriver /usr/local/bin Selenium Python Package 설치 1$ sudo pip3 install selenium 1. 셀레니움 사용해보기 import1from selenium import webdriver Open Browser (Chrome Driver)1driver = webdriver.Chrome() 페이지 이동1driver.get(url) 브라우져 상에서 자바 스크립트 실행1driver.execute_script(&quot;window.scrollTo(300, 400)&quot;) 지금 control하고 있는 window 객체 확인123main_window = driver.current_window_handlemain_window#현재 control 하고 있는 window 의 객체를 리턴한다. 열려 있는 전체 window 탭 모두 확인123windows = driver.window_handleswindows#현재 열려있는 모든 탭의 객체를 리스트 형태로 리턴한다. 열려있는 window 탭 중, control 대상 window 로 바꾸기123driver.switch_to_window(windows[0])#다시 원래 열었던 창으로 돌아가기driver.switch_to_window(main_window) 2. Alert 와 Confirm 다루기 웹을 자동화해서 다니다보면, Alert 창이나 Confirm 창이 의도치 않게 나올 수 있다. 이를 다루는 방법은 다음과 같다. Alert와 Confirm 창의 차이는, Alert 는 확인 창 하나만 있고, Confirm은 확인과 취소가 같이 있는 창이다. (1) Alert Alert 띄우기12drive.switch_to_window(main_window)drive.execute_script(&quot;alert('이게 alert 로 뜰겁니다.');&quot;) Alert 확인 누르기12alert = driver.switch_to.alertalert.accept() Alert 창이 있으면 확인을 누르고, 없으면 없다고 리턴하기 (예외처리)12345try: alert = driver.switch_to.alert alert.accept()except: print(&quot;alert 가 없습니다.&quot;) (2) Confirm Confirm 띄우기1driver.execute_script(&quot;confirm('이게 Confirm 창입니다.');&quot;) Confirm 창 확인 누르기 or 취소 누르기12345confirm = driver.switch_to.alert# 확인# confirm.accept()# 취소confirm.dismiss() 3. 입력창에 글씨 입력하기 이제부터 Selenium을 통해 특정 html 의 element 에 액션을 주려면,각종 Selector 를 사용하여 html 상의 element을 셀렉팅 하고, 해당 element 에게 액션을 주어야한다. 1driver.find_element_by_css_selector(nameof cssselector).send_keys(&quot;입력할 내용&quot;) .find_element_by_css_selector 와 .find_elements_by_css_selector 는 다르다.element 는 하나의 selector 만 선택하는 반면, elements 는 여러가지 element 를 셀렉팅 해서, 리스트 형식으로 Return 한다. 따라서 이렇게 리스트 형식으로 Return 이 된 경우, List[0] 등과 같이 그 엘리먼트를 뒤에 지정해줘야된다. 즉,1234driver.find_element_by_css_selector(nameof cssselector)#위는 바로 selecting 이 된것이지만,driver.find_elements_by_css_selector(nameof cssselector)[0]#위는 뒤에 selecting 위해 list 의 요소를 선택 해주어야한다. 4. 버튼 클릭하기12# 위의 방법처럼, element 를 선택해준다.driver.find_element_by_css_selector(&quot;name of css selector&quot;).click() 5. id, class, 그 외의 attribute 값을 selecting 하는 법1234driver.find_element_by_css_selector(&quot;name of css selector.&quot;).click()# id 의 경우 : #idname# class 의 경우 : .classname# 다른 attribute 의 경우 : [attribute = 'value'] 6. selecting 한 element 의 attribute value 를 얻는 방법 CSS로 선택한 element에 html 태그에는 다양한 attribute 들이 있을 수 있다. 이 중attribute의 value에 접근 하고 싶을 때는 .get_attribute()메소드를 사용할 수 있다.1driver.find_element_by_css_selector(&quot;name of css selector&quot;).get_attribute(&quot;attribute_name&quot;) 7. element 의 위치와, 사이즈 구하기 스크롤을 내리거나, 엘리먼트의 위치와 크기를 알고 싶을 때 사용할 수 있다.12345element = driver.find_element_by_css_selector(&quot;name of css selector&quot;)element.location#element 의 좌측 상단의 위치가 pixel 단위로 x, y 값의 dictionary로 보여준다.element.size#element 의 size 를 height, width를 pixel 단위로 dictionary로 보여준다.","link":"/2018/10/24/Selenium/"},{"title":"Stack","text":"Stack 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. Stack 의 특징 접시를 쌓듯이 데이터를 쌓아 올리는 모양의 데이터 구조 LIFO : Last In First Out == 후입선출 or 선입후출 top index 가 항상 Stack의 가장 윗부분을 가리키고 있어, 우리는 top 위치만 볼 수 있다. 단점 : stack 의 top 이 외에 밑에 쌓여져있는 데이터의 Search 가 안된다. ADT empty() 라는 메소드로 Stack 에 data가 있는지 없는지 확인하게 한다. empty 이면 True, not empty 이면, False 를 return 한다. Stack.empty() returns Boolean 2. Stack의 top 위치에 데이터를 쌓는다. Stack.push(data) returns None Stack의 top 위치에 있는 데이터를 삭제하면서 반환한다. Stack.pop() returns data 4. Stack의 top 위치에 있는 데이터를 반환하지만, 삭제하지 않는다. 어떤 데이터가 있는지 just 확인. Stack.peek() returns data 구현 1 : by python list Stack 구조를 Python에 내장 되어 있는 list를 container 로 삼아 구현하게 되면, 그 구현은 매우매우 쉽다. Python의 List 자료형의 대단함을 그만큼 느낀다. 이 때 List 의 index가 큰 쪽이 top 방향이다.12345678910111213141516171819202122class Stack: def __init__(self): self.container=list() def empty(self): # ADT 를 따라서, 비어 있으면 return True 비어있지 않으면 return False if not self.container: return True return False def push(self, data): # list 를 활용했으므로, list.append(data)를 활용할 수 있다. self.container.append(data) def pop(self): # pop 역시 list.pop()을 활용할 수 있다. return self.container.pop() def peek(self): # peek은 단지 top 에 어떤 데이터가 있는지 확인 하는 것 뿐이므로, 현재 리스트의 가장 마지막에 append 되어 있는 data를 확인하면 된다. return self.container[-1] 구현 2 :","link":"/2018/10/22/Stack/"},{"title":"Requests","text":"WEB CRAWLING 1 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. Requests Requests 패키지는 크롤링 하고자 하는 페이지를 url 값을 통해 가져와 객체로 변환 해주는 기능을 가지고 있다. 1. Installation Requests 를 이용하기 위해 package 를 설치해준다.1$ pip3 install requests request를 이용하면서, json 형식으로의 크롤링과, html 형식으로 css selecting 을 위한 크롤링을 실습해 볼 것이므로, BeautifulSoup Package 역시 같이 설치해준다. (BeautifulSoup은 html parser 를 이용해보기 위함이다.) python-forecastio 는 dark sky 의 api를 활용해 날씨 데이터를 받아올때 사용해보기 위해 설치한다.12$ pip3 install bs4$ pip3 install python-forecastio import 할 것들1234import requestsimport forecastiofrom bs4 import BeautifulSoupfrom pandas.io.json import json_normalize 2. [ jSON ] Dark Sky api 활용 날씨정보 가져오기 DarkSky api 는 위도와 경도를 입력하면, 날씨 정보를 주는 api 이다. https://darsky.net/dev/ 에 가입 후, TOKEN 을 받는다. 위에서 받은 개인의 TOKEN 을 활용해 url 을 먼저, formating을 해준다. requests의 get 메소드를 활용해 url 의 정보를 받아온다. 받아온 정보를 requests 의 json 메소드로 json 형식으로 변환해준다. json 을 확인하고 원하는 정보를 return 해준다. 12345def forecast(lat, lng): url = &quot;https://api.darksky.net/forecast/{}/{},{}&quot;.format(TOKEN, lat, lng) response = requests.get(url) json_obj = response.json() return json_obj[&quot;hourly&quot;][&quot;summary&quot;] 3. [ html ] BS4 활용 html selecting 해서 가져오기 네이버의 실시간 검색순위 부분의 text 를 크롤링 해보자 html 파일을 BS4 를 활용해 받아온뒤, CSS selecting 으로 원하는 text data 를 가져온다. 123456789101112131415from bs4 import BeautifulSoupdef naver(): url = &quot;https://www.naver.com&quot; df = pd.DataFrame(columns=[&quot;rank&quot;, &quot;keyword&quot;]) response = requests.get(url) dom = BeautifulSoup(response.content, &quot;html.parser&quot;) # BeautifulSoup(markup, features, builder, parse_only, from_encoding, exclude_encodings) for keyword in keywords: df.loc[len(df)] = { &quot;rank&quot;:keyword.select_one('.ah_r').text, &quot;keyword&quot;:keyword.select_one('.ah_k').text } return df print(response.content)의 모양을 보자. 따라서, BeautifulSoup 으로 html 형식으로 parsing 해주고, css 를 활용해 selecting 해준다. .select 는 여러개의 엘리먼트를 선택 -&gt; 결과가 리스트 .select_one은 하나의 엘리먼트를 선택 -&gt; 결과가 하나의 객체","link":"/2018/10/24/Requests/"},{"title":"Scrapy","text":"Scrapy 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. Scrapy 라이브러리는 파이썬에서 제공하는 라이브러리로써, 대량의 페이지들의 Crawling을 손쉽게 해주는 라이브러리이다. 1. Install 파이썬의 라이브러리 이므로 pip 으로 설치 할 수 있다.1pip3 install scrapy 2. 실습 실습을 위해 import 할 것들 123import scrapyimport requestsfrom scrapy.http import TextResponse requests 를 통해 url 정보를 받아온다. TextResponse 를 통해 받아온 html 파일을 encoding 과 text형식으로 return 12req = requests.get(&quot;url_name&quot;)response = TextResponse(req.url, body=req.text, encoding=&quot;utf-8&quot;) 123456a = response.xpath('xpath')# xpath 로 지정한 엘리먼트를 가져온다.a_text = reponse.xpath('xpath/text()')# 엘리먼트의 text data 를 가져온다.a_text.extract()# 엘리먼트의 text data들을 말그대로 extract 하여, list 형태로 return 해준다 3. Scrapy 사용하기(1) scrapy 프로젝트 생성 shell command1scrapy startproject crawler 1!scrapy startproject crawler New Scrapy project 'crawler', using template directory '/Users/emjayahn/.pyenv/versions/3.7.0/envs/dss/lib/python3.7/site-packages/scrapy/templates/project', created in: /Users/emjayahn/Dev/DSS/TIL(markdown)/crawler You can start your first spider with: cd crawler scrapy genspider example example.com 1!tree crawler crawler ├── crawler │ ├── __init__.py │ ├── __pycache__ │ ├── items.py │ ├── middlewares.py │ ├── pipelines.py │ ├── settings.py │ └── spiders │ ├── __init__.py │ └── __pycache__ └── scrapy.cfg 4 directories, 7 files (2) Scrapy 기본 구조 Spider 크롤링 절차 정하기 어떤 웹사이트들을 어떻게 크롤링 할 것인지 선언 각각의 웹페이지의 어떤 부분을 스크래핑 할 것 인지 명시하는 클래스 items.py spider 가 크롤링한 data 들을 저장할 때, 사용자 정의 자료구조 클래스 MVC : 중 Model 부분에 해당 Feature 라고 생각 pipeline.py 스크래핑한 데이터를 어떻게 처리할지 정의 데이터에 한글이 포함되어 있을 때는 encoding=’utf-8’ utf-8인코딩이 필요 settings.py Spider, item, pipeline 의 세부 사항을 설정 (예) 크롤링 빈도 등 (예) robots.txt - ROBOTSTXT_OBEY=True","link":"/2018/10/26/Scrapy/"},{"title":"[논문읽기] Implementation of Vanilla GAN","text":"A pytorch implementation of Vanilla GAN using MNIST digits data(https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) 실험 결과와 코드는 https://github.com/EmjayAhn/GAN-pytorch 에서 확인 할 수 있습니다. 0. 목표GAN 은 최근 인기를 끌고 있는 generative model 중 하나입니다. 다양한 모델이 쏟아져 나오고 있기에, 이 트렌트를 따라가기 위해서, 가장 기본적인 vanilla gan 을 구현하고, 이해하는 것이 목표입니다. 이번 예제에서는 MNIST digit 을 사용하였으나, 이미지 외에도 다양한 데이터를 활용할 수 있습니다. 1. Model 구조GAN 의 아버지 Ian Goodfellow가 제안한 이 모델은 두가지 신경망으로 구성 되어 있습니다. 먼저, 우리가 가지고 있는 데이터와 비슷하게 데이터를 생성하는 것을 학습하는 Generator 와 Generator 가 생성한 데이터(fake)와 실제 우리가 가지고 있는 데이터(real)를 fake 인지 real 인지 구분하는 Discriminator 를 구분하는 두 신경망으로 구성되어 있습니다. 1-1. Generator Generator 는 Gaussian Random Noise (mean=0, std=1) 를 입력으로 받아, 이 noise로 부터 data 를 생성해냅니다. 이번 구현에서 Generator는 다음과 같이 작성하였습니다. Dense layer 만 사용했으며, gradient vanishing 현상을 막기 위해 activation 을 거친 후, Batch Normalization 을 추가하였습니다. 1-2. Discriminator Discriminator 는 Generator 가 생성해낸 데이터와 기존에 가지고 있는 진짜 데이터를 입력으로 받아, 진짜 데이터를 1, 가짜데이터를 0으로 학습하는 classifier 입니다. 아래의 Loss Function 을 확인 하겠지만, 진짜 데이터에 대해서는 그 확률 값을 높게 하고, 가짜데이터에서는 그 확률 값을 0에 가깝게 하는 것이 이 모델의 optimize 목표입니다. 이번 구현에서 Discriminator를 다음과 같이 작성하였습니다. 2. Loss Function2-1. Loss Function 의 해석$$\\underset{G}{\\text{min}}\\underset{D}{\\text{max}}V(D, G)=E_{xp_{data(x)}}[logD(x)]+E_{zp_{z}(z)}[log(1-D(G(z)))]$$ Vanilla GAN 의 Loss function 은 위와 같습니다. Loss Function 의 구조 자체는 min-max 최적화로써, Discriminator와 Generator 의 loss 함수를 각각 최적화 해 나아가면서 위 식의 균형 향해 다가가는 것입니다. 먼저, Discriminator에 대한 max 부터 살펴 보면, Real을 입력으로 넣었을 때는, log(D(x))의 기댓값이 최대가 되게 하고, G(z) 즉, 가짜를 가짜라고 할 확률 1-D(G(z))는 최대가 되게끔 학습을 하는 것입니다. Generator 에 대한 min 을 살펴보면, G(z) 는 가우시안 랜덤 변수를 받아 생성된 데이터를 D(G(z)), discriminator에 넣었을 때, 1-D(G(z)), 즉 가짜라고 할 확률을 최소화하게끔 학습하는 것입니다. 이는 결국, Discriminator를 속이기 위해 generator의 최적화가 실행된다는 의미입니다. 이 식에서 중요한 점은, Discriminator 는 학습할 때, Generator 가 생성한 데이터와 진짜 데이터 모두를 보며 학습하지만, Generator 는 그 어디에서도 진짜 데이터가 어떻게 생겼는지는 확인하지 않습니다. 오로지 Discriminator 를 속이기 위해 학습하는 것이지만, 그 결과 우리가 가지고 있는 진짜 데이터와 비슷하게 만들수 있는 모델을 획득하게 될 수 있는 것이라는 점에서 매우 획기적인 모델입니다. 2-2. 실제 구현에서의 변형Generator 에 대한 loss function 은 log(1-(D(G(z)))를 최소화 하는 것입니다. 하지만, log(1-x) 형태의 식은 x가 0일 때, 그 gradient 가 매우 작아, 학습이 매우 오래 걸리는 문제가 있습니다. 이를 해결하기 위해, log(1-D(G(z)))를 G에 대해 최소화 하는 것은 결국, -log(D(G(z)))를 최소화 하는 것과 같고, 이는 log(D(G(z)))를 최대화 하는 것과 같습니다. 따라서 실제 구현에서의 criterion 은 Discriminator 가 사용하는 criterion(여기선, binary cross enntropy loss)을 동일하게 사용합니다. 3. 학습 및 모델 결과학습 parameter 는 다음과 같습니다. Total epoch: 300 batch size : 128 z dimension : 100 Adam optimizer : lr=0.0002, weight_decay=8e-9 다음은 generator가 학습이 되가면서, 같은 가우시안 랜덤 노이즈에 대해 mnist 와 닮은 데이터를 생성해 나가는 과정입니다. (1) 0 epoch 약 400개의 배치를 학습한 후, 찍은 사진이기에 가운데에 아주 미세한 형태는 보이지만, 가우시안 노이즈임을 확인 할 수 있습니다. (2) 20 epoch 20 epoch 만 되더라도, (마치 뱃속의 아가처럼(?)) 가운데에 어떤 형태가 생성되기 시작하는 것을 확인 할 수 있습니다. (3) 100 epoch 9, 3, 8, (horizontal flipped) 3, 1.. 아주 힘들게 MNIST 와 비슷해 보이는 숫자를 확인 할 수 있습니다. 4. 결론이번 구현의 목표는 나의 첫 vanilla gan 을 논문과 여러 자료를 공부해보며, 구현해 보는 것에 있었기에, 이를 완수하고, 실제로 학습 시켰을 때, generator 로써 기능을 할 수 있다는 점에서 유의미 하였습니다. 다양한 repository 에서 서로 다른 framework 를 사용하여, gan 을 구현하는 것을 참조 할 수 있습니다. 하지만, 직접 공부해보고, loss function의 의미를 해석하여 직접 구현해보며 많은 것을 배울 수 있었습니다. 실제로 loss function 위 처럼 바꾸지 않았을 때는 1000 epoch 를 학습하더라도 generator가 학습 되지 않는 실패 경험을 통해, 자세한 논문 리딩과 분석은 구현에 있어 필수적임을 느낄 수 있었습니다. 5. Futher Study자원의 제약으로 작은 모델 구조와 hyper parameter tuning을 더 하지 못한게 아쉽습니다. generator 가 생성해내는 모양이 조금더 세밀하게 할 수 있는 것을 더 해보고 싶고, MNIST 데이터 뿐만아니라 본 논문의 참조사진처럼 CIFAR10 이나, TFD 데이터에 대해서도 실험해보고 싶습니다.","link":"/2019/08/13/Vanilla-GAN/"},{"title":"Thread","text":"Thread 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. 파이썬 기본 : Single Thread (Main Thread) threading 모듈 : main thread에서 subthread 를 생성하여 진행하는 방식 multiprocessing 모듈 : double cpu ThreadPoolExecutor : API - 멀티스레드와 멀티프로세스 동일한 형태로 디자인(Pool 클래스만 변경하면됨) threading.Thread() arguement12345Thread(group=, target=, args= , kwargs=, *, daemon=None)#target= : 실제 스레드에서 돌아가게 될 함수#args= : tuple 로 target 함수에 들어가게될 argument#kwargs= : dictionary로 target 함수에 들어가게될 argument#daemon : 데몬 스레드로 돌아갈지 여부 12345#Thread 의 메소드start(): #스레드의 실행, self 의 run() 메소드를 호출run(): #스레드가 실제로 수행하게될 작업name : #스레드의 이름threading.locals() : #해당 스레드 내부에서 사용할 로컬 변수 지정","link":"/2018/10/24/Thread/"},{"title":"Xpath","text":"xpath 공부한 내용을 스스로 보기 쉽게 정리한 글입니다. 1. xpath란? xpath = XML Path Language XML 문서의 element나 attribute의 value에 접근하기 위한 언어 XML 문서를 해석하기 위한 언어이므로, 기본적으로 path expression 이 바탕이 되어있다. 연산, 문자열 처리를 위한 라이브러리를 내장하고 있다. 2. Location Path element 를 찾으러 가는 것이므로, location을 나타내기 위한 연산자는 다음과 같다. element_name : element_name 과 일치하는 모든 element를 선택한다. / : 가장 처음 쓰는 /는 절대경로를 의미한다. Path 중간에 쓰는 /는 조건에 맞는 바로 다음 하위 엘리먼트를 검색한다. (css selector에서 &gt;와 같다) // : 가장 상위 엘리먼트 . : 현재 엘리먼트 * : 조건에 맞는 전체 하위 엘리먼트를 검색한다(css selector 에서 한칸 띄우는 것 과 같다) element[조건] : 엘리먼트에 조건에 해당되는 것을 검색한다 (예) p[2] : p 엘리먼트 중 두번째 엘리먼트를 선택 **주의:1부터 시작, 0이 아님 ** (예) [@(attribute_key=&quot;attribute_value&quot;)] : 속성값으로 엘리먼트를 선택 [@id=&quot;main&quot;] : “main” 이라는 id 를 선택 [@class=&quot;pp&quot;] : “pp” 라는 class 를 선택 not(조건) : 조건이 아닌 엘리먼트를 찾는다. /text() : 해당 엘리먼트의 text 데이터를 가져온다 /@attribute_name : 해당 엘리먼트의 attribute_name 에 할당된 value 값을 가져옴 /@href : 해당 엘리먼트의 href의 value 값을 가져옴","link":"/2018/10/26/Xpath/"},{"title":"[Python] 쉽게 쓰여진 Decorator","text":"오픈소스나, 다른 사람들이 만든 코드를 재수정한 코드, 제가 짠 코드에 대해 다양한 디버깅과 좀 더 다른 기능을 추가하고 싶을 때, 우리는 Decorator 를 자주 접하게 됩니다. Python 실력을 한층 업그레이드 하기 위함과, 코딩의 또 다른 목적이이 귀차니즘의 해결 이라고 생각할 때 Decorator 에 대한 이해는 그 시작 관문이 됩니다. 이번 글에서는 이 Decorator 에 대한 개념을 쉽게 설명하려고 노력하였습니다. 많은 책들에서 Decorator 의 설명을 본격적으로 들어가기에 앞서, python에서의 변수의 범위와 전역변수, 지역변수, 자유변수 등을 설명하고, 자칫 정신을 혼미하게 만들 수 있는 클로져(closure)를 설명한 뒤에 Decorator 를 만나게 됩니다. 물론 모두 Decorator 에서만아니라 파이썬을 다루고, 컴퓨터 과학을 공부하며, 필수적으로 알아야하는 중요한 개념이긴 하나, 이번 글에서는 예제들을 통해 Decorator 를 짜는 방법과 어떻게 구동이 되는지 실용적인 개념에 대해 요약 정리하려고 합니다. 1. Decorator란? Decorator : 호출 가능한 객체 로써, 호출 가능한 객체를 입력으로 받아, 호출 가능한 객체 를 반환하는 함수 Decorator 를 만들 때, 가장 첫번째로 성립해야하는 구조가 위처럼, Decorator 기능을 하게 될 함수가 호출 가능해야하고, 입력에 호출 가능한 객체를 받아, 반환하는 객체도 호출 가능한 객체로 반환 해주어야 합니다.위의 정의를 만족하는 세상에서 가장 간단한 Decorator 를 다음의 예제코드로 만들 수 있습니다. 위의 간단한 코드의 동작 순서를 살펴봅니다. 123456(3) 에서 say_hi 라는 함수 객체가 dumb_decorator 함수의 입력으로 들어가, dumb_decorator() 함수를 호출합니다.(1) 에서 dumb_decorator는 입력받은 함수 객체(say_hi) 자체를 반환합니다.dumb_decorator 가 반환한 함수객체를 (3)의 decorated 에 저장합니다. 3.에서 decorated는 함수 객체 자체입니다. (4) 에서 decorated() 로, 함수 객체를 실행한 결과를 text 에 저장합니다. 이 코드에서 결국 decorated 함수 객체가 실행되면, say_hi 함수가 실행되고, say_hi함수의 반환값인 &quot;Hi, Hi&quot; 가 text 에 저장되어,(5)에서 출력됩니다. 위의 코드의 결과는 Hi, Hi 가 출력되는 아무 기능이 없는 기본 함수(say_hi)와 Decorator 입니다. 위와 같은 결과이지만, Decorator 문법인 @를 사용한 코드는 다음과 같습니다. 위의 두 예제 코드는 같은 결과를 내지만, 앞서 정의된 dumb_decorator 가 첫번째 예제에서는 꾸미려고하는 say_hi 함수를 dumb_decorator의 입력으로 넣어주어 코드를 실행 시켜 주어야 했습니다. 두번째 예제에서는 꾸미려고하는 say_hi 함수의 선언시 @dumb_decorator 를 먼저 적어주고, 꾸며진 함수 say_hi() 를 실행하는 점에서 차이가 있습니다.앞서 처음에 등장한 구조적 정의를 위 예제에 대입하여 살펴봅니다. Decorator : 호출 가능한 객체 로써, 호출 가능한 객체를 입력으로 받아, 호출 가능한 객체 를 반환하는 함수 호출 가능한 객체로써 (dumb_decorator), 호출 가능한 객체(say_hi)를 입력으로 받아, 호출 가능한 객체((1)에 return func)를 반환하는 함수 일 때, @decorator로 동작 할 수 있습니다. 2. Decorator를 Decorator 처럼1에서 Decorator의 핵심적인 구조를 살펴보았습니다. 이제 본격적으로 Decorator를 사용되기 위해선, decorator 내부에 입력함수의 기능을 꾸며주는 wrapper 함수가 필요합니다. 예제로 살펴보겠습니다. 첫번째 예제와 다른 점이라곤, 우리가 꾸미려고 하는 decorator 함수 안에 내부 wrapper 함수를 추가해줌으로써, 우리가 꾸미려는 내용을 선언해주었습니다. 3. Decorator 의 장점?위에 본 예제를 극단적인 case 로 몰고 가보죠. 우리가 꾸며야할 함수가 많다고 상상해 보겠습니다. 기존에 잘 동작하던 프로그램이 있을 때, 프로그램의 로그가 궁금하다던가, 신경망을 학습시키는 코드에 대해 각 layer 의 gradient 나 출력값을 보고 싶을 수 있습니다. 우리가 decorator 를 사용하지 않는다면, 첫번째 코드 예시 처럼 일일히 다 실행시켜주어야 하는 문제가 발생합니다. 우리는 사용하려고 하는 함수를 선언할때 @decorator 를 붙여 줌으로써, 이러한 귀차니즘을 해결할 수 있습니다. 예제를 통해 살펴보겠습니다.기존에도 잘 돌아가는 프로그램 3개의 log 를 찍어야 하는 순간이 찾아왔다고 가정합니다. generator 를 사용하는 것과 그렇지 않은 것을 비교해봄으로써 generator 의 고마움을 느껴볼 수 있습니다. 이번 예제에서는 간단하게 그 log 를 프로그램 return 형의 글자(character) 수로 생각해보죠. 기존에 존재하던 프로그램이 program_1, program_2, program_3 이라고 생각해보고, 추가적으로 우리가 my_decorator 라는 코드를 통해 각 프로그램의 로그(여기선, charater 수)를 찍어야 하는 task 가 주어졌습니다. 우리가 decorator 를 알기 전이라면, 위와 같이 코드를 작성해 준 후,실행부분에서 각 프로그램을 decorator 에 넣어주어, 꾸며진 결과 객체를 가지고, 이를 다시 실행해주는 행동을 반복해 주어야 합니다. 이제 decorator 의 고마움을 느껴볼 차례입니다. 4. 마치며간단한 예제를 통해 Decorator 가 어떻게 동작하는지, 어떻게 구성해야하는지 핵심적인 부분이 이해됐길 바랍니다. 조금더 공부할 수 있는 키워드는 클로져 (closure), free variable 등이 있을 수 있습니다. 위 키워드의 공부를 통해 조금더 자유로운 generator 설계를 할 수 있을 것으로 믿습니다.","link":"/2019/07/27/decorator/"},{"title":"[GCP] Computing Engine 환경설정","text":"Computing Engine 환경설정 이번 글은, Google Cloud Platform의 Computing Engine 인스턴스의 기본적인 환경설정 방법을 소개하는 글입니다. 직접 작업환경을 세팅하면서, 정리 하는 목적으로 작성하는 글입니다. 다음과 같은 환경을 설정합니다. 인스턴스 생성 및 네트워크 설정 접속을 위한 ssh 생성 및 접속 python3, pip3 설치 CUDA 설치 cuDNN 설치 Pytorch 설치 Jupyter 설치 및 환경설정 1. 인스턴스 생성 및 네트워크 설정Compute Engine에서 자신의 목적에 맞는 리소스를 정해, 인스턴스를 생성해줍니다. Jupyter notebook 을 사용하기 위해, VPC 네트워크 → 방화벽 규칙 탭에서 방화벽 규칙을 만들어 줍니다. 후에 Tensorboard 와 다른 기타 환경들을 사용할 때 그에 맞는 포트 규칙을 동일한 방법으로 열어주면 됩니다. 아래의 4가지를 설정해주고 ‘만들기’ 클릭 이름 : jupyter 소스 IP 범위: 0.0.0.0/0 대상 태그: jupyter tcp: 8888 http, https: 체크 2. 접속을 위한 RSA key pair 생성 및 ssh 접속 gcp 에서 제공하는 gcloud로도 접속 할 수 있습니다. 위에서 생성한 인스턴스에 접속하기 위해, RSA key pair 를 이를 통해 접속 해 봅니다. 아래의 명령어를 이용해 키페어를 생성해 줍니다. 이 때, USERNAME 은 gcp에 등록한 이메일로 설정합니다. $ ssh-keygen -t rsa -f ~/.ssh/[KEYFILE_NAME] -C “[USERNAME]” example) $ ssh-keygen -t rsa -f ~/.ssh/gcp-key -C “myemail@mail.com“ 앞으로 사용할 Password 를 입력하고, 생성된 키페어는 .ssh 폴더 안에서 확인 할 수 있습니다. .ssh/[KEYFILE_NAME].pub 를 확인해 볼 수 있습니다. 생성한 키페어를 gcp 의 메타데이터 탭 → SSH 키에 등록합니다. ssh 접속 $ ssh -i ~/.ssh/[KEYFILE_NAME] [USERNAME]@[GCP외부IP] 3. Python3, PIP 설치위에서 서버에 접속했다면, 서버의 개발환경을 설정해 주기만 하면 됩니다. python3 와 pip 부터 설치해 봅니다. locale 설정 123456$ sudo apt install language-pack-ko$ sudo locale-gen ko_KR.UTF-8$ export LC_ALL=&quot;en_US.UTF-8&quot;$ export LC_CTYPE=&quot;en_US.UTF-8&quot;$ sudo dpkg-reconfigure locales en_US.UTF-8이 [*] 로 체크 되어 있는지까지 확인합니다. Python3, PIP 설치 12$ sudo apt update$ sudo apt install python3-pip 설치 후, python3 --version 으로 python 이 잘 설치 되었는지 확인합니다. 4. CUDA 설치우리가 가장 원하는 리소스인 gpu를 활용한 연산을 위해 CUDA 를 설치 해 줍니다. 먼저, 설치 파일을 다운로드 해줍니다. 12// 루트에서$ wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64 ls 로 cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb 이 잘 다운로드 되었는지 확인 해 줍니다. 다운로드 결과 .deb 확장자가 되어있지 않다면, 파일명에 .deb 를 뒤에 붙여 줍니다. mv cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64 cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb 설치12345$ sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb$ sudo apt-key add /var/cuda-repo-&lt;version&gt;/7fa2af80.pub### $ sudo apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub$ sudo apt update$ sudo apt install cuda CUDA 가 정상적으로 설치되었다면, $ nvidia-smi 를 통해 자신의 gpu 상태를 확인 할 수 있습니다. 또한, /usr/local/cuda/version.txt 에 설치한 CUDA, 현재는 10.0의 version 을 확인 할 수 있습니다. NVIDA tool-kit 설치1sudo apt install nvidia-cuda-toolkit 5. cuDNN 설치다음의 명령어를 통해 cuDNN 을 설치 할 수 있습니다. 123$ sudo sh -c 'echo &quot;deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /&quot; &gt;&gt; /etc/apt/sources.list.d/cuda.list'$ sudo apt update$ sudo apt install libcudnn7-dev 6. Pytorch 설치 우리는 서버가 https 프로토콜을 사용한다고 체크했으므로 -H flag 를 주어 sudo pip3 를 활용해야합니다.12$ sudo -H pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl$ sudo -H pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl 7. Jupyter Notebook 설치 및 환경설정 Jupyter를 설치합니다. 1$ sudo -H pip3 install jupyter 설치 후, $ jupyter notebook 으로 주피터 커널이 켜지는지 확인합니다. 주피터 config 파일을 생성합니다. 1$ jupyter notebook --generate-config 비밀번호를 생성합니다. 이 비밀번호는 지금 설치한 주피터 환경에 들어가기 위한 비밀번호 입니다. 12345$ ipythonfrom notebook.auth import passwdpasswd()Enter Password: 사용할 비밀번호 입력Verify Password: 사용할 비밀번호 입력 출력된 비밀번호 해쉬 sha1: ~~~ 를 복사해 둡니다. 우리의 인스턴스는 https 프로토콜을 사용하므로, SSL 키파일을 생성해야 합니다. 1$ openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout cert.pem -out cert.pem 위 명령어를 입력하고, 뒤따라 나오는 정보들을 입력하여, .pem 파일을 생성합니다. 에서 생성한 config 파일 수정1$ vi /home/[USERNAME]/.jupyter/jupyter_notebook_config.py 123456// config 파일에 다음의 내용을 추가합니다.c = get_config()c.NotebookApp.ip = '내부아이피주소'c.NotebookApp.open_browser=Falsec.NotebookApp.password='3에서 생성한 비밀번호 해쉬 sha1:~'c.Notebook.certfile='4에서 생성한 .pem 파일 경로 /home/USERNAME/cert.pem' 위까지 완료하게 되었으면, 주피터 서버를 열고, https://외부아이피:8888 로 주피터를 접속 하는 것을 확인하시면 되겠습니다.","link":"/2019/06/17/gcp-setting/"},{"title":"[Linux] LightGBM GPU 버전 설치 및 환경설정","text":"LightGBM GPU 버전 Install의 경우,OpenCL 기반의 LightGBM-GPU와 CUDA 기반의 LightGBM-CUDA 버전이 있다.리눅스 환경에서 LightGBM의 설치와 환경설정은 자칫 까다로울 수 있다. 이번 글을 통해 정리해보자. OpenCL Version DocumentationInstallation Guide - LightGBM 3.3.2 documentation CUDA Version DocumentationInstallation Guide - LightGBM 3.3.2 documentation 현재 환경은 NvidiaA100 GPU의 CUDA 환경이 미리 셋팅 되어 있어, 기존 LightGBM-GPU 버전이 아닌, CUDA 버전을 설치하려고 한다. 1. 환경변수 설정CUDA 환경을 설정하면, CUDA의 환경변수를 각 계정별로 셋팅 해주어야 한다. 12345678910$ vi ~/.bashrc# .bashrc에 다음의 환경변수를 추가해준다.# CUDA SETTINGexport PATH=$PATH:/usr/local/cuda-11.6/binexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.6/lib64export CUDADIR=/usr/local/cuda-11.6# 저장후 반드시 실행$ source .bashrc 2. Download LightGBM1git clone --recursive https://github.com/microsoft/LightGBM 3. Build12345cd LightGBMmkdir buildcd buildcmake -DUSE_CUDA=1 ..make -j4 4. Install12cd ../python-packagepython3 setup.py install 5. Troubleshooting 지금 환경의 경우, root에 python이 설치 되어있고, 환경변수를 설정해 각 계정 별로 python 과 pip (python package manager) 가 독립되어 있는 환경이다. 위의 python3 [setup.py](http://setup.py) install 을 하는 경우, 다음과 같은 에러가 난다. 이는 root에 있는 site-packages에 현재 lightgbm 을 설치하는데 있어, permission denied : 권한 설정 에러이다. 회사의 python은 절대 루트에서 작업하지 않는 원칙으로 환경을 설정했고, 이 에러는 당연하다. 따라서 해당 계정 패키지 매니저에 위 과정에서 compile 된 lightgbm을 설치해 주면 된다. 위 [setup.py](http://setup.py) 실행을 통해 컴파일된 파일을 이용하여, 계정 패키지 매니저에 설치해준다. 1python3 -m pip install --install-option=--precompile --user . 6. 정상 설치 확인","link":"/2022/12/05/light-gbm-setting/"},{"title":"[Linux] 자고있을 때도, 알아서.. 리눅스 Crontab","text":"데이터를 모으기 위해 크롤링을 진행하거나, 머신러닝, 딥러닝 실험을 할 때 Linux 환경의 머신에서 정해진 시간과 주기에 맞추어 크롤링을 실행하고, 학습을 해준다면, 수많은 작업들을 미리 설정해둔 내용을 바탕으로 편하게 작업을 자동화 할 수 있습니다. 1. Crontab 스케줄 작성, 삭제, 목록 확인1-1. Crontab 스케줄 작성하기 1$ crontab -e -e (edit) 옵션으로 Crontab 의 스케쥴을 설정해 줄 수 있습니다. 작성할 스케쥴은 리눅스의 디폴트 에디터인 vi 에디터를 이용합니다. 1-2. Crontab 스케줄 지우기 1$ crontab -r -r (remove) 옵션으로 Crontab 에 등록된 스케줄을 삭제해 줄 수 있습니다. 1-3. Crontab 스케줄 목록 확인하기 1$ crontab -l -l (list) 옵션으로 Crontab 에 등록된 스케줄 리스트를 확인 할 수 있습니다. 2. Crontab 주기항상 사용할 때마다, 헷갈리고 잊어버리는 설정 주기 순서입니다. 마지막의 요일 부분은 0, 7: 일요일, 1: 월요일 ~ 6: 토요일 12* * * * *분 시간 일 월 요일 예를 들어, 매주 월요일에 crawling.py 를 실행한다면, 아래와 같이 crontab edit 창에서 작성하고 저장하면 됩니다. 1* * * * 5 python3 /directory/crawling.py 이제부터는 조금 복잡한 주기를 설정할 수도 있습니다. 2-1. 반복 - 매시 25분, 45분에 실행하고 싶을 때 125,45 * * * * python3 /directory/crawling.py - 매 20분마다 실행하고 싶을 때 1*/20 * * * * python3 /directory/crawling.py 2-2. 범위 - 매주 수요일에서 금요일까지 1시 30분마다 실행 시킬 때 130 1 * * 3-5 python3 /directory/crawling.py 3. 예제2분마다 “THIS IS CRONTAAAB”을 test.txt 에 기록해보자. “THIS IS CRONTAAAB”을 test.txt 파일에 기록하는 shell command 를 작성합니다.12# program.sh파일에 다음과 같이 작성합니다.echo &quot;THIS IS CRONTAAAB&quot; &gt;&gt; ./test.txt&quot; crontab -l 명령어를 통해 다음과 같이 작성합니다1*/2 * * * * /directory/program.sh","link":"/2019/08/06/linux-crontab/"},{"title":"numpy_cheatsheet","text":"np.arange(start, end) start 에서 end-1 까지의 행렬(array) return np.linspace(start, end, number_of_dots) number_of_dots : 범위 안의 점 갯수 np.zeros_like(x) 0으로 채운 x 와 같은 크기의 행렬","link":"/2018/11/23/numpy-cheatsheet/"},{"title":"[Python] 볼 때마다 헷갈리는 Iterable, Iterator, Generator 정리하기","text":"Iterable vs Iterator vs Generator 다른 분들의 코드를 읽을 때마다, 내가 사용할 때마다, 헷갈리는 Iterable, Iterator, Generator를 이번 글을 작성해보면서, 마지막으로! (라는 다짐으로) 정리해봅니다. 잘 알고 있는 개념이라고 생각했지만, 다른 사람들로부터의 질문을 받았을 때, 나의 설명이 만족스럽지 못해 ‘아 내가 더 정확히 알아야 한다’ 는 메타인지로부터 출발하는 글입니다. 파이썬의 장점으로 꼽히는, '사용하기 쉬운 데이터 구조'들 덕분에 우리는 루프를 돌아야하는 알고리즘에 대해 손쉽게 코드를 작성 할 수 있습니다. 하지만, 때로는 나만의 객체(class)를 만들고 그 객체가 파이썬에 내장 되어있는 데이터 구조 처럼, 동작하기를 바랍니다. 요즘 들어, 제가 짜는 코드에서 이 욕구는 신경망 모델링을 할 때, 신경망 모델 객체에 데이터의 배치를 feeding 하는 객체를 생성하고 싶을 때, 넘쳐나게 됩니다. 이럴 때, 파이썬에 대한 기본 개념이 잘 잡혀있지 않은 상태에서 복잡한 코드를 짜려고 하는 시도를 하니, 신경망 모델 자체의 구조에 대해서도 복잡한데 이런 루프를 돌면서 반복적으로 일정 데이터를 넘겨주기 위한 간단한 기능을 가진 코드에 대해서도 비효율적으로 작성하게 됩니다. 이런 제 자신의 문제를 해결하기 위해 이번 기회에 Iterator 와 Generator 에 대해 확실하게 정리해보려고 합니다. (feat. 예제코드) 1. 이터러블: Iterable Iterable 객체란? : 객체 안에 있는 원소(element)를 하나씩 반환 가능한 객체 파이썬이 제공하는 대부분의 내장 데이터 구조는 이터러블(Iterable)한 객체 입니다. 뿐만 아니라 우리가 만든 객체(class)도 Iterable 객체가 될 수 있습니다. 이터러블(Iterable)객체는 for 문과 같은 루프 뿐만 아니라, zip이나 map 과 같은 순서대로 처리할 입력이 필요한 곳에서도 사용 될 수 있습니다.이터러블(Iterable) 객체는 iter() 라는 함수의 입력으로 들어갑니다. iter() 라는 함수는 다음에 설명될 이터레이터(Iterator)를 반환합니다. 2. 이터레이터: Iterator Iterator 객체란? : Iterator의 __next__() 나 내장 함수인 next()를 부르면서, 원소(element)를 순차적으로 반환 할 숫 있는 객체 앞서, 설명드린대로 이터레이터(Iterator)는 iter()라는 함수가 반환하는 객체입니다. 그리고, 이터레이터(Iterator)는 반복적으로 __next__()나, next() 함수의 입력으로 들어가 호출하여, next()의 return 값인 원소(element)를 최종적으로 반환합니다.이터레이터(Iterator)가 다음 원소를 계속 반환하다가, 끝에 다달아 반환할 원소가 없을 경우 예외문인 StopIteration이 발생하게 됩니다.즉, 정리하면, Iterable 객체 A → iter(A) → Iterator 객체 B → next(B) → element (data) Question? 우리는 list 같은 이터러블(Iterable) 객체와 for 문을 쓰면서 한번도 iter() 나 next()를 보지 못했는뎁쇼????파이썬의 for 문은 이터러블(Iterable) 객체를 만나, 내부적으로 iter() 함수를 호출하여, 이터레이터(Iterator)를 생성합니다. 이 생성된 이터레이터(Iterator)가 루프가 실행되면서 next() 를 호출하며 반복적인 데이터를 뽑아 낼 수 있게 되는 것입니다. 그리고 모든 원소가 뽑아지고 난 뒤에는 StopIteration 이 발생하며, for 문이 종료 됩니다. 위 설명을 코드로 풀어쓰면, 다음과 같습니다. 우리가 다음과 같은 for 문을 사용하면, 12for element in iterable_object: print(element) 위 코드는 다음과 같이 파이썬 내부적으로 다음과 같이 동작하게 됩니다. 123456789101112# iter() 함수를 호출해, iterator 를 생성하고,iterator_object = iter(iterable_object)while True: # next() 함수를 호출해, element 를 받아옵니다. try: element = next(iterator_object) print(element) # element 가 없을 시, StopIteration Exception 발생 except: StopIteration: break 3. 이터러블(Iterable), 이터레이터(Iterator)와 친해지기3-1. 간단 버전파이썬 이터러블(Iterable) 내장 데이터 구조인 list 를 활용하여, 실습해 봅니다. 123456789101112131415161718&gt;&gt;&gt; iterable_object = [1, 2, 3, 4, 5]&gt;&gt;&gt; iterator_object = iter(iterable_object)&gt;&gt;&gt; iterator_object&lt;list_iterator object at 0x104fe2278&gt;&gt;&gt;&gt; next(iterator_object)1&gt;&gt;&gt; next(iterator_object)2&gt;&gt;&gt; next(iterator_object)3&gt;&gt;&gt; next(iterator_object)4&gt;&gt;&gt; next(iterator_object)5&gt;&gt;&gt; next(iterator_object)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;StopIteration 3-2. 나만의 iterable, iterator객체다음의 코드는 이름과 나이를 받는 데이터 객체입니다. 루프를 돌면서 각각 순서에 맞는 (이름, 나이)형태로 데이터를 반환하는 Iterable 객체입니다. 같은 기능을 하는 더욱 효율적인 코드를 짤 수 있겠지만, 공부한 iterable 과 iterator 를 적용해보는 class 입니다. 4. 제너레이터: Generator 제너레이터(Generator)란?: 특이한 (공식 문서에 ~~~ iterator) 이터레이터(Iterator) 정의에서도 보다시피, 이터레이터(Iterator)입니다. 즉, next() 함수를 만나 동작하는 함수입니다. 이 때, 제너레이터(Generator) 를 일반 함수와 다르게 하는 것이 yield 라는 문법입니다. yield 는 일반 함수의 return과 같이 값을 반환 하지만, return과 다르게 해당 함수(generator)가 종료하지 않고, 그대로 유지됩니다. 다음 순서의 제너레이터(Generator)가 호출되면, 멈추었던 yield 자리에서 다시 함수가 동작하게 됩니다. 요약하자면, 제너레이터(Generator) → next(제너레이터) → 제너레이터 함수 실행 → yield를 만나 next(제너레이터가) 호출된 곳으로 값을 반환 (제너레이터 종료 ❌) → 다시 next(제너레이터) → 멈추었던 yield부터 재실행 Question? 이런 특이하고, 어렵고, 처음엔 익숙하지 않은 제너레이터(Generator)를 왜 때문에 쓰는 겁죠???제너레이터는 메모리를 아끼기 위해서 사용합니다!!! 다음의 코드에서 메모리 사용량의 비교를 통해 살펴 보겠습니다. 5. 제너레이터 (Generator)와 친해지기제너레이터를 사용한 코드가 메모리 사용량 측면에서 얼마나 효율적인지 확인해보겠습니다. 다음의 코드는 999999까지의 숫자를 제곱하여 return 해주는 함수입니다. 첫번째, 일반적인 함수는 end 숫자까지 for 문을 돌면서 그 결과를 저장한 뒤에 return 해줍니다. 두번째 generator 는 for 문이 돌 때, yield 에서 해당 데이터만 리턴하게 되므로, 메모리 사용에서 효율적입니다. 다음의 실험에서도 쉽게 비교할 수 있습니다. 위 코드 실행결과: 12Memory Usage when program start: 8.80859375Memory Usage when program end: 56.0390625 위 코드 실행결과: 12Memory Usage when program start: 8.78515625Memory Usage when program end: 8.78515625 6. 마무리이번 짧은 글에서, Iterable, Iterator, Generator 를 비교해보면서 그 개념과 사용 예제를 간단하게 살펴 보았습니다. 이름에서부터 헷갈릴 수 있는 각 객체에 대한 내용을 이 글을 통해 조금이나마 정리해볼 수 있는 기회가 되셨으면 좋겠으며, 작은 도움이 되셨으면 합니다. 7. Reference Python documentation: generator Python documentation: iterable Python documentation: iterator","link":"/2019/07/15/iterator-generator/"},{"title":"math_cheatsheet","text":"이산확률분포베르누이 분포 (bernoulli distribution) 동전 생각하기 결과가 두가지 중 하나 확률변수를 1 or 0 으루 주었을 때,$$\\text{Bern}(x;\\mu) = \\mu^x(1-\\mu)^{(1-x)}$$ 확률변수를 1 or -1 로 주었을 때,$$\\text{Bern}(x; \\mu) = \\mu^{(1+x)/2} (1-\\mu)^{(1-x)/2}$$ 1234#예제코드#베르누이 분포 SciPy#100개 samplingsp.stats.bernoulli(mu).rvs(100, random_state=0) 이항분포 (binomial distribution) 동전을 N번 던졌다 성공확률이 $\\mu$ 인 베르누이 시도를 $N$ 번 반복 할 때, 성공 횟수를 $X$ 라 하면, $$ X \\sim \\text{Bin}(x;N,\\mu) $$ $$ \\text{Bin}(x;N,\\mu) = \\binom N x \\mu^x(1-\\mu)^{N-x} $$ 12sp.stats.binom(N, mu).rvs(100, random_state=0) 카테고리 분포 (Categorical distribution) 주사위 생각해! $K$ 개의 카테고리가 있을 때,$$ x = (x_1, x_2, x_3, x_4, … , x_k) $$ 각 원소 x_i 가 1이 나올 수 있는 확률 ($i$번쨰 원소의 성공확률)을 $\\mu_i$ 라 하면, $$ \\text{Cat}(x;\\mu) = \\mu_1^{x_1} \\mu_2^{x_2} \\cdots \\mu_K^{x_K} = \\prod_{k=1}^K \\mu_k^{x_k} $$ 이 표현은 One-Hot-Encoding 으로 카테고리 분포를 표현 했기에 가능하다. 단, $$ 0 \\leq \\mu_i \\leq 1 $$ $$ \\sum_{k=1}^K \\mu_k = 1 $$ 123#카테고리 분포는 SciPy 의 메소드가 없으므로, 다항분포의 N을 1로 준다.#mu 는 각 term 이 나올 수 있는 확률 vectorsp.stats.multinomial(1, mu) 다항 분포 (Multinomial distribution) 주사위를 여러번 던졌다. 카테고리 시도를 $N$ 번 반복하여 $k$ $(k=1,…,K)$ 가 $x_k$ 번 나올 확률분포. 123#N : number of trial#mu 는 각 term 이 나올 수 있는 확률 vectorsp.stats.multinomial(N, mu)","link":"/2018/11/23/math-cheatsheet/"},{"title":"[Metrics] PSNR &amp; SSIM","text":"PSNR &amp; SSIMImage Reconstruction을 수행하는 중, Model Selection 을 위한 비교 metric 중 하나인 PSNR, SSIM 을 정리한 글입니다. 1. PSNR1-1. 정의 및 특징Peak Signal-to-Noise Ratio 영상 정보, 화질을 평가할 때 사용되는 Metric. 현재 나는 Image Reconstruction Task 를 수행하며, 다양한 모델의 비교를 위해 사용하기 위해 공부하는 내용이다. 품질이 좋은 이미지는 큰 PSNR 값을 가지며, 품질이 좋지 않은 이미지는 작은 PSNR 값을 가지게 된다. Peak Signal-to-Noise Ratio $$PSNR = 10log_{10}(\\frac{MAX_I^2}{MSE})=20log_{10}(\\frac{MAX_I}{\\sqrt{MSE}}))=20log_{10}(MAX_I)-10log_{10}(MSE)$$ MAXI 는 해당 영상의 최댓값, 해당 채널의 최댓값에서 최솟값을 빼서 구함 e.g. 8-bit gray scale 의 경우, 255-0 = 255 단위: db(log scale) 무손실 영상의 경우 MSE 가 0이기 때문에, PSNR 은 정의 되지 않는다. $$MSE = \\frac{1}{mn}\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}[I(i,j)-K(i, j)]^2$$ I : mxn 사이즈의 grayscale image K: I 에 잡음이 포함된 이미지 (왜곡된 이미지) 1-2. 한계PSNR은 intensity 의 값들을 위 식에 의해 종합하여 평가하는 방식이기 때문에, 실제로 사람이 봤을 때 느끼는 것과 다른 점수를 뱉어낼 때가 있다. 즉, 사람의 지각품질을 제대로 반영하지 못하기 때문에 이를 보완하기 위해 PSNR-HVS, PSNR-HVS-M, SSIM, VIF 등의 Metric 이 개발되었다. 2. SSIM2-1. 정의 및 특징위 PSNR 의 한계를 극복하기 위해, 개발된 metric 으로써, Structural Similarity 의 줄임말이다. 사람의 지각 능력과 metric 을 일치시키는 목적에 개발되었다. 사람은 영상에서 구조 정보를 반영하여 영상을 바라보게 되는데, 영상이 얼마나 그 구조 정보를 변화시키지 않았는가를 살펴보는 metric 이다. 즉, 원본이미지(x)와 왜곡이미지(y)의 Luminance(l), Contrast(c), Structure(s)를 비교한다. contrast: 이미지의 표준편차값 structure: (이미지-평균밝기) / 표준편차 $$l(x, y)=\\frac{2\\mu_x \\mu_y+c_1}{\\mu_x^2+\\mu_y^2+c_1}$$ $$c(x,y)=\\frac{2\\sigma_x\\sigma_y+c_2}{\\sigma_x^2+\\sigma_y^2+c_2}$$ $$s(x,y)=\\frac{\\sigma_{xy}+c_3}{\\sigma_x\\sigma_y+c_3}$$ $$SSIM(x,y)=[l(x,y)^{\\alpha}c(x,y)^{\\beta}s(x,y)^{\\gamma}]$$ $$c_3=c_2/2$$ 위에 c3 와 c2 의 조건을 추가하면 SSIM 은 다음과 같이 축약된다. 3. Reference https://kr.mathworks.com/help/images/ref/ssim.html https://bskyvision.com/ https://en.wikipedia.org/wiki/Structural_similarity https://ko.wikipedia.org/wiki/","link":"/2019/09/01/psnr-ssim/"},{"title":"[논문읽기] Summary of Vision and Rain","text":"Presentation for summary papers Initial Model for removing rain and snow from Image system. Summary of the paper 'detection and removal of rain from video, vision and rain' from ssuser47e145","link":"/2019/08/20/summary-vision-and-rain/"},{"title":"[세미나요약] 데이터 분석, 의심에서 전달까지","text":"2021년 10월 8일, 한국에너지기술연구원 이제현 박사님이 진행하신 ‘데이터 분석, 의심에서 전달까지’ 제목으로 진행된 세미나를 참석했습니다. 본 글은 세미나 내용의 요약입니다. [세미나 발표 PDF 자료]세미나 발표 pdf 자료 1. 데이터 의심하기1-1. 레퍼런스의 중요성 분석결과의 신뢰도, 결과의 책임을 위해 데이터의 출처가 명확해야한다. 출처가 분명하지 않은 데이터는 사용하지 않는 것이 최선 1-2. 데이터의 건정성 데이터 자체의 건정성 결측치 : 데이터가 없음 → 데이터가 없는 것도 가끔은 중요한 메시지가 될 수 있다. (예: 이미지 데이터 내의 까만 이미지 → 빛이 없다고 해석 가능) 결측치에 대한 해석은 결국, 데이터의 도메인 관점에서 생각 중복데이터 : 같은 데이터가 여러개 → Key feature 를 중심으로 논리적으로 판단해야한다. 중복데이터에 대해 일괄적인 처리 이전에 고민해보아야 할 문제 (예: 같은 자리에 건물이 겹쳐 있음 : 비정상적인 데이터, 같은 시간 같은 가게에 손님이 두명 : 정상적인 데이터) 이상치 : (사전적의미) 정상적인 범위에서 벗어나는 데이터 → 통계 분석을 통해 이상치 후보군을 추리고, 도메인 접근을 통해 진짜 이상치인지 판별해야한다. (예: 대학 중퇴자가 왜 소득이 높지? → 빌게이츠, 스티브잡스, 마크 저커버그, 잭도시 등) 이상치로 볼수 있는 데이터가 있다 하더라도, 내가 하는 분석의 목적에 따라서 데이터가 이상치 일수도, 아닐수도 있다. 기계적인 처리는 하면 안됨 1-3. 너무 믿지 말아야할 데이터 너무 믿지 말아야할 데이터 : (예: 영화 장르데이터 → 해리포터 1, 2, 3,4 … 의 장르가 모두 다름. 어떤 절대적 기준에 의해 장르 구분이 된 것이 아니라, 누군가의 주관적 관점으로 새긴 데이터) 1-4. 필요 데이터 본격적인 프로젝트 시행 이전에, 필요한 데이터를 빠르게 계획하고, 살펴본뒤 레퍼런스 체크를 시행해야한다. 1-5. 데이터 파악 데이터 파악 : 통계치는 같은데 그림을 그리면 다르게 해석된다. 반드시 데이터는 그려보아야 한다. (예: 데이터 사우르스, 통계가 얼마나 눈을 가리는지 보여주는 예시) 데이터를 제대로 의심하는 방법 : Exploratory Data Analysis. 데이터를 받았을 때 이렇게 저렇게 찾아보는 과정. (예: 장님이 코끼리를 만져보는 과정) 한명의 장님(나) 여러 방법으로 그려보고 살펴보면서 데이터를 3d 다양한 관점에서 바라보아야 한다. 데이터에 대해 그림을 그릴 때마다 가설을 세우고, 다음 그림을 그릴 때 내 가설을 보완해나아가야함. 마치 셀프 강화학습 처럼 결국 EDA + Hypothesis + Graph = self-강화학습 2. 분석 방법 의심하기 사장님이 감자를 잘라달라 감자 썰기의 관건: 무엇을 만들 것인가 요리의 목적에 따라 다양한 감자 형태, 다양한 조리방식이 있을 수 있다 데이터 분석: 무엇을 할 것인가? 데이터 분석의 관건: 무엇을 위한 분석인가 현황 분석(현황 내용전달), 대안 제시 (설득력: 대안의 장점과 단점), 예측모델개발 (신뢰성: 검증결과, 예상오차) 등 목적에 따라 데이터 뿐만 아니라 그에 따른 다양한 데이터 분석 방법이 필요하다 망치와 모루 전략 (Hammer and Anvil Tactic) 모루가 버티는 동안 망치가 때린다 (마케도니아 알렉산더 대왕) 모루가 중요하다: 지지않아야하고, 이겨한다 → 수학적 엄밀함 (다양한 통계분석방법, T 검정, 층화 추출, 다양한 매트릭, 정규화, 카이제곱, 교차검증 등) 통계학은 의심의 학문이다 : 내가 전체 데이터를 모두 볼 수 없기 때문에 부분만 보고, 부분이 전체에 적용이 될지 → 이 불안을 해소하기 위한 것이 통계학, 수학 망치 : 나만의 인사이트 → 아무도 못한 생각을 통해 전쟁에서 이기자 인사이트 도출 방법: 데이터 자르기 (Segment) Airbnb “국내, 300마일” 인사이트 도출방법: 독창적 시각화 (Visualization) 나이팅게일 → 다쳐서가 아니라 더러워서 사람이 죽는다. Hans Rosling, Ted, 2007 → Animated bubble chart : 세상은 점점 나아지고 있다, 경향성을 새롭게 보여줌 Danny Dorling → Slow Down 가속 성장의 시대는 끝났다. 송강호 → 배우는 오담을 가져온다. 알고보면 그 오답이 진짜 정답이다. 데이터를 받으면, 공부한대로, 정해진 루틴대로 분석하고 visualization 을 진행함.. 남들도 그렇게 하고 있다. 세상에 없는 방법? 남들보다 더 많은 시간과 정성 쏟기 + 스스로 생각하기 3. 고객에게 잘 전달하기 결과를 보고하는 데이터 분석가의 주의사항 내 업무 시간 순이 아니라 상대방 논리에 따라 보고하기 결론 없이 사실만 나열하면 안됨 경영 용어가 아닌 통계 용어를 남발하면 안됨 분석을 원하는 사람들의 진짜 원하는 것 찾아내기 자신들 조차 원하는게 뭔지 정확히 모른다 다양한 질문들과 상황을 통해 그들이 원하는 것이 무엇인지 파악 데이터 vs 도메인 영문과 교수예시: 우리 영문과는 영어가 모국어처럼 입에 붙어야 비로소 국문과랑 같은 출발선에 서는거다. 초벌 데이터 분석으로 알아내는 것 = 도메인에서는 모두 알고 있는 것 데이터를 분석해서 실무자에게 공유해야 하는 내용 + 흥미를 보이는 지점, 애매하게 파악하고 있는 부분 캐치 + 심층 분석 4. 끊임없는 의심 내 분석결과를 살표본다 : Insight 내 아이디어를 빠르게 적용 : Agile, 코딩잘하기 호기심 : 흥미요소 5. 경계하는 자세 생명에 대한 예의 국가별 코로나 19 사망자 데이터 분석 안좋은 소식에 대한 분석결과는 tone &amp; manner 를 지켜서.. 데이터 밖의 세계 컴퓨터, 데이터 속에서만 사는가? vs 어차피, 결국 숫자일 뿐이야? 식사를 마친 손님 : 얼마나 좋은 재료, 어떤 기법을 사용한 요리? X → 음식이 제때 나오고, 맛있게 배부른 곳 → 음식을 어떻게 만들었는지는 그 다음 문제 데이터 분석 : 원래 목적을 잘 파악해서 다가가는게 중요 → 어떤 분석방법, 시각화는 나중, 남들이 잘 하지 않는 시도를 많이 해보기 세미나 발표 pdf 자료","link":"/2021/10/10/summary-seminar-EDA/"}],"tags":[{"name":"TWIL","slug":"TWIL","link":"/tags/TWIL/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"development","slug":"development","link":"/tags/development/"},{"name":"개발환경","slug":"개발환경","link":"/tags/%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD/"},{"name":"setting","slug":"setting","link":"/tags/setting/"},{"name":"글또","slug":"글또","link":"/tags/%EA%B8%80%EB%98%90/"},{"name":"지원서","slug":"지원서","link":"/tags/%EC%A7%80%EC%9B%90%EC%84%9C/"},{"name":"회고","slug":"회고","link":"/tags/%ED%9A%8C%EA%B3%A0/"},{"name":"error","slug":"error","link":"/tags/error/"},{"name":"solution","slug":"solution","link":"/tags/solution/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"xcrun","slug":"xcrun","link":"/tags/xcrun/"},{"name":"commandlinetools","slug":"commandlinetools","link":"/tags/commandlinetools/"},{"name":"목표","slug":"목표","link":"/tags/%EB%AA%A9%ED%91%9C/"},{"name":"논문리뷰","slug":"논문리뷰","link":"/tags/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"},{"name":"추천시스템","slug":"추천시스템","link":"/tags/%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C/"},{"name":"Look-alike","slug":"Look-alike","link":"/tags/Look-alike/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"쿠버네티스","slug":"쿠버네티스","link":"/tags/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"},{"name":"Data Engineering","slug":"Data-Engineering","link":"/tags/Data-Engineering/"},{"name":"CI&#x2F;CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"screen","slug":"screen","link":"/tags/screen/"},{"name":"multiplexer","slug":"multiplexer","link":"/tags/multiplexer/"},{"name":"멀티플렉서","slug":"멀티플렉서","link":"/tags/%EB%A9%80%ED%8B%B0%ED%94%8C%EB%A0%89%EC%84%9C/"},{"name":"스크린","slug":"스크린","link":"/tags/%EC%8A%A4%ED%81%AC%EB%A6%B0/"},{"name":"FastAPI","slug":"FastAPI","link":"/tags/FastAPI/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"웹서버","slug":"웹서버","link":"/tags/%EC%9B%B9%EC%84%9C%EB%B2%84/"},{"name":"Markov","slug":"Markov","link":"/tags/Markov/"},{"name":"Markov Decision Process","slug":"Markov-Decision-Process","link":"/tags/Markov-Decision-Process/"},{"name":"Reinforcement Learning","slug":"Reinforcement-Learning","link":"/tags/Reinforcement-Learning/"},{"name":"awk","slug":"awk","link":"/tags/awk/"},{"name":"Language","slug":"Language","link":"/tags/Language/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"CS224n","slug":"CS224n","link":"/tags/CS224n/"},{"name":"summary","slug":"summary","link":"/tags/summary/"},{"name":"CS231n","slug":"CS231n","link":"/tags/CS231n/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"MoE","slug":"MoE","link":"/tags/MoE/"},{"name":"DeepSeekMoE","slug":"DeepSeekMoE","link":"/tags/DeepSeekMoE/"},{"name":"Paper Summary","slug":"Paper-Summary","link":"/tags/Paper-Summary/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"도커","slug":"도커","link":"/tags/%EB%8F%84%EC%BB%A4/"},{"name":"DeepSeekV3","slug":"DeepSeekV3","link":"/tags/DeepSeekV3/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"확률론적생성모형","slug":"확률론적생성모형","link":"/tags/%ED%99%95%EB%A5%A0%EB%A1%A0%EC%A0%81%EC%83%9D%EC%84%B1%EB%AA%A8%ED%98%95/"},{"name":"Generative","slug":"Generative","link":"/tags/Generative/"},{"name":"생성모형","slug":"생성모형","link":"/tags/%EC%83%9D%EC%84%B1%EB%AA%A8%ED%98%95/"},{"name":"분류모델","slug":"분류모델","link":"/tags/%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"rdbms","slug":"rdbms","link":"/tags/rdbms/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"proxy","slug":"proxy","link":"/tags/proxy/"},{"name":"pillow, Pillow, image","slug":"pillow-Pillow-image","link":"/tags/pillow-Pillow-image/"},{"name":"datastructure","slug":"datastructure","link":"/tags/datastructure/"},{"name":"자동화","slug":"자동화","link":"/tags/%EC%9E%90%EB%8F%99%ED%99%94/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"webdriver","slug":"webdriver","link":"/tags/webdriver/"},{"name":"stack","slug":"stack","link":"/tags/stack/"},{"name":"Crawling, Web, Requests","slug":"Crawling-Web-Requests","link":"/tags/Crawling-Web-Requests/"},{"name":"scrapy","slug":"scrapy","link":"/tags/scrapy/"},{"name":"crawling","slug":"crawling","link":"/tags/crawling/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"Gan","slug":"Gan","link":"/tags/Gan/"},{"name":"Vanilla Gan","slug":"Vanilla-Gan","link":"/tags/Vanilla-Gan/"},{"name":"paper","slug":"paper","link":"/tags/paper/"},{"name":"논문","slug":"논문","link":"/tags/%EB%85%BC%EB%AC%B8/"},{"name":"Thread","slug":"Thread","link":"/tags/Thread/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"decorator","slug":"decorator","link":"/tags/decorator/"},{"name":"데코레이터","slug":"데코레이터","link":"/tags/%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%84%B0/"},{"name":"Google Cloud Platform","slug":"Google-Cloud-Platform","link":"/tags/Google-Cloud-Platform/"},{"name":"lightgbm","slug":"lightgbm","link":"/tags/lightgbm/"},{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"환경설정","slug":"환경설정","link":"/tags/%ED%99%98%EA%B2%BD%EC%84%A4%EC%A0%95/"},{"name":"리눅스","slug":"리눅스","link":"/tags/%EB%A6%AC%EB%88%85%EC%8A%A4/"},{"name":"crontab","slug":"crontab","link":"/tags/crontab/"},{"name":"크론탭","slug":"크론탭","link":"/tags/%ED%81%AC%EB%A1%A0%ED%83%AD/"},{"name":"iterator","slug":"iterator","link":"/tags/iterator/"},{"name":"generator","slug":"generator","link":"/tags/generator/"},{"name":"iterable","slug":"iterable","link":"/tags/iterable/"},{"name":"이터레이터","slug":"이터레이터","link":"/tags/%EC%9D%B4%ED%84%B0%EB%A0%88%EC%9D%B4%ED%84%B0/"},{"name":"제너레이터","slug":"제너레이터","link":"/tags/%EC%A0%9C%EB%84%88%EB%A0%88%EC%9D%B4%ED%84%B0/"},{"name":"이터러블","slug":"이터러블","link":"/tags/%EC%9D%B4%ED%84%B0%EB%9F%AC%EB%B8%94/"},{"name":"DataAnalysis","slug":"DataAnalysis","link":"/tags/DataAnalysis/"},{"name":"DataScience","slug":"DataScience","link":"/tags/DataScience/"},{"name":"Seminar","slug":"Seminar","link":"/tags/Seminar/"},{"name":"Data","slug":"Data","link":"/tags/Data/"}],"categories":[{"name":"Diary","slug":"Diary","link":"/categories/Diary/"},{"name":"Development","slug":"Development","link":"/categories/Development/"},{"name":"글또","slug":"글또","link":"/categories/%EA%B8%80%EB%98%90/"},{"name":"Git","slug":"Development/Git","link":"/categories/Development/Git/"},{"name":"Paper","slug":"Paper","link":"/categories/Paper/"},{"name":"Kubernetes","slug":"Development/Kubernetes","link":"/categories/Development/Kubernetes/"},{"name":"Linux","slug":"Development/Linux","link":"/categories/Development/Linux/"},{"name":"Error&amp;Solution","slug":"Development/Error-Solution","link":"/categories/Development/Error-Solution/"},{"name":"FastAPI","slug":"Development/FastAPI","link":"/categories/Development/FastAPI/"},{"name":"DataScience","slug":"DataScience","link":"/categories/DataScience/"},{"name":"MachineLearning","slug":"MachineLearning","link":"/categories/MachineLearning/"},{"name":"C++","slug":"Development/C","link":"/categories/Development/C/"},{"name":"Lecture","slug":"Lecture","link":"/categories/Lecture/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"LLM","slug":"Paper/LLM","link":"/categories/Paper/LLM/"},{"name":"Docker","slug":"Development/Docker","link":"/categories/Development/Docker/"},{"name":"Math","slug":"Math","link":"/categories/Math/"},{"name":"wiki","slug":"wiki","link":"/categories/wiki/"},{"name":"Pytorch","slug":"MachineLearning/Pytorch","link":"/categories/MachineLearning/Pytorch/"},{"name":"DataStructure","slug":"DataStructure","link":"/categories/DataStructure/"},{"name":"Regression","slug":"DataScience/Regression","link":"/categories/DataScience/Regression/"},{"name":"Apache Spark","slug":"MachineLearning/Apache-Spark","link":"/categories/MachineLearning/Apache-Spark/"},{"name":"CS224n","slug":"Lecture/CS224n","link":"/categories/Lecture/CS224n/"},{"name":"Python","slug":"Development/Python","link":"/categories/Development/Python/"},{"name":"CS231n","slug":"Lecture/CS231n","link":"/categories/Lecture/CS231n/"},{"name":"Google Cloud Platform","slug":"Google-Cloud-Platform","link":"/categories/Google-Cloud-Platform/"},{"name":"Digital Image Processing","slug":"Book/Digital-Image-Processing","link":"/categories/Book/Digital-Image-Processing/"},{"name":"딥러닝을 이용한 자연어 처리","slug":"Lecture/딥러닝을-이용한-자연어-처리","link":"/categories/Lecture/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"},{"name":"MySQL","slug":"wiki/MySQL","link":"/categories/wiki/MySQL/"},{"name":"NGINX","slug":"wiki/NGINX","link":"/categories/wiki/NGINX/"},{"name":"Pillow","slug":"wiki/Pillow","link":"/categories/wiki/Pillow/"},{"name":"Provision","slug":"wiki/Provision","link":"/categories/wiki/Provision/"},{"name":"Selenium","slug":"wiki/Selenium","link":"/categories/wiki/Selenium/"},{"name":"Requests","slug":"wiki/Requests","link":"/categories/wiki/Requests/"},{"name":"Scrapy","slug":"wiki/Scrapy","link":"/categories/wiki/Scrapy/"},{"name":"Xpath","slug":"wiki/Xpath","link":"/categories/wiki/Xpath/"},{"name":"Vision","slug":"MachineLearning/Vision","link":"/categories/MachineLearning/Vision/"},{"name":"Seminar","slug":"DataScience/Seminar","link":"/categories/DataScience/Seminar/"}],"pages":[{"title":"About","text":"EmjayAhn","link":"/about/index.html"}]}