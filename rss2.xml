<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>EmjayAhn, DataScienceBook</title>
  
  <subtitle>EmjayAhn | Logging Everyday</subtitle>
  <link href="https://emjayahn.github.io/rss2.xml" rel="self"/>
  
  <link href="https://emjayahn.github.io/"/>
  <updated>2023-03-26T11:59:36.805Z</updated>
  <id>https://emjayahn.github.io/</id>
  
  <author>
    <name>Emjay Ahn</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[Kubernetes] 쿠버네티스 입문</title>
    <link href="https://emjayahn.github.io/2023/03/26/20230326-basic-kubernetes/"/>
    <id>https://emjayahn.github.io/2023/03/26/20230326-basic-kubernetes/</id>
    <published>2023-03-26T11:51:26.000Z</published>
    <updated>2023-03-26T11:59:36.805Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>머신러닝 서비스를 개발, 배포, 운영을 시작하면서 도커에 대한 이해와 필요성을 느끼며 도입을 위해 공부를 시작했다. 도커를 공부하던 끝에 이제는 쿠버네티스를 시작해보려고한다. 그리고 올해 말에는 CKAD 도 도전해보려고 한다. Kubernetes글 시리즈에서는 Kubernetes를 처음 시작하고 공부한 내용들을 정리해보며, 시험 준비기까지 정리해보려고 한다. 시험을 실제로 도전하기전 학습하고 실습한 내용들을 정리하는 글이다보니 그 끝에 시험에 합격할지까지 관심있게 지켜봐주면 좋겠다. 시험 합격 여부와 상관없이, 이 노력과 글, 지식은 내 안에 쌓일테니 꼼꼼히 공부해보려고한다.</p><span id="more"></span><h2 id="1-쿠버네티스란"><a href="#1-쿠버네티스란" class="headerlink" title="1. 쿠버네티스란?"></a>1. 쿠버네티스란?</h2><p>쿠버네티스는 도커와 같은 컨테이너를 손쉽게 관리하는 플랫폼이다. 도커 컨테이너를 서비스 트래픽의 양과 컨테이너의 양에 따라 배포하고 확장해야하는 이슈가 생기기 마련이다. 이 다수의 컨테이너를 관리하고 이를 자동화하는 플랫폼이다. 있어보이는 표현으로는 컨테이너 오케스트레이션 툴이라고 정리할 수 있겠다.</p><p><img src="/2023/03/26/20230326-basic-kubernetes/Untitled_01.png" alt="Kubernetes"></p><h2 id="2-쿠버네티스의-구성-요소"><a href="#2-쿠버네티스의-구성-요소" class="headerlink" title="2. 쿠버네티스의 구성 요소"></a>2. 쿠버네티스의 구성 요소</h2><p>쿠버네티스의 구성요소를 정리하며, 각 요소들의 기능 및 용어를 정리해보자.</p><h3 id="2-1-파드-Pod"><a href="#2-1-파드-Pod" class="headerlink" title="2-1. 파드 : Pod"></a>2-1. 파드 : Pod</h3><p>파드란 쿠버네티스 내에서 생성되고 관리되는 배포 가능한 가장 작은 컴퓨팅 단위이다. 어플리케이션의 단일 인스턴스라고 이해할 수 있다. 즉, 파드는 하나 이상의 컨테이너 그룹이다. 파드 내에서는 메모리, 네트워크를 공유하고 함께 스케쥴링된다.</p><h3 id="2-2-노드-Node"><a href="#2-2-노드-Node" class="headerlink" title="2-2.  노드 : Node"></a>2-2.  노드 : Node</h3><p>노드란 클러스터의 가상 혹은 물리 머신을 의미한다. 각 노드는 아래서 설명할 컨트롤 플레인에 의해 관리되고, 파드를 실행하는데 필요한 서비스를 포함한다. 클러스터 내에는 다수의 노드가 있을 수 있다. 모든 클러스터는 최소 한 개 이상의 워커 노드를 갖게 된다. 이후 워커 노드는 각 어플리케이션의 구성요소인 파드를 호스팅한다. </p><h3 id="2-3-컨테이너-런타임-엔진"><a href="#2-3-컨테이너-런타임-엔진" class="headerlink" title="2-3. 컨테이너 런타임 엔진"></a>2-3. 컨테이너 런타임 엔진</h3><p><img src="/2023/03/26/20230326-basic-kubernetes/Untitled.png" alt="Docker"></p><p>컨테이너를 구성하고 실행하기 위해 각 노드 안에는 컨테이너 런타임 엔진이 존재한다. 이 컨테이너 런타임 엔진 개념에 포함되는 한가지 예가 바로 도커이다. 쿠버네티스는 도커뿐만아니라 rkt 와 같은 컨테이너와도 호환이 가능하다. </p><h3 id="2-4-컨트롤-플레인-Control-Plane"><a href="#2-4-컨트롤-플레인-Control-Plane" class="headerlink" title="2-4. 컨트롤 플레인 : Control Plane"></a>2-4. 컨트롤 플레인 : Control Plane</h3><p>컨트롤 플레인이란 컨테이너의 전체 라이프 사이클을 정의하고, 배포하며, 관리하기 위한 API 이다. 컨트롤 플레인은 워커 노드와 클러스터 내 파드를 관리하게 된다. 컨트롤 플레인은 앞서 말한 노드와 항상 연결되어 있어, 노드가 정의한 실행환경에 따라 서로 통신하게 된다.</p><p><img src="/2023/03/26/20230326-basic-kubernetes/Untitled_02.png" alt="Control Plane"><br>Control Plane - 출처 : <a href="https://www.redhat.com/ko/topics/containers/kubernetes-architecture">https://www.redhat.com/ko/topics/containers/kubernetes-architecture</a></p><h3 id="2-5-etcd"><a href="#2-5-etcd" class="headerlink" title="2-5. etcd"></a>2-5. etcd</h3><p>클러스터 설정 데이터와 클러스터의 상태를 저장하는 key-value 데이터베이스이다. 클러스터 내에 어떤 노드가 몇 개 존재하며, 어떤 파드가 동작하고 있는지에 관한 정보가 etcd 에 기록된다. 이 etcd에 대한 백업 계획이 필수일 것이다. 이 etcd 데이터 유실이 일어나면 클러스터가 사용하는 리소스 정보를 모두 잃어버리기 때문이다.</p><p>이 외에도 kude-scheduler, kube-controller-manager, cloud-controller-manager, kube-proxy, kubelet 등 쿠버네티스의 기능과 관련된 개념과 용어드리 많이 등장한다. 위 5개와 관련된 용어는 쿠버네티스를 처음 시작하고 실습하는데 필요한 개념이라면 이후에 나오는 용어들은 각각의 실습과 동시에 그 용어와 개념을 정리해보려고 한다.</p><p>몇년동안 줄곧 핫한 플랫폼을 항상 쓰던 기능만 찾아서 써왔다. 이제와서 자세하게 공부하는 것이 조금 늦은 것 같아 아쉬운 점이 많지만, 이 아쉬움을 동기 삼아 열심히 공부해보려고 한다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;머신러닝 서비스를 개발, 배포, 운영을 시작하면서 도커에 대한 이해와 필요성을 느끼며 도입을 위해 공부를 시작했다. 도커를 공부하던 끝에 이제는 쿠버네티스를 시작해보려고한다. 그리고 올해 말에는 CKAD 도 도전해보려고 한다. Kubernetes글 시리즈에서는 Kubernetes를 처음 시작하고 공부한 내용들을 정리해보며, 시험 준비기까지 정리해보려고 한다. 시험을 실제로 도전하기전 학습하고 실습한 내용들을 정리하는 글이다보니 그 끝에 시험에 합격할지까지 관심있게 지켜봐주면 좋겠다. 시험 합격 여부와 상관없이, 이 노력과 글, 지식은 내 안에 쌓일테니 꼼꼼히 공부해보려고한다.&lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Kubernetes" scheme="https://emjayahn.github.io/categories/Development/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://emjayahn.github.io/tags/Kubernetes/"/>
    
    <category term="쿠버네티스" scheme="https://emjayahn.github.io/tags/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"/>
    
    <category term="Data Engineering" scheme="https://emjayahn.github.io/tags/Data-Engineering/"/>
    
    <category term="CI/CD" scheme="https://emjayahn.github.io/tags/CI-CD/"/>
    
  </entry>
  
  <entry>
    <title>[논문리뷰] Real-time Attention Based Look-alike Model for Recommender System (Part 2)</title>
    <link href="https://emjayahn.github.io/2023/03/12/20230312-paper-RALM-2/"/>
    <id>https://emjayahn.github.io/2023/03/12/20230312-paper-RALM-2/</id>
    <published>2023-03-12T05:34:24.000Z</published>
    <updated>2023-03-12T05:35:52.006Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 후반부 심을 살펴보고자 한다. 특히 Online Processing, Online Serving 파트를 집중적으로 살펴보자.</p><span id="more"></span><h3 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features"></a>Key Features</h3><p>본 논문의 핵심은 3가지로 구분된다. 1. User representation을 학습하는 offline train model 2. Seeds representation 을 학습하는 비동기 online processing 3. user와 seed간의 similarity를 계산하고, 점수를 매겨 서빙하는 Online Serving</p><p>지난 Part 1에서 User representation과 offline train model을 살펴보았다면, 이번 글에서는 비동기 online processing 과 Online serving 부분에 대해 살펴보자.</p><h3 id="1-Online-Asynchronous-Processing"><a href="#1-Online-Asynchronous-Processing" class="headerlink" title="1. Online Asynchronous Processing"></a>1. Online Asynchronous Processing</h3><p>비동기 온라인 프로세싱에서의 핵심은  앞서 데이터베이스에 가지고 있는 유저 pool의 표현 방식 seeds representation을 실시간으로 업데이트 하는 것이다. Seeds는 시스템이 지속되고, 그 pool이 늘어남에 따라 계속 축적될 것이다. 또한 가지고 있는 유저는 계속 그 행동과 히스토리 데이터를 남길 것이고 그 데이터에 따라 유저를 표현하는 방식도 최신화 되어야만한다. 따라서 이 representation 은 주기적인 업데이트가 필요하고, 수많은 seeds를 효율적으로 관리하고 비슷한 seeds를 구분 짓기 위해 군집화를 시행한다. 비동기 온라인 프로세싱은 다음 두 가지로 구성된다.</p><p><strong>User feedback monitor</strong></p><p>Seed의 클릭, 페이지 방문 등 프로파일 데이터를 모니터링 하며, 다음 클러스터링에 영향을 주게 되는 user profile 을 실시간으로 업데이트한다. 이 논문에서는 3백만의 click 데이터를 활용하여 seed들의 profile을 업데이트 했다.</p><p><strong>Seeds Clustering</strong></p><p>K-means 알고리즘을 이용해 seed 들을 k 개의 군집으로 clustering 하였다. 각 cluster의 중심점과 업데이트 되는 중심점은 저장해 놓고, 이를 seeds의 raw representation  $R_{seeds}$ 개념으로 보았다.</p><p>$$<br>R_{seeds} &#x3D; &lt;!–swig￼0–&gt;, E_{centroid_{2}}, E_{centroid_{3}} ,…, E_{centroid_{k}}}}<br>$$</p><h3 id="2-Online-Serving"><a href="#2-Online-Serving" class="headerlink" title="2. Online Serving"></a>2. Online Serving</h3><p>이 온라인 서빙 부분은 실제 구현하는 각 회사나 개인의 환경에 따라 본 논문의 형태와는 다를 수 있겠다. 하지만 나 역시 이 부분의 이해를 토대로 회사의 환경에 맞게 응용하여 적용하였으므로 차분히 살펴보자.</p><p>이 모델이 서빙이 될 때, 그 input 부터 살펴보면 다음과 같다.</p><ol><li>Current user → Fetch look-alike embedding</li><li>Fetch the centroid embeddings</li><li>Predict global embedding (global attention unit)</li><li>Predict local embedding (local attention unit)</li><li>Calculate global similarity &amp; local similarity</li></ol><p>위 단계별로 걸쳐진 global similarity와 local similarity는 다음의 식으로 통합된다.</p><p>$$<br>score_{u, s} &#x3D; \alpha cosine(E_{u}, E_{global_{s}})+ \beta cosine(E_{u}, E_{local_{s}})<br>$$</p><ul><li>$E_{global_{s}}$ : seeds의 global embedding</li><li>$E_{local_{s}}$ : seeds의 local embedding</li><li>$\alpha , \beta$ : global similarity와 local similarity의 각 가중치 (본 논문에서는 $\alpha&#x3D;0.3$, $\beta &#x3D;0.7$로 적용했다.)</li></ul><p>이렇게 앞서 만든 모델들의 각 유닛에 input 과 cluster embedding 간의 유사도 계산을 통해 최종 계산된 본 유사도를 활용하여 user extension 의 그룹을 정할 수 있다.</p><h3 id="3-본-논문-리뷰를-마치며"><a href="#3-본-논문-리뷰를-마치며" class="headerlink" title="3. 본 논문 리뷰를 마치며"></a>3. 본 논문 리뷰를 마치며</h3><p>회사의 업무로써 이 논문을 처음 읽었을 때는 그리 크게 감탄하지 못했다. 하지만 본격적으로 구현해보면서, 본 논문의 주장하는 바와 그 주장이 논리적으로 다가와 내게 “Aha”포인트를 주어, 이 논문을 정리하고 공유해보고 싶었다. 이 논문의 인상 깊은 점은 attention unit 을 통한 global , local 유저간의 유사도를 얻는 아이디어 였다. attention unit을 제외하고 이 모델을 살펴 보면, linear regression을 이용한 user extension 과 크게 다르지 않다는 것을 알 수 있다.</p><p>다른 분야(NLP)의 전유물이라고만 느껴왔던 attention unit 을 적용하는 아이디어에 대해 다시 한번 감탄하며 나 역시 분야를 가리지 않는 스터디를 통해 창의적인 시도를 계속 해봐야겠다는 다짐을 한다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 후반부 심을 살펴보고자 한다. 특히 Online Processing, Online Serving 파트를 집중적으로 살펴보자.&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="https://emjayahn.github.io/categories/Paper/"/>
    
    
    <category term="글또" scheme="https://emjayahn.github.io/tags/%EA%B8%80%EB%98%90/"/>
    
    <category term="논문리뷰" scheme="https://emjayahn.github.io/tags/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"/>
    
    <category term="추천시스템" scheme="https://emjayahn.github.io/tags/%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C/"/>
    
    <category term="Look-alike" scheme="https://emjayahn.github.io/tags/Look-alike/"/>
    
  </entry>
  
  <entry>
    <title>[논문리뷰] Real-time Attention Based Look-alike Model for Recommender System (Part 1)</title>
    <link href="https://emjayahn.github.io/2023/02/26/20230226-paper-RALM-1/"/>
    <id>https://emjayahn.github.io/2023/02/26/20230226-paper-RALM-1/</id>
    <published>2023-02-26T05:59:57.000Z</published>
    <updated>2023-02-26T06:02:39.607Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 핵심을 살펴보고, 위 논문의 각 파트를 구현하면서 마주한 문제와 고민을 공유해보고자 한다. Part 1, 2로 나누어 User representation learning 파트와 Online Processing 파트를 나누어 살펴보자.</p><span id="more"></span><p>광고를 송출 하는데 있어, 요즘 내가 풀고 있는 문제는 “오디언스의 확보”이다. 광고주마다 특정 KPI 를 달성하는데 필요한 오디언스는 정해져있다고 전제할 때, 광고 시스템은 전체 오디언스 풀에서 특정 KPI를 달성하는데 유리한 오디언스를 찾아내 타겟팅, 리타겟팅을 잘 해내야 한다. “오디언스 확보”를 위해서 다양한 아이디어에 근간해 개발을 하고 있고, 우리 광고 시스템에 실험을 하고 있다. 그 중 RecSys분야에서 재미있게 읽은 Attention based Look-alike Model 논문을 리뷰해 본다. Look-alike Model 은 특정 캠페인에서 효율(간단하게는 CTR, CVR 등)이 좋았던 N명의 오디언스의 특징을 찾고, 전체 오디언스 풀에서 N명과 유사한 M을 찾는 것이다. </p><h3 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features"></a>Key Features</h3><p>본 논문의 핵심은 3가지로 구분된다. 1. User representation을 학습하는 offline train model 2. Seeds representation 을 학습하는 비동기 online processing 3. user와 seed간의 similarity를 계산하고, 점수를 매겨 서빙하는 Online Serving</p><p>본 논문을 직접 구현하는데 있어 가장 중요한 것은 1, 2번의 모델링 방법이다. 3의 경우, 각 회사나 시스템마다 적용할 수 있는 방법은 다양하게 있을 것이다. 본 글에서는 1번에 집중하여 핵심을 파악해보자. 다음글에서 2번 모델에 알아보자.</p><h3 id="1-User-Representation-Learning"><a href="#1-User-Representation-Learning" class="headerlink" title="1. User Representation Learning"></a>1. User Representation Learning</h3><p>유저 profile 데이터는 매우 다양하게 있을 것이다. 기본적인 메타데이터부터 특정 광고 캠페인에서의 클릭수, 랜딩 페이지, 랜딩 페이지에서의 활동 등. user 를 표현 할 수 있는 profile feature data 는 잘 정제 되어 있다는 전제하에 본 논문이 제시하는 user representation learning 모델을 살펴보자. </p><p><img src="/2023/02/26/20230226-paper-RALM-1/Untitled.png" alt="그림 : User representation learning Model Architecture"></p><p>그림 : User representation learning Model Architecture</p><p><strong>Sampling</strong></p><p>먼저, 본 논문은 user representation embedding 을 학습시키기 위해 multi-class classification 문제를 만들었다. 유저마다 클릭하는 아이템의 카테고리를 부여하고, 각 카테고리로 분류하는 문제이다. 이 때 수 많은 카테고리가 존재할 것이고, 유저의 분포와 카테고리 마다의 분포가 학습시키는데 불리하므로, 다음과 같은 negative sampling 을 활용했다.</p><p>$$<br>p(x_{i})&#x3D; \frac {log(k+2)-log(k+1)}{log(D+1)}<br>$$</p><ul><li>$x_{i}$ : i번째 아이템</li><li>$k$ : i 번째 아이템의 랭크</li><li>$D$ : 아이템 랭크의 최댓값</li><li>$p(x_{i})$ : i번째 아이템이 뽑힐 확률</li></ul><p>본 논문에서는 negative sampling 에서 poitive : negative 의 비율을 1:10으로 설정했다.</p><p><strong>모델 구조</strong></p><p>본 몬문에서는 위의 multi-class classification 문제를 풀기 위해, 모델 구조는 다음과 같이 간단하다.</p><ol><li>Embedding layer : (user, item)</li><li>(2-1) Concatenation layer : 붙이자!  or (2-2) Attention merge layer : 잘 붙이자!</li><li>Multi layer perceptron</li><li>(optimizer) Adam optimizer</li></ol><p> 마지막 Loss 는 Cross Entropy Loss</p><p>$$<br>L &#x3D; - \Sigma_{j \in X} y_ilogP(c&#x3D;i| U, X_{i})<br>$$</p><ul><li>$X$: 아이템 embedding 집합</li><li>$y_{i}$ : 0 or 1 의 라벨</li></ul><p><strong>Attention Merge Layer</strong></p><p>본 논문에서는 단순 concatenation layer 을 사용하니, 특정 아이템 필드에서 오버피팅 되는 문제가 있어, 강하고 약한 상관관계를 묘사하기 위해 다음과 같은 attention 유닛을 사용했다. </p><p>$$<br>u&#x3D;tanh(W_{1}H)<br>$$</p><p>$$<br>a_{i} &#x3D; \frac {e^{W_{2}u_{i}^{T}}}{\Sigma_{j}^{n}e^{W_{2}u_{j}^{T}}}<br>$$</p><ul><li>$h \in \mathbb {R}^m$, $H \in \mathbb {R^{n \times m}}$</li><li>$W_1 \in \mathbb{R}^{k \times n}$, $W_2 \in \mathbb {R}^{k}$</li><li>$u \in \mathbb{R}^n$ : activation 유닛</li><li>$a \in \mathbb{R}^{n}$ : attention weight</li><li>$k$ : attention 유닛 사이즈</li></ul><p>위 식을 계산하고, 최종적으로 concatenated layer 를 대신하는 vector 는 다음과 같이 계산된다.</p><p>$$<br>M&#x3D;aH<br>$$</p><h3 id="2-User-Representation-Learning-구현에-있어서-마주한-문제들"><a href="#2-User-Representation-Learning-구현에-있어서-마주한-문제들" class="headerlink" title="2. User Representation Learning 구현에 있어서 마주한 문제들."></a>2. User Representation Learning 구현에 있어서 마주한 문제들.</h3><p><strong>2-1. User Profile Data</strong></p><p>처음과 끝은 데이터임은 모든 데이터사이언티스트가 가지고 있는 고민이다. 양질의 데이터 웨어하우스를 구성하는것. 본 논문을 구현하고 시스템에 테스트 하는데 있어 가장 오랜 시간이 걸린 것이 입력 데이터 웨어하우스를 구성하는 것이었다. 기존에 사용하고 있는 데이터에서 attention 학습을 위해 시계열적인 학습 데이터를 구성했다. 그리고 여전히 추가되는 새로운 feature에 대해서도 고민하고 있다. 광고 특성상 각 소재 및 매체마다 붙는 IAB 카테고리 뿐만 아니라, 유저의 활동에도 각 카테고리 값을 시계열적으로 담았다. 본 논문의 아이디어를 차용해, 일정 기간 동안 클릭 및 전환하는 IAB 카테고리 내에서의 네거티브 샘플링을 적용했다.</p><p><strong>2-2. Attention Merge Layer의 효과</strong></p><p>본 논문처럼 나 역시 base model을 단순 concatenated layer 로 잡았다. (torch.concat 만 하면 되니까..) 반면에 논문에서 소개된 구조로 attention layer를 추가한 다음 모델에서는 학습 시키는데 어려움이 있었다. 특정 attention weight 만 업데이트 되는 문제를 발견하게 되었다. attention 목적에 맞는 기능을 하긴 했으나, 특정 attention weight 만 업데이트가 되면서, 일부 item embedding 은 반영되지 못하는 효과가 있었다. 이를 만회하기 위해, 나는 attention merge layer 와 base 모델의 concatenated layer 구조를 z 축으로 붙여 학습시키기도 하였다. 수치상으로는 앞 선 두 구조보다 나은 결과를 보였으나, 해당 구조가 같는 의미와 기능은 조금더 고민해보아야 한다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;본 글에서는 Real-time Attention Based Look-alike Model for Recommender System 논문의 핵심을 살펴보고, 위 논문의 각 파트를 구현하면서 마주한 문제와 고민을 공유해보고자 한다. Part 1, 2로 나누어 User representation learning 파트와 Online Processing 파트를 나누어 살펴보자.&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="https://emjayahn.github.io/categories/Paper/"/>
    
    
    <category term="글또" scheme="https://emjayahn.github.io/tags/%EA%B8%80%EB%98%90/"/>
    
    <category term="논문리뷰" scheme="https://emjayahn.github.io/tags/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"/>
    
    <category term="추천시스템" scheme="https://emjayahn.github.io/tags/%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C/"/>
    
    <category term="Look-alike" scheme="https://emjayahn.github.io/tags/Look-alike/"/>
    
  </entry>
  
  <entry>
    <title>[글또] 글또 8기를 시작하는 글</title>
    <link href="https://emjayahn.github.io/2023/02/04/20230204-geultto-objective/"/>
    <id>https://emjayahn.github.io/2023/02/04/20230204-geultto-objective/</id>
    <published>2023-02-04T11:53:16.000Z</published>
    <updated>2023-02-04T11:54:44.199Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="01-Greetings"><a href="#01-Greetings" class="headerlink" title="01. Greetings"></a>01. Greetings</h2><p>글또 8기를 시작하며, 앞으로 활동하는 동안 목표하고자 하는 바를 정리해본다. </p><p>작년 한해 동안 너무나도 정신없는 한해를 보냈다. 회사 내에서 머신러닝 프로젝트 2건에 대한 기획에서부터 ETL, Data Pipeline, 모델 연구 개발, 모델 서빙까지 작업했다. 한 해를 돌아보면서 아쉬웠던 부분은 새롭게 알게된 다양한 기술(특히, Data Engineering 분야와 MLOps 분야)과 새로 접하는 논문 (Tabular Network, RecSys), 그리고 작업한 코드들을 단백하게 정리하지 못했던 것이다.</p><p>이번 활동을 통해서, 알고 싶은 것과 알게 된 것을 <strong>체계적이고 알기 쉽게 정리하는 것</strong>이 나의 목표이다.</p><span id="more"></span><h2 id="02-Objective"><a href="#02-Objective" class="headerlink" title="02. Objective"></a>02. Objective</h2><p>이번 글또 8기를 활동하면서 목표하는 바는 다음과 같다.</p><ol><li>글 쓰는 습관 기르기<ul><li>평소 논문 요약과 기술 정리는 개인적으로 정리하고 있으나, 남에게 공개할 만큼 “글”로 묘사 하지 않는다. 이런 점은 작성할 때는 편하지만, 다시 볼 때 기억을 되살리는 면에서 매우 큰 약점을 가지고 있다. 심지어는 논문을 다시 읽을 떄도 있고, 코드 전문을 다시 볼 때도 많다.</li><li>주제를 선정해, 공개하는 글에 대해서는 최대한 자세하고 친절한 설명과 정리를 하겠다.</li></ul></li><li>추천시스템, 특히 CTR based &#x2F; Audience Extension 추천 정리<ul><li>요즘 관심 있는 주제는 CTR based 추천과 Audience  Extension 에 대한 추천에 관심이 많다.</li><li>잡고 있는 논문 중심으로 정리하며, 테스트를 진행할 수 있는 코드를 짜는 것이 목표이다.</li></ul></li><li>NiFi, Airflow 정리<ul><li>작년부터 nifi 를 활용해 데이터 파이프라인 구축을 완료했다. Nifi 를 활용해 튜닝 할 수 있는 부분을 알게 될 때 마다 잘 정리하고 싶다. 또한 다른 회사에서는 airflow 를 많이 활용 하고 있다보니, nifi와의 공통점&#x2F;차이점들을 살펴볼 필요가 있겠다는 생각을 했다. 틈틈히 airflow부분도 살펴봐야겠다.</li></ul></li><li>다른 분들의 글 읽기 &#x2F; 커피챗 참여<ul><li>글또에 정말 다양한 분야에 계신 분들이 많다. 머신러닝&#x2F;ai 와 관련된 분야 뿐만 아니라 데이터 엔지니어, 데이터 분석 분야에 글을 틈틈히 읽고 싶다. 또 광고 분야에 계신분들도 있는 것 같아,  ad-tech 관련된 글과 커뮤니케이션도 많이 할 수 있을 것 같아 기대 중이다.</li></ul></li><li>블로그 플랫폼 이사<ul><li>현재 github 블로그를 이용중이다. 근데 이사하고 싶다.</li><li>현재 후보는 tistory, oopy, medium.<ul><li>새로운 플랫폼을 활용하려면 또 시간을 내어서 플랫폼 탐색을 해야하기 때문에.. 매번 글을 업로드 할 때마다  github 외에 한군데씩 올려보고, 조금씩 만져보며 이사를 천천히 준비하려고 한다.</li></ul></li></ul></li></ol><h2 id="03-Conclusion"><a href="#03-Conclusion" class="headerlink" title="03. Conclusion"></a>03. Conclusion</h2><p>가볍게 쓰기 시작한 목표 정리 글이 쓰다보니 장대해진 것 같다. 6개월이 지난 시점에 활동을 마무리 하면서 후회 없는 시간이 되었으면 좋겠다.</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;01-Greetings&quot;&gt;&lt;a href=&quot;#01-Greetings&quot; class=&quot;headerlink&quot; title=&quot;01. Greetings&quot;&gt;&lt;/a&gt;01. Greetings&lt;/h2&gt;&lt;p&gt;글또 8기를 시작하며, 앞으로 활동하는 동안 목표하고자 하는 바를 정리해본다. &lt;/p&gt;
&lt;p&gt;작년 한해 동안 너무나도 정신없는 한해를 보냈다. 회사 내에서 머신러닝 프로젝트 2건에 대한 기획에서부터 ETL, Data Pipeline, 모델 연구 개발, 모델 서빙까지 작업했다. 한 해를 돌아보면서 아쉬웠던 부분은 새롭게 알게된 다양한 기술(특히, Data Engineering 분야와 MLOps 분야)과 새로 접하는 논문 (Tabular Network, RecSys), 그리고 작업한 코드들을 단백하게 정리하지 못했던 것이다.&lt;/p&gt;
&lt;p&gt;이번 활동을 통해서, 알고 싶은 것과 알게 된 것을 &lt;strong&gt;체계적이고 알기 쉽게 정리하는 것&lt;/strong&gt;이 나의 목표이다.&lt;/p&gt;</summary>
    
    
    
    <category term="글또" scheme="https://emjayahn.github.io/categories/%EA%B8%80%EB%98%90/"/>
    
    
    <category term="글또" scheme="https://emjayahn.github.io/tags/%EA%B8%80%EB%98%90/"/>
    
    <category term="목표" scheme="https://emjayahn.github.io/tags/%EB%AA%A9%ED%91%9C/"/>
    
  </entry>
  
  <entry>
    <title>[글또] 삶의 지도</title>
    <link href="https://emjayahn.github.io/2023/01/14/20230114-geultto-map-of-life/"/>
    <id>https://emjayahn.github.io/2023/01/14/20230114-geultto-map-of-life/</id>
    <published>2023-01-14T14:25:26.000Z</published>
    <updated>2023-01-14T14:56:59.567Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="00-들어가는-글"><a href="#00-들어가는-글" class="headerlink" title="00. 들어가는 글"></a>00. 들어가는 글</h2><p>글또 8기에 지원하며, <strong>삶의 지도</strong>를 그려보는 시간을 가졌다. 공지를 보고 일주일이 지나도록 어떻게 글을 써내려가야 할지 손이 움직이지 않았다. 나 자체를 돌아보며, 글 자체보다 나를 돌아보는 이 시간들이 매우 값졌다. 나를 이루는 다양한 면들이 단순히 한가지 사건에서 비롯되지 않았다는 것을 깨달음과 동시에 복잡하게 얽힌 시간과 경험을 글로 써내려가며 조금씩 정리 되는 것도 경험했다. 아래의 짧은 글을 통해서 조금이나마 나에게 관심 있는 사람들에게 내 <strong>삶의 지도</strong>가 잘 전달되었으면 한다. </p><span id="more"></span><h2 id="01-모험과-도전을-즐기는-현재의-나"><a href="#01-모험과-도전을-즐기는-현재의-나" class="headerlink" title="01. 모험과 도전을 즐기는 현재의 나"></a>01. 모험과 도전을 즐기는 현재의 나</h2><p>#2023 #데이터사이언티스트 #ML엔지니어 #개척자 #도전</p><p>나는 현재 나스미디어 데이터사이언티스트로 일을 하고 있다. 미디어렙사이자 광고 플랫폼을 운영하고 있는 나스미디어는 온라인 &#x2F; 오프라인 광고 시장에서 1위를 선점하고 있는 회사이다. 이곳의 데이터사이언티스트로 일을 하면서 다양한 프로젝트를 리딩하고, 현재는 광고 추천 시스템을 연구하고 있다.</p><p>나는 나스미디어 최초의 데이터사이언티스트로 입사했다. 2021년에 들어왔을 때 우리 데이터사이언스팀은 팀원이 혼자인 1인팀이었고, 현재는 7명의 팀원들이 있다. 처음 회사에 들어왔을 때는 연구개발을 위한 인프라도 부재했고, 하루 수억건의 트래픽 데이터는 머신러닝&#x2F;데이터분석을 위한 형태로 적재되지 않았다. 처음 입사하자마자 광고 도메인에 대한 비지니스 공부를 함과 동시에 이런 인프라를 구축하는데 힘을 썼다. </p><p>2021년의 나스미디어에 합류한 나의 결정을 돌아보니, 나는 모험과 도전을 좋아하는 사람이다. 또한 나를 가장 들뜨게 하는 것은 이런 모험과 도전을 하는 과정에서 겪는 시행착오와 그 시행착오 끝에 얻어지는 지혜와 지식을 정리하고 알아가는 과정에 희열을 느끼는 사람이다. 지금도 내가 모르는 것에 대한 탐구와 아는 것을 정리하여 공유할 때 얻어지는 보람을 향해 달려가고 있다. </p><h2 id="02-암흑기-현재의-초석이된-과거의-나"><a href="#02-암흑기-현재의-초석이된-과거의-나" class="headerlink" title="02. 암흑기.. 현재의 초석이된 과거의 나"></a>02. 암흑기.. 현재의 초석이된 과거의 나</h2><p>#201x #고시생 #회색빛 #밑거름</p><p>지금의 나를 이루고 있는 성격&#x2F;지식&#x2F;삶에 대한 태도가 언제 구성되었는가 돌이켜보니, 21살의 내가 떠올랐다. 나는 대학에 입학하고, 21살부터 고시생이 되었다. 그리고 5년을 신림동 고시촌에서 공부했고, 첫 실패와 포기라는 단어를 마주했다. 주변 지인들과 그 시절을 회상하며 나는 “회색빛의 나와 회색하늘의 신림”이라는 표현을 자주했다. 하지만 그 때의 경험은 지금의 나를 지탱하는 큰 밑거름이다.</p><p><strong>도전. 실패. ..그리고 다시 도전.</strong> </p><p>시험에 도전하고, 그리고 도전과 도전 사이에는 반드시 실패가 존재한다. 당시에는 도전 자체에 큰 의미를 두었지만, 지금의 나는 그 실패를 딛고 일어서는 자세에 대해 중요하게 생각한다. 어떤 일과 계획이 뜻대로 되지 않을 때 우리는 이를 실패라고 정의 할 수 있다. 하지만 실패는 다음 실행과 계획에 중요한 경험을 쌓게 한다. 이 가치관은 과거의 내가 여러차례의 낙방을 경험하며 체화된 가치관이다.</p><p><strong>쌓인 지식. 컴퓨터, 데이터, 프로그래밍.</strong></p><p>고시생활을 5년 하면서, 5년 동안 24시간 공부만 했겠는가. 시험기간에는 평소에 보지도 않던 뉴스가 그렇게 재밌을수가 없다는 것은 모두가 공감할 것이다. 나 역시 하루 12시간 공부를 하고 녹초가 되어 집에 돌아와서 법전을 다시 펴지 못했다. 고시생활의 유일한 낙은 밤에 와서 보는 열혈강의 C언어 책과 C by Dissection 전공책이었다. 전공시간 때는 하나도 재미없었던 책을 아무 생각 없이(?) 코드를 타이핑하면서 보내는 시간을 좋아했었다. 다음날 아침 6시에 독서실을 나가야하는데, 새벽 3시까지 테트리스 게임을 짤 때도 있었다. 그 때의 딴짓은 지금의 밑거름이 되었다.</p><table>    <tr>        <td>            <figure>                <img src="./IMG_9078.jpeg">                <figcaption>지금도 간직하고 있는 그 시절 열혈강의 C.<br>요즘은 표지가 바뀌었다는데..</figcaption>            </figure>        </td>        <td>            <figure>                <img src="./IMG_9079.jpeg" width=95%>                <figcaption>지금도 간직하고 있는 그 시절 <br>C by Dissection 전공책. </figcaption>            </figure>        </td>    </tr></table> <!-- alt="그 시절 열혈강의 C. 요즘은 표지가 바뀌었다는데." --><!-- alt="지금도 간직하고 있는 그 시절 C by Dissection 전공책" --><!-- ![[사진] 지금도 간직하고 있는 그 시절 C by Dissection 전공책](IMG_9079.jpeg)<!-- ![[사진] 그 시절 열혈강의 C. 요즘은 표지가 바뀌었다는데.](IMG_9078.jpeg) --><h2 id="03-데이터사이언스로의-도전하는-나"><a href="#03-데이터사이언스로의-도전하는-나" class="headerlink" title="03. 데이터사이언스로의 도전하는 나"></a>03. 데이터사이언스로의 도전하는 나</h2><p>#딥러닝 #알파고 #다시도전</p><p>2016년에 늦은 나이로 군입대를 한 나는 알파고와 이세돌 대국을 경험하며, 딥러닝이 뉴스를 도배하는 시기를 마주한다. 딥러닝이라는 단어는 이미지 프로세싱 전공 수업 마지막 챕터에서 접했지만, “대학원에 와서 공부하라”는 교수님의 말씀만 기억이 날뿐었다. 전공수업에서 나왔던 단어가 뉴스를 도배하니, 자연스레 관심이 갔다. 이미지프로세싱 교과서를 다시 펼쳐보며, 모델 위주로 공부하던 나는 점차 데이터 생애 주기의 앞으로 관심이 갔다. 어떤 데이터가 어떻게 생성되며, 적재되는 방법과 관리하는 체계에 관심이 갔고, 분석하고 그 끝에 모델링을 하고 서빙하는 그 과정 전체를 공부하기 시작했다.</p><p>지금도 이 관심사는 여전하다. 다양한 기술과 새로운 방법론을 접할 때마다 관심을 갖고 follow-up 하려는 나의 노력은 <strong>과거의 나의 존재</strong>들이 만들어준 좋은 습관인 것 같다.</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;00-들어가는-글&quot;&gt;&lt;a href=&quot;#00-들어가는-글&quot; class=&quot;headerlink&quot; title=&quot;00. 들어가는 글&quot;&gt;&lt;/a&gt;00. 들어가는 글&lt;/h2&gt;&lt;p&gt;글또 8기에 지원하며, &lt;strong&gt;삶의 지도&lt;/strong&gt;를 그려보는 시간을 가졌다. 공지를 보고 일주일이 지나도록 어떻게 글을 써내려가야 할지 손이 움직이지 않았다. 나 자체를 돌아보며, 글 자체보다 나를 돌아보는 이 시간들이 매우 값졌다. 나를 이루는 다양한 면들이 단순히 한가지 사건에서 비롯되지 않았다는 것을 깨달음과 동시에 복잡하게 얽힌 시간과 경험을 글로 써내려가며 조금씩 정리 되는 것도 경험했다. 아래의 짧은 글을 통해서 조금이나마 나에게 관심 있는 사람들에게 내 &lt;strong&gt;삶의 지도&lt;/strong&gt;가 잘 전달되었으면 한다. &lt;/p&gt;</summary>
    
    
    
    <category term="글또" scheme="https://emjayahn.github.io/categories/%EA%B8%80%EB%98%90/"/>
    
    
    <category term="글또" scheme="https://emjayahn.github.io/tags/%EA%B8%80%EB%98%90/"/>
    
    <category term="지원서" scheme="https://emjayahn.github.io/tags/%EC%A7%80%EC%9B%90%EC%84%9C/"/>
    
    <category term="회고" scheme="https://emjayahn.github.io/tags/%ED%9A%8C%EA%B3%A0/"/>
    
  </entry>
  
  <entry>
    <title>[MAC] xcrun: error: invalid active developer 에러 해결방법</title>
    <link href="https://emjayahn.github.io/2022/12/12/20221212-mac-xcrunn-error-invalid-active-ddeveloper-error/"/>
    <id>https://emjayahn.github.io/2022/12/12/20221212-mac-xcrunn-error-invalid-active-ddeveloper-error/</id>
    <published>2022-12-11T16:24:43.000Z</published>
    <updated>2022-12-11T16:30:15.433Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>방금 전, MacOS Ventura 13.0.1로 업그레이드 하고, flutter, python 개발 중 다음 과 같은 에러 코드를 내뱉으며 잘 되던 것들이 안되기 시작했다.<br>간단한 git부터 시작해서, 맥 내 환경변수를 포함하는 대부분의 명령어에서 다음과 같은 에러 메시지를 보냈다. 다음 글에서 그 해결방법을 정리했다.</p><span id="more"></span><h2 id="Error-Message"><a href="#Error-Message" class="headerlink" title="Error Message"></a>Error Message</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun</span><br></pre></td></tr></table></figure><p><img src="/2022/12/12/20221212-mac-xcrunn-error-invalid-active-ddeveloper-error/Untitled.png" alt="[Error Message] xcrun: error: invalid active developer"></p><p>[Error Message] xcrun: error: invalid active developer</p><p>이런 현상은 맥 OS를 업데이트하면 종종 나타나왔었는데, M1으로 넘어오고나서는 처음 보는 현상이기에 해결법도 여전한지 확인해보며, 이 글을 적고 있다.</p><h2 id="해결방법"><a href="#해결방법" class="headerlink" title="해결방법"></a>해결방법</h2><p>맥의 개발자 도구인 CommandLineTools를 재설치하여 해당 에러를 고칠 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ xcode-select --install</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;방금 전, MacOS Ventura 13.0.1로 업그레이드 하고, flutter, python 개발 중 다음 과 같은 에러 코드를 내뱉으며 잘 되던 것들이 안되기 시작했다.&lt;br&gt;간단한 git부터 시작해서, 맥 내 환경변수를 포함하는 대부분의 명령어에서 다음과 같은 에러 메시지를 보냈다. 다음 글에서 그 해결방법을 정리했다.&lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Error&amp;Solution" scheme="https://emjayahn.github.io/categories/Development/Error-Solution/"/>
    
    
    <category term="error" scheme="https://emjayahn.github.io/tags/error/"/>
    
    <category term="solution" scheme="https://emjayahn.github.io/tags/solution/"/>
    
    <category term="mac" scheme="https://emjayahn.github.io/tags/mac/"/>
    
    <category term="xcrun" scheme="https://emjayahn.github.io/tags/xcrun/"/>
    
    <category term="commandlinetools" scheme="https://emjayahn.github.io/tags/commandlinetools/"/>
    
  </entry>
  
  <entry>
    <title>[github] github token 설정 및 키체인 등록</title>
    <link href="https://emjayahn.github.io/2022/12/05/20221205-github-setting/"/>
    <id>https://emjayahn.github.io/2022/12/05/20221205-github-setting/</id>
    <published>2022-12-05T11:01:59.000Z</published>
    <updated>2022-12-05T11:07:04.847Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>최근에 맥북을 사고, 새로산 맥북에 개발환경을 하나씩 셋팅하고 있다. 그러면서 오랜만에 등록하는 github token과 매번 귀찮게 비밀번호를 기입하는 것을 막기 위한 키체인 등록까지 완료하여, 이 부분을 정리해 기록한다.</p><p>이번 글에서 소개하는 github 환경 셋팅은 크게 두 단계로 나뉜다.</p><ol><li>github token 발급</li><li>macbook에 token 저장 및 git config 수정</li></ol><span id="more"></span><h2 id="1-github-token-발급"><a href="#1-github-token-발급" class="headerlink" title="1. github token 발급"></a>1. github token 발급</h2><h3 id="1-1-github-접속-및-설정-페이지-접속"><a href="#1-1-github-접속-및-설정-페이지-접속" class="headerlink" title="1-1. github 접속 및 설정 페이지 접속"></a>1-1. github 접속 및 설정 페이지 접속</h3><p>자신의 github 계정에 접속하여 오른쪽 상단에 <code>setting</code> 을 클릭한다.</p><p><img src="/2022/12/05/20221205-github-setting/Untitled.png" alt="Untitled"></p><h3 id="1-2-Developer-Settings-에-접속"><a href="#1-2-Developer-Settings-에-접속" class="headerlink" title="1-2. Developer Settings 에 접속"></a>1-2. Developer Settings 에 접속</h3><p>왼쪽에 developer settings 클릭</p><p><img src="/2022/12/05/20221205-github-setting/Untitled_1.png" alt="Untitled"></p><h3 id="1-3-Token-메뉴-접속"><a href="#1-3-Token-메뉴-접속" class="headerlink" title="1-3. Token 메뉴 접속"></a>1-3. Token 메뉴 접속</h3><p>빨간색 박스 친 부분을 클릭하여, 토큰 생성 페이지에 접속한다.</p><p><img src="/2022/12/05/20221205-github-setting/Untitled_2.png" alt="Untitled"></p><p><img src="/2022/12/05/20221205-github-setting/Untitled_3.png" alt="Untitled"></p><h3 id="1-4-생성하는-Token의-권한-생성"><a href="#1-4-생성하는-Token의-권한-생성" class="headerlink" title="1-4. 생성하는 Token의 권한 생성"></a>1-4. 생성하는 Token의 권한 생성</h3><p>(1) 본인이 관리 할 수 있도록 이름을 지어준다.</p><p>(2) 본 토큰의 만료 일자 지정</p><p>(3) 토큰의 권한 범위 설정</p><p><img src="/2022/12/05/20221205-github-setting/Untitled_4.png" alt="Untitled"></p><h3 id="1-5-생성되는-토큰-저장"><a href="#1-5-생성되는-토큰-저장" class="headerlink" title="1-5. 생성되는 토큰 저장"></a>1-5. 생성되는 토큰 저장</h3><p>하단의 Generate token 버튼을 누르면 토큰이 발급된다. 본 토큰은 해당 페이지를 닫으면 더이상 확인 할 수 없으므로 잘 복사해두고 관리 해두어야 한다.</p><p>나는 개인 맥북에서 환경설정을 하는 중이므로, 다음 단계를 통해 해당 토큰을 내 개인 맥북의 keychain 에 저장하여 자동으로 기입 될 수 있도록 했다.</p><h2 id="2-Keychain-등록-및-비밀번호-자동기입"><a href="#2-Keychain-등록-및-비밀번호-자동기입" class="headerlink" title="2. Keychain 등록 및 비밀번호 자동기입"></a>2. Keychain 등록 및 비밀번호 자동기입</h2><h3 id="2-1-keychain-access-application-실행"><a href="#2-1-keychain-access-application-실행" class="headerlink" title="2-1. keychain access application 실행"></a>2-1. keychain access application 실행</h3><p>맥북 spotlight에서 <code>keychain [Access.app](http://Access.app) (키체인 접근)</code> 을 검색하여 들어간다.</p><p>검색에서 <a href="http://github.com/">github.com</a> 을 검색한다.</p><p><img src="/2022/12/05/20221205-github-setting/Untitled_5.png" alt="Untitled"></p><p>검색 결과, 방금 생성한 token 이 등록 되어 있으면 상관없지만 만약 등록 되어 있지 않다면, </p><p>이름 : github.com</p><p>계정 : 본인 깃헙 아이디</p><p>암호 : 방금 생성한 토큰</p><p>위 내용으로 등록한다.</p><h3 id="2-2-github-config-에-키체인-등록"><a href="#2-2-github-config-에-키체인-등록" class="headerlink" title="2-2.  github config 에  키체인 등록"></a>2-2.  github config 에  키체인 등록</h3><p>기본 terminal 혹은 iterm에서 github config 를 등록해준다.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --<span class="variable language_">global</span> credential.<span class="property">helper</span> oskeychain</span><br></pre></td></tr></table></figure><p>위 과정을 통해, 깃헙 비밀번호(토큰) 기입 없이 자유롭게 푸쉬할 수 있게 된다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;최근에 맥북을 사고, 새로산 맥북에 개발환경을 하나씩 셋팅하고 있다. 그러면서 오랜만에 등록하는 github token과 매번 귀찮게 비밀번호를 기입하는 것을 막기 위한 키체인 등록까지 완료하여, 이 부분을 정리해 기록한다.&lt;/p&gt;
&lt;p&gt;이번 글에서 소개하는 github 환경 셋팅은 크게 두 단계로 나뉜다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;github token 발급&lt;/li&gt;
&lt;li&gt;macbook에 token 저장 및 git config 수정&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Git" scheme="https://emjayahn.github.io/categories/Development/Git/"/>
    
    
    <category term="git" scheme="https://emjayahn.github.io/tags/git/"/>
    
    <category term="development" scheme="https://emjayahn.github.io/tags/development/"/>
    
    <category term="개발환경" scheme="https://emjayahn.github.io/tags/%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD/"/>
    
    <category term="setting" scheme="https://emjayahn.github.io/tags/setting/"/>
    
  </entry>
  
  <entry>
    <title>[Linux] LightGBM GPU 버전 설치 및 환경설정</title>
    <link href="https://emjayahn.github.io/2022/12/05/light-gbm-setting/"/>
    <id>https://emjayahn.github.io/2022/12/05/light-gbm-setting/</id>
    <published>2022-12-04T16:14:55.000Z</published>
    <updated>2022-12-05T08:54:55.763Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>LightGBM GPU 버전 Install의 경우,<br>OpenCL 기반의 LightGBM-GPU와 CUDA 기반의 LightGBM-CUDA 버전이 있다.<br>리눅스 환경에서 LightGBM의 설치와 환경설정은 자칫 까다로울 수 있다. 이번 글을 통해 정리해보자.</p><span id="more"></span><h3 id="OpenCL-Version-Documentation"><a href="#OpenCL-Version-Documentation" class="headerlink" title="OpenCL Version Documentation"></a>OpenCL Version Documentation</h3><p><a href="https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#id17">Installation Guide - LightGBM 3.3.2 documentation</a></p><h3 id="CUDA-Version-Documentation"><a href="#CUDA-Version-Documentation" class="headerlink" title="CUDA Version Documentation"></a>CUDA Version Documentation</h3><p><a href="https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#id20">Installation Guide - LightGBM 3.3.2 documentation</a></p><p>현재 환경은 NvidiaA100 GPU의 CUDA 환경이 미리 셋팅 되어 있어, 기존 LightGBM-GPU 버전이 아닌, CUDA 버전을 설치하려고 한다.</p><h2 id="1-환경변수-설정"><a href="#1-환경변수-설정" class="headerlink" title="1. 환경변수 설정"></a>1. 환경변수 설정</h2><p>CUDA 환경을 설정하면, CUDA의 환경변수를 각 계정별로 셋팅 해주어야 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># .bashrc에 다음의 환경변수를 추가해준다.</span></span><br><span class="line"><span class="comment"># CUDA SETTING</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/cuda-11.6/bin</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda-11.6/lib64</span><br><span class="line"><span class="built_in">export</span> CUDADIR=/usr/local/cuda-11.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 저장후 반드시 실행</span></span><br><span class="line">$ <span class="built_in">source</span> .bashrc</span><br></pre></td></tr></table></figure><h2 id="2-Download-LightGBM"><a href="#2-Download-LightGBM" class="headerlink" title="2. Download LightGBM"></a>2. Download LightGBM</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/microsoft/LightGBM</span><br></pre></td></tr></table></figure><h2 id="3-Build"><a href="#3-Build" class="headerlink" title="3. Build"></a>3. Build</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> LightGBM</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake -DUSE_CUDA=1 ..</span><br><span class="line">make -j4</span><br></pre></td></tr></table></figure><h2 id="4-Install"><a href="#4-Install" class="headerlink" title="4. Install"></a>4. Install</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../python-package</span><br><span class="line">python3 setup.py install</span><br></pre></td></tr></table></figure><h2 id="5-Troubleshooting"><a href="#5-Troubleshooting" class="headerlink" title="5. Troubleshooting"></a>5. Troubleshooting</h2><ul><li>지금 환경의 경우, root에 python이 설치 되어있고, 환경변수를 설정해 각 계정 별로 python 과 pip (python package manager) 가 독립되어 있는 환경이다.</li><li>위의 <code>python3 [setup.py](http://setup.py) install</code> 을 하는 경우, 다음과 같은 에러가 난다.</li></ul><p><img src="/2022/12/05/light-gbm-setting/Untitled.png" alt="Untitled"></p><ul><li><p>이는 root에 있는 site-packages에 현재 lightgbm 을 설치하는데 있어, permission denied : 권한 설정 에러이다.</p><ul><li>회사의 python은 절대 루트에서 작업하지 않는 원칙으로 환경을 설정했고, 이 에러는 당연하다.</li><li>따라서 해당 계정 패키지 매니저에 위 과정에서 compile 된 lightgbm을 설치해 주면 된다.</li></ul></li><li><p>위 <code>[setup.py](http://setup.py)</code> 실행을 통해 컴파일된 파일을 이용하여, 계정 패키지 매니저에 설치해준다.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --install-option=--precompile --user .</span><br></pre></td></tr></table></figure></li></ul><h2 id="6-정상-설치-확인"><a href="#6-정상-설치-확인" class="headerlink" title="6. 정상 설치 확인"></a>6. 정상 설치 확인</h2><p><img src="/Untitled_01.png" alt="Untitled"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;LightGBM GPU 버전 Install의 경우,&lt;br&gt;OpenCL 기반의 LightGBM-GPU와 CUDA 기반의 LightGBM-CUDA 버전이 있다.&lt;br&gt;리눅스 환경에서 LightGBM의 설치와 환경설정은 자칫 까다로울 수 있다. 이번 글을 통해 정리해보자.&lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Linux" scheme="https://emjayahn.github.io/categories/Development/Linux/"/>
    
    
    <category term="setting" scheme="https://emjayahn.github.io/tags/setting/"/>
    
    <category term="linux" scheme="https://emjayahn.github.io/tags/linux/"/>
    
    <category term="lightgbm" scheme="https://emjayahn.github.io/tags/lightgbm/"/>
    
    <category term="machine learning" scheme="https://emjayahn.github.io/tags/machine-learning/"/>
    
    <category term="환경설정" scheme="https://emjayahn.github.io/tags/%ED%99%98%EA%B2%BD%EC%84%A4%EC%A0%95/"/>
    
  </entry>
  
  <entry>
    <title>회귀 모델 성능평가지표 : MAE, MSE, RMSE, R2 Score</title>
    <link href="https://emjayahn.github.io/2022/02/10/Regression-Score/"/>
    <id>https://emjayahn.github.io/2022/02/10/Regression-Score/</id>
    <published>2022-02-10T06:40:03.000Z</published>
    <updated>2022-02-10T06:54:18.012Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li>회귀모델의 대표적인 성능 지표를 알아보는 글입니다.</li><li>회귀 모델에서는 얼마나 정확하게 그 값을 예측하는 지가 중요합니다. y값의 형태는 낙찰가격처럼 연속된 실수형태이기 때문에, 그 값을 정확하게 예측하거나 가장 근사치로 예측하는 것이 가장 중요합니다. 따라서 회귀모델에서의 성능평가 지표는 실제y값과 예측y값을 비교합니다.</li><li>대표적인 성능평가 지표에는 다음과 같은 4가지 종류가 있습니다.</li></ul><ol><li>MAE (Mean Absolute Error)</li><li>MSE (Mean Squared Error)</li><li>RMSE (Root Mean Squared Error)</li><li>R2 Score (Coefficient of Determination) : 결정 계수</li></ol><span id="more"></span><h2 id="1-MAE-Mean-Absolute-Error"><a href="#1-MAE-Mean-Absolute-Error" class="headerlink" title="1. MAE (Mean Absolute Error)"></a>1. MAE (Mean Absolute Error)</h2><ul><li><p>MAE 계산 순서</p><ol><li>오차 &#x3D; 실제값 - 예측값</li><li>절댓값 오차 : |오차|</li><li>모든 데이터의 오차를 구해야 하므로 시그마를 취함</li><li>오차의 전체 분포 파악을 위해 평균을 취함</li></ol></li><li><p>위 계산 순서를 수식으로 표현하면 다음과 같습니다.</p></li></ul><p>$$MAE &#x3D; \frac { { \Sigma |y_{true}-y_{pred} | } } {n}$$</p><ul><li>MAE의 특징<ul><li>Error의 절대값을 취하기 때문에, 에러의 크기가 그대로 반영됨</li><li>평균값이기 때문에, 개별 데이터의 에러의 평균 통계량을 의미</li><li>에러에 따른 Loss 가 선형적으로 올라갈 때 적합</li><li>이상치가 많을 때 주로 사용</li></ul></li></ul><h2 id="2-MSE-Mean-Squared-Error"><a href="#2-MSE-Mean-Squared-Error" class="headerlink" title="2. MSE (Mean Squared Error)"></a>2. MSE (Mean Squared Error)</h2><ul><li><p>MSE 의 계산 순서</p><ol><li><p>오차 &#x3D; 실제값 - 예측값</p></li><li><p>오차의 제곱</p></li><li><p>모든 데이터의 오차를 구해야하므로 시그마를 취함</p></li><li><p>오차의 전체 분포 파악을 위해 평균을 취함</p></li></ol></li><li><p>수식 표현</p><p>  $$MSE &#x3D; \frac { { \Sigma (y_{true}-y_{pred})^2 } } {n}$$</p></li><li><p>MSE 의 특징</p><ul><li>MAE 는 Loss 에 대해 그대로 반영하는 반면, MSE 는 에러의 제곱을 해주므로, 해당 Loss 를 좀더 강력히 제재하는 효과를 가집니다.</li><li>따라서 이상치가 있는 경우, 에러가 크게 측정되는 경향 이를 모델에 활용</li><li>다만 이 에러의 영향을 크게 하여, 모델 성능을 높이려는 목적</li></ul></li></ul><h2 id="3-RMSE-Root-Mean-Squared-Error"><a href="#3-RMSE-Root-Mean-Squared-Error" class="headerlink" title="3. RMSE (Root Mean Squared Error)"></a>3. RMSE (Root Mean Squared Error)</h2><ul><li><p>RMSE 계산 순서</p><ol><li><p>오차 &#x3D; 실제값 - 예측값</p></li><li><p>오차의 제곱</p></li><li><p>모든 데이터의 오차를 구해야하므로 시그마를 취함</p></li><li><p>오차의 전체 분포 파악을 위해 평균을 취함</p></li><li><p>평균값에 루트</p></li></ol></li><li><p>수식표현</p><p>  $$RMSE &#x3D; \sqrt { \frac { {\Sigma (y_{true}-y_{pred})^2} } {n}}$$</p></li><li><p>RMSE 의 특징</p><ul><li>MSE 의 값은 오차를 제곱해 계산하는 식으로, 그 값이 매우 커지는 경향이 있음</li><li>이를 보완하기 위해, Root 를 씌움</li><li>또한 성능평가 수치가, y 예측 값과 그 단위가 같으므로 직관적인 에러수치</li><li>에러에 따른 Loss 가 기하 급수적으로 올라가는 상황에서 쓰기 적합</li><li>MAE 와 함께 가장 일반적으로 많이 쓰이는 회귀모델 성능분석지표</li></ul></li></ul><h2 id="4-R2-Score-Coefficient-of-Determination-결정계수"><a href="#4-R2-Score-Coefficient-of-Determination-결정계수" class="headerlink" title="4. R2 Score (Coefficient of Determination : 결정계수)"></a>4. R2 Score (Coefficient of Determination : 결정계수)</h2><ul><li><p>R2 Score 는 실제 y의 변동량 대비 모델 예측 y의 변동량을 의미</p><ul><li>즉, 실제 y값의 분산에 비해, 예측 y의 분산이 얼만큼인지 비교</li><li>해당 회귀 모델이 주어진 데이터에 얼마나 적합한지를 평가하는 지표</li><li>상관관계가 높을수록 1에 가까워짐</li><li>(해석 예시) r2 score&#x3D;0.4라면, 40%의 설명력을 가진다고 해석</li></ul></li><li><p>MAE, MSE, RMSE 는 에러에 대한 수치이므로, 그 수치가 작을 수록 좋은 지표</p></li><li><p>R2 Score 는 1에 가까울 수록 성능이 좋음</p></li><li><p>R2 Score 계산</p><p>  $$R^2 Score&#x3D;1-\frac {SSE} {SST} &#x3D; 1- \frac {MSE} {Var(y) }$$</p><p>  $$SSE&#x3D;\frac {1} {n} \Sigma (y_{true}-y_{pred})^2$$</p><p>  $$SST&#x3D;\frac {1} {n} \Sigma (y_{true}-y_{mean})^2$$</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;회귀모델의 대표적인 성능 지표를 알아보는 글입니다.&lt;/li&gt;
&lt;li&gt;회귀 모델에서는 얼마나 정확하게 그 값을 예측하는 지가 중요합니다. y값의 형태는 낙찰가격처럼 연속된 실수형태이기 때문에, 그 값을 정확하게 예측하거나 가장 근사치로 예측하는 것이 가장 중요합니다. 따라서 회귀모델에서의 성능평가 지표는 실제y값과 예측y값을 비교합니다.&lt;/li&gt;
&lt;li&gt;대표적인 성능평가 지표에는 다음과 같은 4가지 종류가 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;MAE (Mean Absolute Error)&lt;/li&gt;
&lt;li&gt;MSE (Mean Squared Error)&lt;/li&gt;
&lt;li&gt;RMSE (Root Mean Squared Error)&lt;/li&gt;
&lt;li&gt;R2 Score (Coefficient of Determination) : 결정 계수&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="DataScience" scheme="https://emjayahn.github.io/categories/DataScience/"/>
    
    <category term="Regression" scheme="https://emjayahn.github.io/categories/DataScience/Regression/"/>
    
    
  </entry>
  
  <entry>
    <title>[Linux] AWK 간단 정리</title>
    <link href="https://emjayahn.github.io/2021/12/07/AWK-basics/"/>
    <id>https://emjayahn.github.io/2021/12/07/AWK-basics/</id>
    <published>2021-12-07T14:32:12.000Z</published>
    <updated>2021-12-07T14:38:14.939Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li>AWK 는 데이터를 다루는 사람들이라면 한번씩은 그 Command를 사용해봤을 것입니다.</li><li>저는 과거 Dataframe 을 생성해 본격적인 분석 및 연구.개발 작업이 들어가기 전에, AWK 를 통해 간단한 데이터 처리를 하는 경우, Raw Data 형식을 간단하게 정제하여 Database에 적재하는 경우에 사용해 왔습니다. 이 경우, 많이 사용하는 관용적인 구문외에는 AWK 자체를 살펴볼 기회가 적었습니다.</li><li>최근 사내에서 로그 데이터의 추출을 위해 AWK를 오랜만에 다시 사용하게 되면서, 잊었던 AWK문법을 다시 한 번 살펴보며, 이번 기회에 AWK의 간단 사용예제부터 AWK 문법 몇가지를 정리해보고자 합니다.</li></ul><span id="more"></span><h2 id="AWK-Aho-Weinberger-Kernighan-오크"><a href="#AWK-Aho-Weinberger-Kernighan-오크" class="headerlink" title="AWK (Aho Weinberger Kernighan 오크)"></a>AWK (Aho Weinberger Kernighan 오크)</h2><ul><li>스크립트 언어</li><li>텍스트 파일을 <strong>조회&#x2F;필터링&#x2F;가공</strong> 출력하는 프로그램</li><li>쉘스크립트 상에서 데이터를 간단히 처리할 수 있는 필수 프로그램</li><li>각 row data는 Enter(줄바꿈, newline)로 구분, column data는 공백, tab으로 구분</li><li>각 row data, 줄은 <strong>레코드(Record)</strong> 라 지칭</li><li>각 데이터, column, 단어 등은 <strong>필드(Field)</strong> 라 지칭</li></ul><h2 id="AWK-의-동작방식"><a href="#AWK-의-동작방식" class="headerlink" title="AWK 의 동작방식"></a>AWK 의 동작방식</h2><ol><li>필드 전체 : <strong>$0</strong>,  특정 필드 지칭 : <strong>$1</strong> ~ (주의 : 0번이 첫번째가 아님!!)</li><li>기본적인 default 구분자는  **공백(Space, Tab)**이나, <strong>-F</strong> 옵션을 줌으로써 구분 기호를 지정가능</li><li>AWK command 형식 : <code>awk &#123;pattern&#125; &#123;action&#125; filename</code> <ol><li>pattern, action 둘 중 한 값만 있으면 됨</li></ol></li></ol><h2 id="AWK-사용예제"><a href="#AWK-사용예제" class="headerlink" title="AWK 사용예제"></a>AWK 사용예제</h2><h3 id="1-Column-data-추출"><a href="#1-Column-data-추출" class="headerlink" title="1. Column data 추출"></a>1. Column data 추출</h3><ul><li>각 Column 은 $1 와 같은 형태로 필드에 접근하여 추출 할 수 있습니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># awk &#123;action&#125; filename 형식</span></span><br><span class="line">awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> ./file_you_want.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># $0 전체 column 추출</span></span><br><span class="line">awk <span class="string">&#x27;&#123;print $0&#125;&#x27;</span> ./file_you_want.log</span><br></pre></td></tr></table></figure><h3 id="2-특정-Pattern-정규표현식"><a href="#2-특정-Pattern-정규표현식" class="headerlink" title="2. 특정 Pattern : 정규표현식"></a>2. 특정 Pattern : 정규표현식</h3><ul><li>문자열 중에 <code>ADID</code> 라는 글씨가 포함된 레코드를 출력해주는 커맨드입니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;/ADID/&#x27;</span> ./platform.log </span><br></pre></td></tr></table></figure><p>→ 출력 예시 : 20211207    ADID1234556    123$456    device3    window</p><ul><li>AWK pattern에는 정규표현식을 사용할 수 있습니다.<ul><li>pattern내에 정규표현식 구분은 <code>/regular expression/</code> (슬래쉬)로 이루어집니다.</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ awk <span class="string">&#x27;/[A-Z][a-z]+/&#x27;</span> ./system.log</span><br></pre></td></tr></table></figure><h3 id="3-AWK-Command-if구문"><a href="#3-AWK-Command-if구문" class="headerlink" title="3. AWK Command : if구문"></a>3. AWK Command : if구문</h3><ul><li>특정 조건에 맞는 구문을 뽑을 때, 다음과 같이 사용할 수 있습니다.</li><li>다음은 3번 필드의 값이 1과 같을 때 전체 레코드를 뽑는 커맨드 입니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;if ($3 == 1) print ($0)&#125;&#x27;</span> ./system.log</span><br></pre></td></tr></table></figure><p>→ 출력 예시 : </p><p>20211207    ADID123456    1    device3    window</p><p>20211207    ADID123654    1    device2    android</p><p>20211207    ADID654321    1    device1    ios</p><ul><li>다음은 1번 필드가 20211206과 같고 3번 필드가 2이상인 전체 레코드를 뽑는 커맨드입니다.<ul><li>이처럼, if 구문 안에 다양한 조건들과 <code>&amp;&amp;</code>(and) <code>||</code>(or), <code>!</code>(not) 을 활용할 수 있습니다.</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;if ($1 == 20211206 &amp;&amp; $3 &gt;= 2) print($0)&#125;&#x27;</span> ./system.log</span><br></pre></td></tr></table></figure><p>→ 출력 예시 :</p><p>20211206    ADID123456    2    device2    window</p><p>20211206    ADID654321    3    device3    ios</p><p>20211206    ADID432561    4    device2    android</p><ul><li><code>?</code> , <code>:</code>  의 기능 : if-else 구문<ul><li>if 구문 → $1 else $2 라는 뜻입니다.</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ awk <span class="string">&#x27;&#123;조건 ? $1 : $2&#125;&#x27;</span> ./system.log</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-AWK-Command-for-구문"><a href="#4-AWK-Command-for-구문" class="headerlink" title="4. AWK Command : for 구문"></a>4. AWK Command : for 구문</h3><ul><li>AWK 구문에서도 필요시 다음과 같이 for문을 사용할 수 있습니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">for (i=0;i&lt;2;i++)</span></span><br><span class="line"><span class="string">print()</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="5-AWK-BEGIN-END"><a href="#5-AWK-BEGIN-END" class="headerlink" title="5. AWK BEGIN, END"></a>5. AWK BEGIN, END</h3><ul><li>BEGIN과 END는 AWK 구문이 시작되기 전, 마친 후에 수행되는 커맨드입니다.</li><li>다음 커맨드는 <code>&#123;count++&#125;</code> 가 수행되기 전과 후에 Start, End 를 알리고, Count 를 세는 커맨드 입니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;</span></span><br><span class="line"><span class="string">BEGIN &#123;</span></span><br><span class="line"><span class="string">print(&quot;Begin Processing...&quot;)</span></span><br><span class="line"><span class="string">count = 0</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">count++</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">END &#123;</span></span><br><span class="line"><span class="string">print(&quot;COUNT: &quot; count)</span></span><br><span class="line"><span class="string">print(&quot;End Processing&quot;)</span></span><br><span class="line"><span class="string">&#125;&#x27;</span> ./system.log</span><br><span class="line"><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="AWK-정의-변수"><a href="#AWK-정의-변수" class="headerlink" title="AWK 정의 변수"></a>AWK 정의 변수</h2><ul><li>AWK 에서는 사용자의 편의를 위해 자체적으로 정의된 변수가 몇가지 있습니다. 미리 정의된 변수를 AWK command 안에서 다양하게 활용할 수 있습니다. 다음은 AWK에서 정의된 변수들중 많이 사용되는 몇가지를 추려보았습니다.</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">  ARGV        : command line argument 배열</span><br><span class="line">ARGC        : ARGV 배열 요소의 갯수</span><br><span class="line">  CONVFMT     : 포맷팅 형식 (example: 숫자 포맷팅 형식)</span><br><span class="line">  ENVIRON     : 환경변수 배열</span><br><span class="line">  FILENAME    : 파일 이름 (경로포함)</span><br><span class="line">  FS          : 필드 구분자 (default: space)</span><br><span class="line">  NF          : 필드의 갯수</span><br><span class="line">  NR          : 현재 레코드의 순서</span><br><span class="line">  OFMT        : 문자열 출력 형식</span><br><span class="line">  OFS         : 필드 구분자 (default: space)</span><br><span class="line">  ORS         : 레코드 구분자 (default: newline)</span><br><span class="line">  RLENGTH     : match 함수에 의해 매칭된 문자열의 길이</span><br><span class="line">  RS          : 레코드 구분 문자 (default: newline)</span><br></pre></td></tr></table></figure><h2 id="쉘파이프-안에서의-AWK"><a href="#쉘파이프-안에서의-AWK" class="headerlink" title="쉘파이프 안에서의 AWK"></a>쉘파이프 안에서의 AWK</h2><ul><li>위의 사용예제들처럼 Linux CLI 환경에서 AWK command의 강력함은 확인 할 수 있었습니다. 이 외에도 쉘스크립트, 쉘파이프 안에서 AWK 를 활용하고, argument 를 전달하는지는 다음의 예제에서 확인 할 수 있습니다.</li><li>AWK command 에서 argument를 넘겨 줄 때는 <strong>-v</strong> 옵션을 사용하여 넘겨 줄 수 있습니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_variable=<span class="string">&quot;hello&quot;</span></span><br><span class="line">$ <span class="built_in">echo</span> | awk -v output=<span class="variable">$test_variable</span> <span class="string">&#x27;&#123; print &quot;TEST VARIABLE : &quot; output&#125;&#x27;</span></span><br><span class="line">TEST VARIABLE : hello</span><br></pre></td></tr></table></figure><p><img src="/2021/12/07/AWK-basics/Untitled.png" alt="Untitled"></p><ul><li>AWK command 를 상세하게 알고 싶다면, 그 동작 원리와 구조 또한 살펴볼게 많이 있습니다. 각자의 활용 정도에 따라 더욱 필요한 요소를 아래 reference 등의 자료를 통해 공부할 수 있을 것입니다.</li><li>이번 기회를 통해 짧게나마 AWK 를 정리 할 수 있었고, 활용 snippet code 를 남김으로써 다음 재사용시 빠르게 활용할 수 있을 것으로 기대됩니다.</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>AWK 내에 정의된 함수와 변수 등을 자세히 알고 싶다면, 다음 documentation 을 참조하실 수 있습니다.</li></ul><p><a href="https://www.gnu.org/software/gawk/manual/gawk.html">The GNU Awk User’s Guide</a></p><p><a href="https://recipes4dev.tistory.com/171">리눅스 awk 명령어 사용법. (Linux awk command) - 리눅스 파일 텍스트 데이터 검사, 조작, 출력.</a></p>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;AWK 는 데이터를 다루는 사람들이라면 한번씩은 그 Command를 사용해봤을 것입니다.&lt;/li&gt;
&lt;li&gt;저는 과거 Dataframe 을 생성해 본격적인 분석 및 연구.개발 작업이 들어가기 전에, AWK 를 통해 간단한 데이터 처리를 하는 경우, Raw Data 형식을 간단하게 정제하여 Database에 적재하는 경우에 사용해 왔습니다. 이 경우, 많이 사용하는 관용적인 구문외에는 AWK 자체를 살펴볼 기회가 적었습니다.&lt;/li&gt;
&lt;li&gt;최근 사내에서 로그 데이터의 추출을 위해 AWK를 오랜만에 다시 사용하게 되면서, 잊었던 AWK문법을 다시 한 번 살펴보며, 이번 기회에 AWK의 간단 사용예제부터 AWK 문법 몇가지를 정리해보고자 합니다.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Linux" scheme="https://emjayahn.github.io/categories/Development/Linux/"/>
    
    
    <category term="linux" scheme="https://emjayahn.github.io/tags/linux/"/>
    
    <category term="awk" scheme="https://emjayahn.github.io/tags/awk/"/>
    
  </entry>
  
  <entry>
    <title>Docker, 깔끔하고 빠른 분석.연구.개발 환경 세팅</title>
    <link href="https://emjayahn.github.io/2021/11/28/Docker/"/>
    <id>https://emjayahn.github.io/2021/11/28/Docker/</id>
    <published>2021-11-27T15:34:44.000Z</published>
    <updated>2021-11-27T15:38:40.118Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="부제-데이터사이언티스트의-도커-사용기"><a href="#부제-데이터사이언티스트의-도커-사용기" class="headerlink" title="부제 : 데이터사이언티스트의 도커 사용기"></a>부제 : 데이터사이언티스트의 도커 사용기</h3><p><img src="/2021/11/28/Docker/docker-logo.png" alt="docker-logo.png"></p><ul><li>이번 글에서는 저를 포함하여, 도커를 처음 접하는 사람들을 위해 도커(Docker)와 도커 이미지, 도커 컨테이너의 개념에 대해 살펴봅니다.</li><li>간단한 도커파일 작성 예제를 통해, 자신에게 맞는 환경 세팅을 따라 해 볼 수 있습니다.<span id="more"></span></li></ul><hr><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">오픈 소스 A 돌리려면, X, Y, Z 버전의 개발 언어와 라이브러리가 필요하다는데?</span><br><span class="line">오픈 소스 B 돌리려면, X1, Y2, Z3 버전의 라이브러리인데?</span><br><span class="line">왜 내 맥북에서는 잘 도는데, 서버로 옮기면 왜 안돼?</span><br></pre></td></tr></table></figure><p>여러분들은 분석, 연구, 개발 환경 세팅을 어떻게 하시나요? 다양한 방법이 있을 수 있겠고, 무엇보다 자신에게 가장 편한 방법이 제일 좋은 방법일 것 입니다. 본격, 업무 시작 전 책상을 정리하고 키보드와 마우스를 한번씩 털어주는 습관이 있는 저는 제 개인 맥북과 업무 PC, 분석 및 개발서버의 환경을 깔끔(?)(단, 오로지 제 관점에서의 깔끔)하게 하는 취향이고, 세 가지의 다른 OS 환경임에도 불구하고 동일한 환경세팅을 하고 싶었습니다. </p><p>이 니즈를 해결해 줄 도커. 도커내 이미지와 컨테이너의 개념을 살펴보겠습니다.</p><p>❗️Caution❗️</p><p>초보 도커er, 데이터사이언티스트 관점에서의 도커 활용기이기에, 오정보와 더욱 효율적인 방법이 있을 수 있습니다. 댓글을 통한 피드백을 주시면 매우 감사하겠습니다!</p><h2 id="0-도커-이전에-저는"><a href="#0-도커-이전에-저는" class="headerlink" title="0. 도커 이전에 저는."></a>0. 도커 이전에 저는.</h2><p>도입부에서 말씀드렸다시피, 환경의 가상화 및 추상화는 프로젝트 단위로 환경을 관리하고 깔끔(?)한 환경 세팅을 위한 필수요소입니다. 이를 위해 제 개인 맥북과 PC 에서는 <code>Python</code> 을 위한 Pipenv, Virtualenv, Autoenv <code>C, C++</code> 를 위한 Compile 옵션과 Visual Studio의 project 단위 관리를 활용해 깔끔을 떨었습니다. 도커를 통해 이제 System level 까지 환경 추상화를 도전해보려고 합니다.</p><h2 id="1-도커-Docker-란"><a href="#1-도커-Docker-란" class="headerlink" title="1. 도커(Docker)란?"></a>1. 도커(Docker)란?</h2><p><img src="/2021/11/28/Docker/Docker-Website-2018-Diagrams-071918-V5_26_Docker-today.png" alt="Docker-Website-2018-Diagrams-071918-V5_26_Docker-today.png"></p><p>도커를 한마디로 정의하면, <strong>컨테이너</strong> 단위로 우리의 서비스와 환경을 패키징하고, 애자일(Agile)하게 동일한 환경을 제공 할 수 있게 하는 오픈 소스 프레임워크 입니다. 도커 컨테이너의 패키징 기능은 우리가 사용하는 개발 언어, 라이브러리 뿐만 아니라, 코드, 런타임, 시스템 설정, 커널 및 OS 까지 한 가지 혹은 몇 가지의 컨테이너로 패키징 할 수 있게 합니다. 도커를 사용하면, 분석가 및 데이터사이언티스트들은 다음과 같은 이점을 활용할 수 있습니다.</p><ul><li>분석 및 개발 환경을 컨테이너를 통해 추상화하여, 동일한 환경을 제공</li><li>한 서버내에서 여러 인원이 작업을 수행할 때, VM과 같은 기존 가상환경보다 더욱 효율적인 리소스를 활용</li><li>여러 프로젝트를 진행하지만, 각각 다른 환경에서 수행되어야 할 때 컨테이너 단위로 각 환경을 관리</li><li>개발 환경과 배포 환경을 동일하고 빠르게 환경 설정</li><li>오픈소스와 라이브러리를 많이 사용하는 분석, 모델링 업무 특성상 OS 마다 다른 설치 방법을 고민할 필요 없음!</li></ul><h2 id="2-도커-컨테이너-Docker-container-란"><a href="#2-도커-컨테이너-Docker-container-란" class="headerlink" title="2. 도커 컨테이너(Docker  container)란?"></a>2. 도커 컨테이너(Docker  container)란?</h2><p><img src="/2021/11/28/Docker/docker-container.png" alt="귀여운 도커 컨테이너"></p><p>귀여운 도커 컨테이너</p><p>도커 컨테이너는 <strong>도커를 이루는 가장 기본 단위</strong>입니다. 위에서도 살펴보았듯이, 우리가 감싸려고 하는 어플리케이션, 개발환경을 패키징하는 추상 객체입니다. 기존 시스템 OS와 독립된 공간에서 모든 프로세스가 진행될 수 있게끔하는 가상화 기술입니다. </p><p>도커 컨테이너가 기존의 Virtual Machine 과 다른 점은 전체 호스트 OS를 가상화하여 활용할 수 있다는 점입니다. Virtual Machine 은 게스트 OS(가상화한 사용자)가 호스트 OS 위에 올라가 동작하여, 시스템 리소스를 제한적으로 사용할 수 밖에 없는 단점이 있는 반면에, 도커의 경우 호스트 OS 전체를 사용하여 (게스트 OS 개념이 없음) 시스템 리소스를 전부 사용 할 수 있습니다.</p><p><img src="/2021/11/28/Docker/container-vm-whatcontainer_2.png" alt="가상환경을 사용했을 때 시스템구조, 이미지 출처 : docker.com"></p><p>가상환경을 사용했을 때 시스템구조, 이미지 출처 : docker.com</p><p><img src="/2021/11/28/Docker/docker-containerized-appliction-blue-border_2.png" alt="도커를 사용했을 때 시스템구조, 이미지 출처 : docker.com"></p><p>도커를 사용했을 때 시스템구조, 이미지 출처 : docker.com</p><h2 id="3-도커-이미지-Docker-Image-란"><a href="#3-도커-이미지-Docker-Image-란" class="headerlink" title="3. 도커 이미지(Docker Image)란?"></a>3. 도커 이미지(Docker Image)란?</h2><p><img src="/Untitled.png" alt="이미지 출처: [https://kimck.tistory.com/entry/Docker-File-Docker-Image를-만들기-위한-명세서](https://kimck.tistory.com/entry/Docker-File-Docker-Image%EB%A5%BC-%EB%A7%8C%EB%93%A4%EA%B8%B0-%EC%9C%84%ED%95%9C-%EB%AA%85%EC%84%B8%EC%84%9C)"></p><p>이미지 출처: <a href="https://kimck.tistory.com/entry/Docker-File-Docker-Image%EB%A5%BC-%EB%A7%8C%EB%93%A4%EA%B8%B0-%EC%9C%84%ED%95%9C-%EB%AA%85%EC%84%B8%EC%84%9C">https://kimck.tistory.com/entry/Docker-File-Docker-Image를-만들기-위한-명세서</a></p><p>도커 이미지는 <strong>도커 컨테이너의 설계도</strong>입니다. 도커 이미지를 통해 컨테이너 내부에 어떤 환경을 포함하여 패키징 할 것인지 계획을 세웁니다. 도커 이미지 생성 방법은 (1) <a href="https://hub.docker.com/">DockerHub</a> 를 활용해 Github처럼 공개된 이미지 소스를 활용하는 방법이 있고, (2) Dockerfile 을 통해 도커 이미지를 빌드하는 방법이 있습니다. 다음 예제에서 간단한 Dockerfile 작성을 통해 이미지를 만들고 Python과 jupyter 환경을 컨테이너화 해보겠습니다.</p><h2 id="4-일단-만들어보자"><a href="#4-일단-만들어보자" class="headerlink" title="4. 일단 만들어보자!"></a>4. 일단 만들어보자!</h2><p>도커를 설치하는 자세한 방법은 이 글에서는 생략하도록 하겠습니다. 다음과 같은 방법으로 쉽게 설치 할 수 있으니, 자신의 환경에 맞게 설치하시고 다음을 진행해주세요!</p><p><code>Linux</code> : yum, apt 등 OS 에 맞는 방법으로 설치해주세요.</p><p><code>Mac</code> : Intel chip과 Apple M1 chip 에 따라 각각 설치해주세요.</p><p><code>Window</code> : Docker Desktop for Windows 를 설치해주세요 (Window os 종류에 맞게 WSL, Hyper-V 기반에 맞는 docker 설치를 진행해 주세요)</p><p>본 실습 예제의 결과물은 Docker 환경에서 (1) Python3.7 , (2) Jupyter Notebook , (3) Numpy, Pandas 라이브러리 설치 (4) 호스트 파일시스템과 도커 파일시스템을 연결 설정까지 이루어지겠습니다.</p><h3 id="4-1-도커-실행"><a href="#4-1-도커-실행" class="headerlink" title="4.1 도커 실행"></a>4.1 도커 실행</h3><ul><li>도커가 정상적으로 설치 되었으면, 도커의 실행 여부를 확인하고 도커를 켜고 끄는 방법을 알아봅니다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 도커 실행 여부 확인</span></span><br><span class="line">$ systemctl status docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 도커 실행</span></span><br><span class="line">$ sudo systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 도커 종료</span></span><br><span class="line">$ sudo systemctl stop docker</span><br></pre></td></tr></table></figure><h3 id="4-2-Dockerfile-작성"><a href="#4-2-Dockerfile-작성" class="headerlink" title="4.2 Dockerfile 작성"></a>4.2 Dockerfile 작성</h3><p>먼저, 다음과 같이 작성하고 현재 실습 디렉토리에 <code>Dockerfile</code> 로 저장해 줍니다.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install --upgrade pip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install jupyter</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install numpy</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install pandas</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> <span class="built_in">tail</span> -f /dev/null</span></span><br></pre></td></tr></table></figure><ul><li><code>FROM</code> : <a href="https://hub.docker.com/">DockerHub</a> 에 공개되어 있는 오픈 이미지를 우리 이미지의  base 로 하는 의미입니다. python3.7 버전의 오픈 이미지를 바탕으로 우리 이미지를 빌드할 것입니다.</li><li><code>RUN</code> : 도커 이미지가 빌드되고, 수행되는 명령절입니다. Python 기반의 분석, 개발환경 세팅을 위하는 것인 만큼 pip를 활용해 해당 패키지를 설치해 줍니다.</li><li><code>EXPOSE</code> : 우리는 jupyter 환경을 설치할 예정이므로, jupyter 가 사용하는 8888 번 포트를 개방해줍니다.</li><li><code>CMD</code> : 컨테이너 내부 shell에서 수행되는 커맨드입니다. 배포 및 운용을 위한 컨테이너라면 CMD python3 ~~~.py 를 해주겠죠. 다만, 우리는 컨테이너를 계속 실행된 상태에서 분석 및 개발을 위한 환경이기 때문에 컨테이너 동작 이후 종료 되지 않아야 합니다. 따라서 &#x2F;dev&#x2F;null page 를 계속 읽어드리는 명령을 통해 환경 유지를 할 수 있습니다.</li></ul><h3 id="4-3-Docker-image-빌드"><a href="#4-3-Docker-image-빌드" class="headerlink" title="4.3 Docker image 빌드"></a>4.3 Docker image 빌드</h3><p>위에서 작성한 Dockerfile을 바탕으로 아래 명령어를 통해 도커 이미지를 빌드해 줍니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># $ docker image builld -t 이미지명:태그명 Dockerfile경로</span></span><br><span class="line">$ docker image build -t python-jupyter:stable .</span><br></pre></td></tr></table></figure><ul><li><code>-t</code> : 생성될 이미지에 태그를 붙여줍니다. 태그를 생략하게 되면, :latest 가 default 로 붙습니다.</li><li>Dockerfile 경로 : docker image build 명령은 default 로 현재 디렉토리의 Dockerfile 을 찾습니다. 파일 디렉토리와 파일명이 다른 도커파일을 지정하고 싶다면, <code>-f</code> 을 통해 경로&#x2F;파일명을 다르게 설정할 수 있습니다.</li></ul><h3 id="4-4-Docker-container-실행"><a href="#4-4-Docker-container-실행" class="headerlink" title="4.4 Docker container 실행"></a>4.4 Docker container 실행</h3><p>Docker image 를 바탕으로 도커 컨테이너를 실행해 줍니다. 도커 컨테이너 실행시 주의할 점이 몇가지 있습니다. 먼저 도커는 안정적인 배포와 운영을 위해 한번 실행된 컨테이너의 설정과 환경을 변경하기 쉽지 않습니다. 아니, 설정과 환경을 변경할 수 없습니다. (시도하지 마세요. 저처럼 너무나 고생하게 됩니다.) 따라서 컨테이너를 실행 할 때, 고려하는 요소를 모두 포함하여 실행시켜주는 것이 중요합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># $ docker run (각 종 옵션) DockerImage명</span></span><br><span class="line">$ docker run -d --name python-jupyter-stable -p 8888:8888 -v \</span><br><span class="line">/home/user-name/workspace:/home/user-name/workspace python-jupyter:stable </span><br></pre></td></tr></table></figure><ul><li><code>-d</code> : Docker container 실행을 백그라운드에서 실행하는 옵션입니다. 도커는 안정적인 운영을 위해 foreground 실행을 하게 되면 커맨드lock 이 걸리게 됩니다.</li><li><code>—-name</code> : 실행되는 컨테이너의 이름 설정</li><li><code>-p</code> : 호스트 서버의 포트와 컨테이너 포트 연결. 우리는 jupyter notebook 이 사용할 8888번 포트를 서로 연결해 줍니다.</li><li><code>-v</code> : 이 옵션을 통해 컨테이너 내부에서 저장되는 파일시스템과 호스트 서버의 파일시스템을 연결해 줍니다. 호스트 파일시스템을 컨테이너에 마운트 시킨다는 개념으로 생각합니다. <code>호스트서버파일시스템:컨테이너내부파일시스템</code></li><li>python-jupyter:stable : 위에서 생성한 이미지명:태그</li></ul><h3 id="4-5-Docker-container-shell-접속"><a href="#4-5-Docker-container-shell-접속" class="headerlink" title="4.5 Docker container shell 접속"></a>4.5 Docker container shell 접속</h3><p>Docker container 가 정상적으로 만들어졌다면, container 내부로 들어가 jupyter notebook  을 실행해 주어야 합니다. container 내부 shell 에 접속하는 방법은 다음과 같습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it python-jupyter-stable bash</span><br></pre></td></tr></table></figure><p>위 커맨드를 이용해 컨테이너 내부에 접속해, jupyter notebook 을 실행해부면 됩니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook --allow-root &amp; <span class="comment">#background에서 jupyter notebook 실행</span></span><br></pre></td></tr></table></figure><h3 id="5-마치며"><a href="#5-마치며" class="headerlink" title="5. 마치며"></a>5. 마치며</h3><p>간단한 실습 예제를 통해 다양한 OS 환경에서도 동일한 분석 및 개발 환경 세팅에 대해 알아보았습니다. 위에서 작성한 Dockerfile 만 있다면, 제가 어느 환경에서 작업하더라도 docker image build, docker run 을 통해 안정적인 분석과 연구 개발을 진행 할 수 있습니다. 본 글을 통해, 도커의 필요성과 도커의 개념을 이해하고, 도커를 처음 접하는 분들에게 본격적인 도커의 소개가 되었으면 하는 바램입니다. 저 역시, 앞으로 도커를 이용해 더욱 Agile하고 고급 환경구축을 시도해 볼 것이며, 새롭게 알게 되는 내용들은 알기쉽게 정리하여 본 블로그와 PAP 커뮤니티를 통해 소개해드릴 예정입니다.</p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;부제-데이터사이언티스트의-도커-사용기&quot;&gt;&lt;a href=&quot;#부제-데이터사이언티스트의-도커-사용기&quot; class=&quot;headerlink&quot; title=&quot;부제 : 데이터사이언티스트의 도커 사용기&quot;&gt;&lt;/a&gt;부제 : 데이터사이언티스트의 도커 사용기&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2021/11/28/Docker/docker-logo.png&quot; alt=&quot;docker-logo.png&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이번 글에서는 저를 포함하여, 도커를 처음 접하는 사람들을 위해 도커(Docker)와 도커 이미지, 도커 컨테이너의 개념에 대해 살펴봅니다.&lt;/li&gt;
&lt;li&gt;간단한 도커파일 작성 예제를 통해, 자신에게 맞는 환경 세팅을 따라 해 볼 수 있습니다.</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Docker" scheme="https://emjayahn.github.io/categories/Development/Docker/"/>
    
    
    <category term="Docker" scheme="https://emjayahn.github.io/tags/Docker/"/>
    
    <category term="도커" scheme="https://emjayahn.github.io/tags/%EB%8F%84%EC%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>[C++] 2.연산자(Operators)</title>
    <link href="https://emjayahn.github.io/2021/10/14/C-%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%89%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%A1-Operators/"/>
    <id>https://emjayahn.github.io/2021/10/14/C-%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%89%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%A1-Operators/</id>
    <published>2021-10-14T09:51:33.000Z</published>
    <updated>2021-10-14T11:16:22.540Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. </p><p>모든 연산자에 대한 리뷰보다는 조금 까다롭거나, 쉽게 잊을 수 있는 연산자 등을 위주로 정리하려고 합니다.</p><span id="more"></span><h3 id="산술연산자-x2F-x3D"><a href="#산술연산자-x2F-x3D" class="headerlink" title="산술연산자(+, -, *, &#x2F;, %, +&#x3D;)"></a>산술연산자(+, -, *, &#x2F;, %, +&#x3D;)</h3><p>&#x2F; : 나누기,</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 이 때, 정수와 정수간의 연산은 result 에는 2가 저장됨</span></span><br><span class="line"><span class="type">int</span> result = <span class="number">7</span> / <span class="number">3</span>;</span><br><span class="line"><span class="comment">// 이 때, 나머지는 모듈러스 연산자로 계산</span></span><br><span class="line"><span class="type">int</span> remain = <span class="number">7</span> % <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 이 경우는, 에러는 발생시키지 않으나 warning sign 을 확인할 수 있음.</span></span><br><span class="line"><span class="comment">// int type의 result에 float 혹은 double 형태의 연산값을 저장하기에 warning sign 발생</span></span><br><span class="line"><span class="type">int</span> result = <span class="number">7.0</span> / <span class="number">3.0</span>;</span><br><span class="line"><span class="comment">// 이를 막기위해 작성자의 의도를 담아 TypeCasting 을 해주는 것을 추천</span></span><br><span class="line"><span class="type">int</span> result = (<span class="type">int</span>)(<span class="number">7.0</span> / <span class="number">3.0</span>);</span><br></pre></td></tr></table></figure><p>% : Modulus 나머지 연산자, Modulus는 argument 가 모두 정수여야 계산 가능. 실수간의 Modulus계산은 에러</p><p>+&#x3D; : a +&#x3D; 10 → a &#x3D; a + 10</p><h3 id="증감연산자-—"><a href="#증감연산자-—" class="headerlink" title="증감연산자(++, —)"></a>증감연산자(++, —)</h3><p>증감연산자는 정수의 경우 1을 더하거나 빼는 경우이지만, 포인터에서는 메모리 단위로 증가하는 것.</p><p>즉, 증감연산자는 unit 단위로 증가 또는 감소 하는 연산</p><p>++ : a++ → a &#x3D; a + 1, ++a → a &#x3D; a + 1</p><p>— : a— → a &#x3D; a - 1, —a → a &#x3D; a-1</p><p>앞에 붙는 경우(전치)와 뒤에 붙는 경우(후치)는 연산의 우선순위가 변화. 후위는 우선순위가 가장 마지막, 전위는 우선순위가 먼저 수행.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> result = <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> a = <span class="number">0</span>;</span><br><span class="line">a = result++; <span class="comment">// a=10, result=11</span></span><br><span class="line"></span><br><span class="line">result = <span class="number">10</span>;</span><br><span class="line">a = <span class="number">0</span>;</span><br><span class="line">a = ++result; <span class="comment">// a=11, result=11</span></span><br></pre></td></tr></table></figure><h3 id="논리연산자-Booleans-not-amp-amp-and-or"><a href="#논리연산자-Booleans-not-amp-amp-and-or" class="headerlink" title="논리연산자(Booleans), !(not), &amp;&amp;(and), ||(or)"></a>논리연산자(Booleans), !(not), &amp;&amp;(and), ||(or)</h3><p>true: 0이 아닌 모든 값, 일반적으로 1</p><p>false: 0</p><p>boolean 자료형: <code>bool</code> (true, false)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> istrue = <span class="literal">true</span>; <span class="comment">// isture -&gt; true</span></span><br><span class="line"><span class="type">int</span> istrue_integer = <span class="literal">true</span>; <span class="comment">//istrue_integer -&gt; 1</span></span><br></pre></td></tr></table></figure><h3 id="비교연산자-x3D-x3D-≠-lt-gt-≤-≥"><a href="#비교연산자-x3D-x3D-≠-lt-gt-≤-≥" class="headerlink" title="비교연산자(&#x3D;&#x3D;, ≠, &lt;,&gt;, ≤,≥)"></a>비교연산자(&#x3D;&#x3D;, ≠, &lt;,&gt;, ≤,≥)</h3><p>&#x3D;&#x3D; : equal</p><p>! &#x3D;: not equal</p><h3 id="삼항연산자"><a href="#삼항연산자" class="headerlink" title="삼항연산자"></a>삼항연산자</h3><p>간단한 if-else 문의 한줄 표현</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">a == <span class="number">10</span> ? a = <span class="literal">true</span> : a = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//위 결과를 if else 문으로 표현하면 다음과 같다.</span></span><br><span class="line"><span class="keyword">if</span> (a == <span class="number">10</span>)&#123;</span><br><span class="line">a=<span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">a=<span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. &lt;/p&gt;
&lt;p&gt;모든 연산자에 대한 리뷰보다는 조금 까다롭거나, 쉽게 잊을 수 있는 연산자 등을 위주로 정리하려고 합니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="C++" scheme="https://emjayahn.github.io/categories/Development/C/"/>
    
    
    <category term="Language" scheme="https://emjayahn.github.io/tags/Language/"/>
    
    <category term="C++" scheme="https://emjayahn.github.io/tags/C/"/>
    
    <category term="C" scheme="https://emjayahn.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>[C++] 1.자료형(DataTypes)</title>
    <link href="https://emjayahn.github.io/2021/10/13/C-%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD%E1%84%92%E1%85%A7%E1%86%BC-DataTypes/"/>
    <id>https://emjayahn.github.io/2021/10/13/C-%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD%E1%84%92%E1%85%A7%E1%86%BC-DataTypes/</id>
    <published>2021-10-13T12:35:26.000Z</published>
    <updated>2021-10-13T12:49:11.237Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. </p><span id="more"></span><h2 id="1-C-의-주석"><a href="#1-C-의-주석" class="headerlink" title="1. C++ 의 주석"></a>1. C++ 의 주석</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 주석</span></span><br></pre></td></tr></table></figure><h2 id="2-C-의-자료형-DataType"><a href="#2-C-의-자료형-DataType" class="headerlink" title="2. C++ 의 자료형, DataType"></a>2. C++ 의 자료형, DataType</h2><h3 id="자료형s"><a href="#자료형s" class="headerlink" title="자료형s"></a>자료형s</h3><p>정수형 : <code>char</code> 1byte, <code>short</code> 2byte, <code>int</code> 4byte, <code>long</code> 4byte, <code>long long</code> 8byte 등</p><p>실수형 : <code>float</code> 4byte, <code>double</code> 8byte 등</p><p>평소엔 : <code>signed int</code>, signed 는 생략 (-128 ~ 127)</p><ul><li>MSB 0 000 0000 (2) : MSB - Most Significant Bit for sign</li></ul><p>양의 값만 할당 : <code>unsigned int</code> (0 ~ 255)</p><p>unsigned 값에 256 을 할당하면? bit: 1111 1111 (2) + 1 (2) &#x3D; 1 0000 0000 → 0으로 생각 (overflow)</p><p>unsigned 값에 -1 을 할당하면? bit: 1111 1111 (2) &#x3D; 255 (10) (-1의 정의는 1을 더했을 때 0이 되는 값으로 정의하므로 1111 1111로 표현되며(2의보수법), 이는 unsigned의 컴파일 결과 255로 표현된다)</p><h3 id="실수표현방법-부동소수점-방식"><a href="#실수표현방법-부동소수점-방식" class="headerlink" title="실수표현방법: 부동소수점 방식"></a>실수표현방법: 부동소수점 방식</h3><ul><li>부동소수점 방식으로 소수와 실수를 표현하는 것은 글로 정리하는 것이 오히려 혼란을 야기할 수 있으므로, 추후에 필요하다면 손으로 쓴 풀이를 정리해보겠습니다.<ul><li>참고: <a href="https://ko.wikipedia.org/wiki/%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90">부동소수점 위키백과</a></li></ul></li><li>정수와 실수의 메모리 저장 방식은 각가 다른 것이 중요</li><li>따라서 정수와 실수간의 연산 방식은 기존의 연산방식은 다름</li><li><code>float</code> 과 <code>double</code> 을 적절히 활용하여 실수값의 범위에 따라 사용</li></ul><h3 id="TypeCasting-형변환"><a href="#TypeCasting-형변환" class="headerlink" title="TypeCasting(형변환)"></a>TypeCasting(형변환)</h3><p>서로 다른 자료형끼리 연산은 되도록 자제해야하지만, 어쩔수 없이 수행해야만 하는 순간이 있기 마련이다. C++ 에서는 Python과 달리 compiler 에 의존하는 경우가 많기 때문에 TypeCasting 을 의식적으로 해주는 것이 코드 가독성과 예측성을 높이는 방법이다. TypeCasting 을 해주지 않아도, 실제로는 compiler 가 강제적으로 형변환하여 연산하지만, 이는 의도와 다른 결과를 만들어내 실수할 수 있는 여지를 많이 남기는 것이다. 습관처럼 예상하고 필요시 꼭 casting 하도록 하자.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> int_number = <span class="number">5</span></span><br><span class="line"><span class="type">float</span> floating_number = <span class="number">3.0</span></span><br><span class="line"><span class="comment">//Type Casting</span></span><br><span class="line"><span class="type">float</span> result = floating_number + (<span class="type">float</span>)int_number</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;C와 C++이 필요해, 제 머릿속 메모리의 Recall 이 필요했습니다. 요즘엔 주로 Python을 사용하다보니, C, C++ 의 기초문법과 CodeStyle을 다시 떠올려야합니다. 학생 때 열심히 공부했으나 방구석 한켠에 먼지 쌓인 열혈강의 C, C++책과 인터넷자료, 유튜브를 통해 Remind하고 공부하는 내용을 요약 정리하려고 합니다. 본 글에서는 C에 대한 내용보다 C++ 내용이 주를 이룰 예정입니다. &lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="C++" scheme="https://emjayahn.github.io/categories/Development/C/"/>
    
    
    <category term="Language" scheme="https://emjayahn.github.io/tags/Language/"/>
    
    <category term="C++" scheme="https://emjayahn.github.io/tags/C/"/>
    
    <category term="C" scheme="https://emjayahn.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>[세미나요약] 데이터 분석, 의심에서 전달까지</title>
    <link href="https://emjayahn.github.io/2021/10/10/summary-seminar-EDA/"/>
    <id>https://emjayahn.github.io/2021/10/10/summary-seminar-EDA/</id>
    <published>2021-10-10T03:45:08.000Z</published>
    <updated>2021-10-13T12:52:20.709Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>2021년 10월 8일, 한국에너지기술연구원 이제현 박사님이 진행하신 ‘데이터 분석, 의심에서 전달까지’ 제목으로 진행된 세미나를 참석했습니다. 본 글은 세미나 내용의 요약입니다.</p><span id="more"></span><p>[세미나 발표 PDF 자료]<br><a href="http://www.bigdata-map.kr/board/open">세미나 발표 pdf 자료</a></p><h2 id="1-데이터-의심하기"><a href="#1-데이터-의심하기" class="headerlink" title="1. 데이터 의심하기"></a>1. 데이터 의심하기</h2><h3 id="1-1-레퍼런스의-중요성"><a href="#1-1-레퍼런스의-중요성" class="headerlink" title="1-1. 레퍼런스의 중요성"></a>1-1. 레퍼런스의 중요성</h3><ul><li>분석결과의 신뢰도, 결과의 책임을 위해 데이터의 출처가 명확해야한다. 출처가 분명하지 않은 데이터는 사용하지 않는 것이 최선</li></ul><h3 id="1-2-데이터의-건정성"><a href="#1-2-데이터의-건정성" class="headerlink" title="1-2. 데이터의 건정성"></a>1-2. 데이터의 건정성</h3><ul><li>데이터 자체의 건정성<ul><li>결측치 : 데이터가 없음 → 데이터가 없는 것도 가끔은 중요한 메시지가 될 수 있다. (예: 이미지 데이터 내의 까만 이미지 → 빛이 없다고 해석 가능) 결측치에 대한 해석은 결국, 데이터의 도메인 관점에서 생각</li><li>중복데이터 : 같은 데이터가 여러개 → Key feature 를 중심으로 논리적으로 판단해야한다. 중복데이터에 대해 일괄적인 처리 이전에 고민해보아야 할 문제 (예: 같은 자리에 건물이 겹쳐 있음 : 비정상적인 데이터, 같은 시간 같은 가게에 손님이 두명 : 정상적인 데이터)</li><li>이상치 : (사전적의미) 정상적인 범위에서 벗어나는 데이터 → 통계 분석을 통해 이상치 후보군을 추리고, 도메인 접근을 통해 진짜 이상치인지 판별해야한다. (예: 대학 중퇴자가 왜 소득이 높지? → 빌게이츠, 스티브잡스, 마크 저커버그, 잭도시 등) 이상치로 볼수 있는 데이터가 있다 하더라도, 내가 하는 분석의 목적에 따라서 데이터가 이상치 일수도, 아닐수도 있다. 기계적인 처리는 하면 안됨</li></ul></li></ul><h3 id="1-3-너무-믿지-말아야할-데이터"><a href="#1-3-너무-믿지-말아야할-데이터" class="headerlink" title="1-3. 너무 믿지 말아야할 데이터"></a>1-3. 너무 믿지 말아야할 데이터</h3><ul><li>너무 믿지 말아야할 데이터 : (예: 영화 장르데이터 → 해리포터 1, 2, 3,4 … 의 장르가 모두 다름. 어떤 절대적 기준에 의해 장르 구분이 된 것이 아니라, 누군가의 주관적 관점으로 새긴 데이터)</li></ul><h3 id="1-4-필요-데이터"><a href="#1-4-필요-데이터" class="headerlink" title="1-4. 필요 데이터"></a>1-4. 필요 데이터</h3><ul><li>본격적인 프로젝트 시행 이전에, 필요한 데이터를 빠르게 계획하고, 살펴본뒤 레퍼런스 체크를 시행해야한다.</li></ul><h3 id="1-5-데이터-파악"><a href="#1-5-데이터-파악" class="headerlink" title="1-5. 데이터 파악"></a>1-5. 데이터 파악</h3><ul><li><p>데이터 파악 : 통계치는 같은데 그림을 그리면 다르게 해석된다. 반드시 데이터는 그려보아야 한다. (예: 데이터 사우르스, 통계가 얼마나 눈을 가리는지 보여주는 예시)</p><p>  <img src="/2021/10/10/summary-seminar-EDA/Untitled.png" alt="데이터 사우르스"></p></li><li><p>데이터를 제대로 의심하는 방법 : Exploratory Data Analysis. 데이터를 받았을 때 이렇게 저렇게 찾아보는 과정. (예: 장님이 코끼리를 만져보는 과정) 한명의 장님(나) 여러 방법으로 그려보고 살펴보면서 데이터를 3d 다양한 관점에서 바라보아야 한다. 데이터에 대해 그림을 그릴 때마다 가설을 세우고, 다음 그림을 그릴 때 내 가설을 보완해나아가야함. 마치 셀프 강화학습 처럼</p><ul><li>결국 EDA + Hypothesis + Graph &#x3D; self-강화학습</li></ul></li></ul><h2 id="2-분석-방법-의심하기"><a href="#2-분석-방법-의심하기" class="headerlink" title="2. 분석 방법 의심하기"></a>2. 분석 방법 의심하기</h2><ul><li>사장님이 감자를 잘라달라<ul><li>감자 썰기의 관건: 무엇을 만들 것인가</li><li>요리의 목적에 따라 다양한 감자 형태, 다양한 조리방식이 있을 수 있다</li></ul></li><li>데이터 분석: 무엇을 할 것인가?<ul><li>데이터 분석의 관건: 무엇을 위한 분석인가</li><li>현황 분석(현황 내용전달), 대안 제시 (설득력: 대안의 장점과 단점), 예측모델개발 (신뢰성: 검증결과, 예상오차) 등 목적에 따라 데이터 뿐만 아니라 그에 따른 다양한 데이터 분석 방법이 필요하다</li></ul></li><li>망치와 모루 전략 (Hammer and Anvil Tactic)<ul><li>모루가 버티는 동안 망치가 때린다 (마케도니아 알렉산더 대왕)<ul><li>모루가 중요하다: 지지않아야하고, 이겨한다 → <strong>수학적 엄밀함</strong> (다양한 통계분석방법, T 검정, 층화 추출, 다양한 매트릭, 정규화, 카이제곱, 교차검증 등) 통계학은 의심의 학문이다 : 내가 전체 데이터를 모두 볼 수 없기 때문에 부분만 보고, 부분이 전체에 적용이 될지 → 이 불안을 해소하기 위한 것이 통계학, 수학</li><li>망치 : 나만의 인사이트 → 아무도 못한 생각을 통해 전쟁에서 이기자<ul><li>인사이트 도출 방법: 데이터 자르기 (Segment)</li><li>Airbnb “국내, 300마일”</li><li>인사이트 도출방법: 독창적 시각화 (Visualization)<ul><li>나이팅게일 → 다쳐서가 아니라 더러워서 사람이 죽는다.</li><li>Hans Rosling, Ted, 2007 → Animated bubble chart : 세상은 점점 나아지고 있다, 경향성을 새롭게 보여줌</li><li>Danny Dorling → Slow Down 가속 성장의 시대는 끝났다.</li><li>송강호 → 배우는 오담을 가져온다. 알고보면 그 오답이 진짜 정답이다.</li><li>데이터를 받으면, 공부한대로, 정해진 루틴대로 분석하고 visualization 을 진행함.. 남들도 그렇게 하고 있다. 세상에 없는 방법?</li><li>남들보다 더 많은 시간과 정성 쏟기 + 스스로 생각하기</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="3-고객에게-잘-전달하기"><a href="#3-고객에게-잘-전달하기" class="headerlink" title="3. 고객에게 잘 전달하기"></a>3. 고객에게 잘 전달하기</h2><ul><li>결과를 보고하는 데이터 분석가의 주의사항<ul><li>내 업무 시간 순이 아니라 상대방 논리에 따라 보고하기</li><li>결론 없이 사실만 나열하면 안됨</li><li>경영 용어가 아닌 통계 용어를 남발하면 안됨</li></ul></li><li>분석을 원하는 사람들의 진짜 원하는 것 찾아내기<ul><li>자신들 조차 원하는게 뭔지 정확히 모른다</li><li>다양한 질문들과 상황을 통해 그들이 원하는 것이 무엇인지 파악</li></ul></li><li>데이터 vs 도메인<ul><li>영문과 교수예시: 우리 영문과는 영어가 모국어처럼 입에 붙어야 비로소 국문과랑 같은 출발선에 서는거다.</li><li>초벌 데이터 분석으로 알아내는 것 &#x3D; 도메인에서는 모두 알고 있는 것</li><li>데이터를 분석해서 실무자에게 공유해야 하는 내용 + 흥미를 보이는 지점, 애매하게 파악하고 있는 부분 캐치 + 심층 분석</li></ul></li></ul><h2 id="4-끊임없는-의심"><a href="#4-끊임없는-의심" class="headerlink" title="4. 끊임없는 의심"></a>4. 끊임없는 의심</h2><ul><li>내 분석결과를 살표본다 : Insight</li><li>내 아이디어를 빠르게 적용 : Agile, 코딩잘하기</li><li>호기심 : 흥미요소</li></ul><h2 id="5-경계하는-자세"><a href="#5-경계하는-자세" class="headerlink" title="5. 경계하는 자세"></a>5. 경계하는 자세</h2><ul><li>생명에 대한 예의<ul><li>국가별 코로나 19 사망자 데이터 분석</li><li>안좋은 소식에 대한 분석결과는 tone &amp; manner 를 지켜서..</li></ul></li><li>데이터 밖의 세계<ul><li>컴퓨터, 데이터 속에서만 사는가? vs 어차피, 결국 숫자일 뿐이야?</li></ul></li><li>식사를 마친 손님 : 얼마나 좋은 재료, 어떤 기법을 사용한 요리?  X → 음식이 제때 나오고, 맛있게 배부른 곳 → 음식을 어떻게 만들었는지는 그 다음 문제</li><li>데이터 분석 : 원래 목적을 잘 파악해서 다가가는게 중요 → 어떤 분석방법, 시각화는 나중, 남들이 잘 하지 않는 시도를 많이 해보기</li></ul><p><a href="http://www.bigdata-map.kr/board/open">세미나 발표 pdf 자료</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;2021년 10월 8일, 한국에너지기술연구원 이제현 박사님이 진행하신 ‘데이터 분석, 의심에서 전달까지’ 제목으로 진행된 세미나를 참석했습니다. 본 글은 세미나 내용의 요약입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="DataScience" scheme="https://emjayahn.github.io/categories/DataScience/"/>
    
    <category term="Seminar" scheme="https://emjayahn.github.io/categories/DataScience/Seminar/"/>
    
    
    <category term="DataAnalysis" scheme="https://emjayahn.github.io/tags/DataAnalysis/"/>
    
    <category term="DataScience" scheme="https://emjayahn.github.io/tags/DataScience/"/>
    
    <category term="Seminar" scheme="https://emjayahn.github.io/tags/Seminar/"/>
    
    <category term="Data" scheme="https://emjayahn.github.io/tags/Data/"/>
    
  </entry>
  
  <entry>
    <title>[Metrics] PSNR &amp; SSIM</title>
    <link href="https://emjayahn.github.io/2019/09/01/psnr-ssim/"/>
    <id>https://emjayahn.github.io/2019/09/01/psnr-ssim/</id>
    <published>2019-09-01T05:41:22.000Z</published>
    <updated>2019-09-01T05:46:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="PSNR-amp-SSIM"><a href="#PSNR-amp-SSIM" class="headerlink" title="PSNR &amp; SSIM"></a>PSNR &amp; SSIM</h1><p>Image Reconstruction을 수행하는 중, Model Selection 을 위한 비교 metric 중 하나인 PSNR, SSIM 을 정리한 글입니다.</p><span id="more"></span><h2 id="1-PSNR"><a href="#1-PSNR" class="headerlink" title="1. PSNR"></a>1. PSNR</h2><h3 id="1-1-정의-및-특징"><a href="#1-1-정의-및-특징" class="headerlink" title="1-1. 정의 및 특징"></a>1-1. 정의 및 특징</h3><p>Peak Signal-to-Noise Ratio</p><p> 영상 정보, 화질을 평가할 때 사용되는 Metric. 현재 나는 Image Reconstruction Task 를 수행하며, 다양한 모델의 비교를 위해 사용하기 위해 공부하는 내용이다.</p><p>품질이 좋은 이미지는 큰 PSNR 값을 가지며, 품질이 좋지 않은 이미지는 작은 PSNR 값을 가지게 된다. </p><ul><li>Peak Signal-to-Noise Ratio</li></ul><p>$$PSNR &#x3D; 10log_{10}(\frac{MAX_I^2}{MSE})&#x3D;20log_{10}(\frac{MAX_I}{\sqrt{MSE}}))&#x3D;20log_{10}(MAX_I)-10log_{10}(MSE)$$</p><ul><li><p>MAXI 는 해당 영상의 최댓값, 해당 채널의 최댓값에서 최솟값을 빼서 구함</p><ul><li>e.g. 8-bit gray scale 의 경우, 255-0 &#x3D; 255</li></ul></li><li><p>단위: db(log scale)</p></li><li><p>무손실 영상의 경우 MSE 가 0이기 때문에, PSNR 은 정의 되지 않는다.</p><p>  $$MSE &#x3D; \frac{1}{mn}\sum_{i&#x3D;0}^{m-1}\sum_{j&#x3D;0}^{n-1}[I(i,j)-K(i, j)]^2$$</p></li><li><p>I : mxn 사이즈의 grayscale image</p></li><li><p>K: I 에 잡음이 포함된 이미지 (왜곡된 이미지)</p></li></ul><h3 id="1-2-한계"><a href="#1-2-한계" class="headerlink" title="1-2. 한계"></a>1-2. 한계</h3><p>PSNR은 intensity 의 값들을 위 식에 의해 종합하여 평가하는 방식이기 때문에, 실제로 사람이 봤을 때 느끼는 것과 다른 점수를 뱉어낼 때가 있다. 즉, <strong>사람의 지각품질을 제대로 반영하지 못하기 때문에</strong> 이를 보완하기 위해 PSNR-HVS, PSNR-HVS-M, SSIM, VIF 등의 Metric 이 개발되었다.</p><h2 id="2-SSIM"><a href="#2-SSIM" class="headerlink" title="2. SSIM"></a>2. SSIM</h2><h3 id="2-1-정의-및-특징"><a href="#2-1-정의-및-특징" class="headerlink" title="2-1. 정의 및 특징"></a>2-1. 정의 및 특징</h3><p>위 PSNR 의 한계를 극복하기 위해, 개발된 metric 으로써, Structural Similarity 의 줄임말이다. 사람의 지각 능력과 metric 을 일치시키는 목적에 개발되었다. 사람은 영상에서 구조 정보를 반영하여 영상을 바라보게 되는데, 영상이 얼마나 그 구조 정보를 변화시키지 않았는가를 살펴보는 metric 이다.</p><p>즉, 원본이미지(x)와 왜곡이미지(y)의 Luminance(l), Contrast(c), Structure(s)를 비교한다.</p><p>contrast: 이미지의 표준편차값</p><p>structure: (이미지-평균밝기) &#x2F; 표준편차</p><p>$$l(x, y)&#x3D;\frac{2\mu_x \mu_y+c_1}{\mu_x^2+\mu_y^2+c_1}$$</p><p>$$c(x,y)&#x3D;\frac{2\sigma_x\sigma_y+c_2}{\sigma_x^2+\sigma_y^2+c_2}$$</p><p>$$s(x,y)&#x3D;\frac{\sigma_{xy}+c_3}{\sigma_x\sigma_y+c_3}$$</p><p>$$SSIM(x,y)&#x3D;[l(x,y)^{\alpha}c(x,y)^{\beta}s(x,y)^{\gamma}]$$</p><p>$$c_3&#x3D;c_2&#x2F;2$$</p><p>위에 c3 와 c2 의 조건을 추가하면 SSIM 은 다음과 같이 축약된다.<br><img src="/2019/09/01/psnr-ssim/Untitled-fee293f9-69f7-49d5-beba-5c035dc7ab87.png"></p><h2 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h2><ol><li><a href="https://kr.mathworks.com/help/images/ref/ssim.html">https://kr.mathworks.com/help/images/ref/ssim.html</a></li><li><a href="https://bskyvision.com/">https://bskyvision.com/</a></li><li><a href="https://en.wikipedia.org/wiki/Structural_similarity">https://en.wikipedia.org/wiki/Structural_similarity</a></li><li><a href="https://ko.wikipedia.org/wiki/">https://ko.wikipedia.org/wiki/</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;PSNR-amp-SSIM&quot;&gt;&lt;a href=&quot;#PSNR-amp-SSIM&quot; class=&quot;headerlink&quot; title=&quot;PSNR &amp;amp; SSIM&quot;&gt;&lt;/a&gt;PSNR &amp;amp; SSIM&lt;/h1&gt;&lt;p&gt;Image Reconstruction을 수행하는 중, Model Selection 을 위한 비교 metric 중 하나인 PSNR, SSIM 을 정리한 글입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="MachineLearning" scheme="https://emjayahn.github.io/categories/MachineLearning/"/>
    
    <category term="Vision" scheme="https://emjayahn.github.io/categories/MachineLearning/Vision/"/>
    
    
  </entry>
  
  <entry>
    <title>[Book] Summary of Digital Image Processing Chapter 03</title>
    <link href="https://emjayahn.github.io/2019/08/26/DIP-chapter3/"/>
    <id>https://emjayahn.github.io/2019/08/26/DIP-chapter3/</id>
    <published>2019-08-26T12:54:53.000Z</published>
    <updated>2019-08-26T13:17:59.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Chapter-3-Intensity-Transformations-and-Spatial-Filtering"><a href="#Chapter-3-Intensity-Transformations-and-Spatial-Filtering" class="headerlink" title="Chapter 3: Intensity Transformations and Spatial Filtering"></a>Chapter 3: Intensity Transformations and Spatial Filtering</h1><p>Rafael C.Gonzalez and Richard E.Woods. <i>Digital Image Processing</i>. PEARSON 을 다시 한번 읽어보며, 개인적으로 정리한 글입니다.</p><span id="more"></span><h2 id="3-1-Background"><a href="#3-1-Background" class="headerlink" title="3.1 Background"></a>3.1 Background</h2><h3 id="3-1-1-The-Basics-of-Intensity-Transformations-and-Spatial-Filtering"><a href="#3-1-1-The-Basics-of-Intensity-Transformations-and-Spatial-Filtering" class="headerlink" title="3.1.1 The Basics of Intensity Transformations and Spatial Filtering"></a>3.1.1 The Basics of Intensity Transformations and Spatial Filtering</h3><ul><li>모든 spatial domain process 에서 operator  와 input image f(x,y), output image g(x, y) 로 표현된다.</li></ul><p>$$g(x, y) &#x3D; T[f(x, y)]$$</p><h2 id="3-2-Some-Basic-Intensity-Transformation-Functions"><a href="#3-2-Some-Basic-Intensity-Transformation-Functions" class="headerlink" title="3.2 Some Basic Intensity Transformation Functions"></a>3.2 Some Basic Intensity Transformation Functions</h2><h3 id="3-2-1-Image-Negatives"><a href="#3-2-1-Image-Negatives" class="headerlink" title="3.2.1 Image Negatives"></a>3.2.1 Image Negatives</h3><ul><li>Negative transformation</li><li>이미지 반전 효과</li></ul><p>$$s &#x3D; L-1-r$$</p><h3 id="3-2-2-Log-Transormations"><a href="#3-2-2-Log-Transormations" class="headerlink" title="3.2.2 Log Transormations"></a>3.2.2 Log Transormations</h3><p>$$s&#x3D;c*log(1+r)$$</p><ul><li>c : constant, assumed r ≥ 0</li><li>low intensity value of input → wider range of output levels</li></ul><h3 id="3-2-3-Power-Law-Gamma-Transformations"><a href="#3-2-3-Power-Law-Gamma-Transformations" class="headerlink" title="3.2.3 Power-Law(Gamma) Transformations"></a>3.2.3 Power-Law(Gamma) Transformations</h3><p>$$s &#x3D; cr^\gamma&#x3D;c(r+\epsilon)^\gamma$$</p><p>c, gamma: positive constants</p><ul><li>gamma 의 값에 따라서, intensity의 어떤 부분이 강조되는지가 다르다.</li><li>Original Image 와 monitor 에 비추는 이미지간의 차이를 중요하게 다룰 때, gamma correction 을 사용하게 된다.</li><li>일반적인 contrast를 다룰 때 중요하게 사용되기도 한다. MRI 사진 sample 예</li></ul><h3 id="3-2-4-Piecewise-Linear-Transformation-Functions"><a href="#3-2-4-Piecewise-Linear-Transformation-Functions" class="headerlink" title="3.2.4 Piecewise-Linear Transformation Functions"></a>3.2.4 Piecewise-Linear Transformation Functions</h3><h3 id="1-Contrast-stretching"><a href="#1-Contrast-stretching" class="headerlink" title="1. Contrast stretching"></a>1. Contrast stretching</h3><ul><li>Low-contrast image 은 sensing 면에서 떨어질 수 있으므로, intensity range를 연장하여, 큰 범위의 intensity 를 사용할 수 있도록 하는 방법</li><li>(input_intensity, output_intensity)→ (r1, s1) 과 (r2, s2)의 관계를 조절하여 contrast transform 형태를 조절한다. 극단적으로 r1&#x3D;r2, s1&#x3D;0, s2&#x3D;L-1 이면, binary image 를 생성한다.(thresholding function)</li></ul><h3 id="2-Intensity-level-slicing"><a href="#2-Intensity-level-slicing" class="headerlink" title="2. Intensity-level slicing"></a>2. Intensity-level slicing</h3><ul><li>관심있는 영역의 Intensity-level 외에는 모두 0으로 처리하거나, 관심있는 영역은 특정 intensity level 로 두고, 나머지 level 은 그대로 두는 형태등이 있을 수 있다.</li></ul><h3 id="3-Bit-plane-slicing"><a href="#3-Bit-plane-slicing" class="headerlink" title="3. Bit-plane slicing"></a>3. Bit-plane slicing</h3><ul><li>8bit 의 이미지 슬라이드 중, significant order의 bit slide 중 특정 부분을 slicing</li></ul><h2 id="3-3-Histogram-Processing"><a href="#3-3-Histogram-Processing" class="headerlink" title="3.3 Histogram Processing"></a>3.3 Histogram Processing</h2><h3 id="3-3-1-Histogram-Equalization"><a href="#3-3-1-Histogram-Equalization" class="headerlink" title="3.3.1 Histogram Equalization"></a>3.3.1 Histogram Equalization</h3><ul><li>Assume monotonic transformation: one-to-one mapping or many-to-one mapping</li><li>output pdf ps, input pdf pr</li></ul><p>$$p_s(s) &#x3D; p_r(r)|\frac{dr}{ds}|$$</p><ul><li>이 식은?</li></ul><p>$$s&#x3D;T(r)&#x3D;(L-1)\int_{0}^{r}{p_r(w)dw}$$</p><ul><li>histogram equalization, histogram linearization</li></ul><p>$$s_k&#x3D;T(r_k)&#x3D;(L-1)\sum_{j&#x3D;0}^{k}p_r(r_j) &#x3D; \frac{L-1}{MN}\sum_{j&#x3D;0}^{k}{n_j}$$</p><ul><li>output image 의 p_s,  distribution 이 uniform 되게 하는 형태</li><li>결과적으로, 같은 이미지 형태이지만, 밝기와 contrast 가 모두 다르더라도 일정한 historgram 이 되도록 transform 해준다.</li></ul><h3 id="3-3-2-Histogram-Matching-Specifiaction"><a href="#3-3-2-Histogram-Matching-Specifiaction" class="headerlink" title="3.3.2 Histogram Matching(Specifiaction)"></a>3.3.2 Histogram Matching(Specifiaction)</h3><ul><li>Uniform historgram이 항상 좋은 것은 아니다.</li><li>histogram matching, histogram specification : The method used to generate a processed image that has specified histogram</li></ul><p>(1) histogram p_r(r) 을 계산, s_k 를 구하기 위해 histogram equalization transformation 식을 계산</p><p>(2) 원하는 p_z(z) 를 이용하여, function G 를 계산</p><p>(3)(2)에서 계산한 G를 이용해 z_k (k&#x3D;0, 1, 2, …L-1) 까지 계산</p><p>(4) inverse of G 계산</p><p>(5)  r → z trasnformation 계산</p><h3 id="3-3-3-Local-Histogram-Processing"><a href="#3-3-3-Local-Histogram-Processing" class="headerlink" title="3.3.3 Local Histogram Processing"></a>3.3.3 Local Histogram Processing</h3><ul><li>이 전 두가지 histogram processing model 은 global  한 영역에서 진행, 즉 전체 이미지에 대해 intensity distribution 을 확인하고, 이를 이용해 transformation 을 진행 하였다.</li><li>이러한 modeling 스킬을 Local enhancement 에 사용가능</li><li>Local enhancement 는 neighborhood 를 정하고, 중심을 이동해가며, neighborhood 안에서의 histogram equalization 이나 histogram specification transformation 등을 이용할 수 있다.</li><li>계산을 줄이기 위해, nonoverlapping region 을 사용하여 위 방법을 동일하게 사용할 수 있으나, blocky effect 를 발생시킬 수 있음</li><li>blocky effect (p.161)</li></ul><h3 id="3-3-4-Using-Histogram-Statistics-for-Image-Enhancement"><a href="#3-3-4-Using-Histogram-Statistics-for-Image-Enhancement" class="headerlink" title="3.3.4 Using Histogram Statistics for Image Enhancement"></a>3.3.4 Using Histogram Statistics for Image Enhancement</h3><h2 id="3-4-Fundamentals-of-Spatial-Filtering"><a href="#3-4-Fundamentals-of-Spatial-Filtering" class="headerlink" title="3.4 Fundamentals of Spatial Filtering"></a>3.4 Fundamentals of Spatial Filtering</h2><h3 id="3-4-1-The-mechanics-of-Spatial-FIltering"><a href="#3-4-1-The-mechanics-of-Spatial-FIltering" class="headerlink" title="3.4.1 The mechanics of Spatial FIltering"></a>3.4.1 The mechanics of Spatial FIltering</h3><ol><li>Neighborhood (typically a small rectangle) 2. predefined operation</li></ol><h3 id="3-4-2-Spatial-Correlation-and-Convolution"><a href="#3-4-2-Spatial-Correlation-and-Convolution" class="headerlink" title="3.4.2 Spatial Correlation and Convolution"></a>3.4.2 Spatial Correlation and Convolution</h3><ul><li>correlation, convolution: 180 degree 반전</li></ul><h3 id="3-4-3-Vector-Representation-of-Linear-Filttering"><a href="#3-4-3-Vector-Representation-of-Linear-Filttering" class="headerlink" title="3.4.3 Vector Representation of Linear Filttering"></a>3.4.3 Vector Representation of Linear Filttering</h3><p>$$R&#x3D;\sum_{k&#x3D;1}^{9}w_kz_k&#x3D;\boldsymbol{w}^T\boldsymbol{z}$$</p><h3 id="3-4-4-Generating-Spatial-Filter-Masks"><a href="#3-4-4-Generating-Spatial-Filter-Masks" class="headerlink" title="3.4.4 Generating Spatial Filter Masks"></a>3.4.4 Generating Spatial Filter Masks</h3><ul><li>mn mask</li><li>Average value of masked values → image smoothing</li><li>위치에 따른 gaussian filter 예 (standard deviation?(p.173))</li></ul><h2 id="3-5-Smoothing-Spatial-Filters"><a href="#3-5-Smoothing-Spatial-Filters" class="headerlink" title="3.5 Smoothing Spatial Filters"></a>3.5 Smoothing Spatial Filters</h2><ul><li>smoothing for blurring, noise reduction</li><li>blurring : removal of small details from an image prior to object extraction, bridging of small gaps in lines or curves</li><li>noise reduction: blurring by linear or non-linear filtering</li></ul><h3 id="3-5-1-Smoothing-Linear-Filters"><a href="#3-5-1-Smoothing-Linear-Filters" class="headerlink" title="3.5.1 Smoothing Linear Filters"></a>3.5.1 Smoothing Linear Filters</h3><ul><li>averaging filters &#x3D;&#x3D; lowpass filters</li><li>Replace the value of every pixel in an image by the average of the intensity levels in neighborhood defined by the filter mask → reduced “sharp” transitions in intensity</li><li>box filter : all coefficient are euqal in filter</li></ul><h3 id="3-5-2-Order-Statistic-Nonlinear-Filters"><a href="#3-5-2-Order-Statistic-Nonlinear-Filters" class="headerlink" title="3.5.2 Order-Statistic(Nonlinear) Filters"></a>3.5.2 Order-Statistic(Nonlinear) Filters</h3><ul><li>median filter (popular): effective in impulse noise-reduction (salt-pepper noise)</li><li>implement<ol><li>sort values of neighborhood</li><li>determine their median</li><li>assign the value to filtered image</li></ol></li></ul><h2 id="3-6-Sharpening-Spatial-Filters"><a href="#3-6-Sharpening-Spatial-Filters" class="headerlink" title="3.6 Sharpening Spatial Filters"></a>3.6 Sharpening Spatial Filters</h2><ul><li>highlight transitions</li></ul><h3 id="3-6-1-Foundation"><a href="#3-6-1-Foundation" class="headerlink" title="3.6.1 Foundation"></a>3.6.1 Foundation</h3><h3 id="3-6-2-Using-the-Second-Derivative-for-Image-Sharpeing—The-Laplacian"><a href="#3-6-2-Using-the-Second-Derivative-for-Image-Sharpeing—The-Laplacian" class="headerlink" title="3.6.2 Using the Second Derivative for Image Sharpeing—The Laplacian"></a>3.6.2 Using the Second Derivative for Image Sharpeing—The Laplacian</h3><ul><li>capture intensity discontinuities in an image and deemphasize</li></ul><p>$$g(x, y)&#x3D;f(x, y) + c[\triangledown^2f(x,y)]$$</p><h3 id="3-6-3-Unsharp-Masking-and-Highboost-Filtering"><a href="#3-6-3-Unsharp-Masking-and-Highboost-Filtering" class="headerlink" title="3.6.3 Unsharp Masking and Highboost Filtering"></a>3.6.3 Unsharp Masking and Highboost Filtering</h3><ul><li>unsharp masking<ol><li>Blur the original image</li><li>Subtract the blurred image from the original (the resulting difference is called the mask)</li><li>Add the mask to the original</li></ol></li></ul><p>$$g_{mask}(x,y)&#x3D;f(x,y)-\bar{f}(x,y)$$</p><p>$$g(x,y) &#x3D; f(x, y) + k*g_{mask}(x, y), \quad k&gt;&#x3D;0$$</p><ul><li>k&gt;1 , highboost filtering</li><li>k&lt;1, de-emphasizes unsharp mask</li></ul><h3 id="3-6-4-Using-First-Order-Derivatives-for-Nonlinear-Image-Sharpening—The-gradient"><a href="#3-6-4-Using-First-Order-Derivatives-for-Nonlinear-Image-Sharpening—The-gradient" class="headerlink" title="3.6.4 Using First-Order Derivatives for (Nonlinear) Image Sharpening—The gradient"></a>3.6.4 Using First-Order Derivatives for (Nonlinear) Image Sharpening—The gradient</h3><ul><li>Using the magnitude of the gradient, magnitude M(x, y)</li></ul><p>$$M(x, y)&#x3D;mag(\triangledown f)&#x3D;\sqrt{g_x^2+g_y^2}&#x3D;|g_x|+|g_y|$$</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Chapter-3-Intensity-Transformations-and-Spatial-Filtering&quot;&gt;&lt;a href=&quot;#Chapter-3-Intensity-Transformations-and-Spatial-Filtering&quot; class=&quot;headerlink&quot; title=&quot;Chapter 3: Intensity Transformations and Spatial Filtering&quot;&gt;&lt;/a&gt;Chapter 3: Intensity Transformations and Spatial Filtering&lt;/h1&gt;&lt;p&gt;Rafael C.Gonzalez and Richard E.Woods. &lt;i&gt;Digital Image Processing&lt;/i&gt;. PEARSON 을 다시 한번 읽어보며, 개인적으로 정리한 글입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Book" scheme="https://emjayahn.github.io/categories/Book/"/>
    
    <category term="Digital Image Processing" scheme="https://emjayahn.github.io/categories/Book/Digital-Image-Processing/"/>
    
    
  </entry>
  
  <entry>
    <title>[논문읽기] Summary of Vision and Rain</title>
    <link href="https://emjayahn.github.io/2019/08/20/summary-vision-and-rain/"/>
    <id>https://emjayahn.github.io/2019/08/20/summary-vision-and-rain/</id>
    <published>2019-08-20T12:25:00.000Z</published>
    <updated>2019-08-20T12:29:43.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Presentation-for-summary-papers"><a href="#Presentation-for-summary-papers" class="headerlink" title="Presentation for summary papers"></a>Presentation for summary papers</h2><ul><li>Initial Model for removing rain and snow from Image system.</li></ul><span id="more"></span><iframe src="//www.slideshare.net/slideshow/embed_code/key/w9AhGosEGYe6Dc" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/ssuser47e145/summary-of-the-paper-detection-and-removal-of-rain-from-video-vision-and-rain" title="Summary of the paper &#x27;detection and removal of rain from video, vision and rain&#x27;" target="_blank">Summary of the paper &#x27;detection and removal of rain from video, vision and rain&#x27;</a> </strong> from <strong><a href="https://www.slideshare.net/ssuser47e145" target="_blank">ssuser47e145</a></strong> </div>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Presentation-for-summary-papers&quot;&gt;&lt;a href=&quot;#Presentation-for-summary-papers&quot; class=&quot;headerlink&quot; title=&quot;Presentation for summary papers&quot;&gt;&lt;/a&gt;Presentation for summary papers&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Initial Model for removing rain and snow from Image system.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Paper" scheme="https://emjayahn.github.io/categories/Paper/"/>
    
    
  </entry>
  
  <entry>
    <title>[논문읽기] Implementation of Vanilla GAN</title>
    <link href="https://emjayahn.github.io/2019/08/13/Vanilla-GAN/"/>
    <id>https://emjayahn.github.io/2019/08/13/Vanilla-GAN/</id>
    <published>2019-08-13T07:00:13.000Z</published>
    <updated>2019-08-13T07:27:05.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>A pytorch implementation of Vanilla GAN using MNIST digits data<br>(<a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf</a>)</p><p>실험 결과와 코드는 <a href="https://github.com/EmjayAhn/GAN-pytorch">https://github.com/EmjayAhn/GAN-pytorch</a> 에서 확인 할 수 있습니다.</p><span id="more"></span><h2 id="0-목표"><a href="#0-목표" class="headerlink" title="0. 목표"></a>0. 목표</h2><p>GAN 은 최근 인기를 끌고 있는 generative model 중 하나입니다. 다양한 모델이 쏟아져 나오고 있기에, 이 트렌트를 따라가기 위해서, 가장 기본적인 vanilla gan 을 구현하고, 이해하는 것이 목표입니다. 이번 예제에서는 MNIST digit 을 사용하였으나, 이미지 외에도 다양한 데이터를 활용할 수 있습니다.</p><h2 id="1-Model-구조"><a href="#1-Model-구조" class="headerlink" title="1. Model 구조"></a>1. Model 구조</h2><p>GAN 의 아버지 Ian Goodfellow가 제안한 이 모델은 두가지 신경망으로 구성 되어 있습니다. 먼저, 우리가 가지고 있는 데이터와 비슷하게 데이터를 생성하는 것을 학습하는 <strong>Generator</strong> 와 Generator 가 생성한 데이터(fake)와 실제 우리가 가지고 있는 데이터(real)를 fake 인지 real 인지 구분하는 <strong>Discriminator</strong> 를 구분하는 두 신경망으로 구성되어 있습니다. </p><p><img src="/2019/08/13/Vanilla-GAN/Untitled-b4ab047c-a850-427f-8e06-379dce74e281.png"></p><h3 id="1-1-Generator"><a href="#1-1-Generator" class="headerlink" title="1-1. Generator"></a>1-1. Generator</h3><ul><li>Generator 는 Gaussian Random Noise (mean&#x3D;0, std&#x3D;1) 를 입력으로 받아, 이 noise로 부터 data 를 생성해냅니다.</li><li>이번 구현에서 Generator는 다음과 같이 작성하였습니다.</li></ul><p><img src="/2019/08/13/Vanilla-GAN/Untitled-5a191f6c-b437-4eab-89a7-b34692124ac3.png"></p><ul><li>Dense layer 만 사용했으며, gradient vanishing 현상을 막기 위해 activation 을 거친 후, Batch Normalization 을 추가하였습니다.</li></ul><h3 id="1-2-Discriminator"><a href="#1-2-Discriminator" class="headerlink" title="1-2. Discriminator"></a>1-2. Discriminator</h3><ul><li>Discriminator 는 Generator 가 생성해낸 데이터와 기존에 가지고 있는 진짜 데이터를 입력으로 받아, 진짜 데이터를 1, 가짜데이터를 0으로 학습하는 classifier 입니다.</li><li>아래의 Loss Function 을 확인 하겠지만, 진짜 데이터에 대해서는 그 확률 값을 높게 하고, 가짜데이터에서는 그 확률 값을 0에 가깝게 하는 것이 이 모델의 optimize 목표입니다.</li><li>이번 구현에서 Discriminator를 다음과 같이 작성하였습니다.</li></ul><p><img src="/2019/08/13/Vanilla-GAN/Untitled-4de92b80-7e9d-452e-9956-0298c2b493e2.png"></p><h2 id="2-Loss-Function"><a href="#2-Loss-Function" class="headerlink" title="2. Loss Function"></a>2. Loss Function</h2><h3 id="2-1-Loss-Function-의-해석"><a href="#2-1-Loss-Function-의-해석" class="headerlink" title="2-1. Loss Function 의 해석"></a>2-1. Loss Function 의 해석</h3><p>$$\underset{G}{\text{min}}\underset{D}{\text{max}}V(D, G)&#x3D;E_{x<del>p_{data(x)}}[logD(x)]+E_{z</del>p_{z}(z)}[log(1-D(G(z)))]$$</p><p>Vanilla GAN 의 Loss function 은 위와 같습니다. Loss Function 의 구조 자체는 min-max 최적화로써, Discriminator와 Generator 의 loss 함수를 각각 최적화 해 나아가면서 위 식의 균형 향해 다가가는 것입니다.</p><ul><li>먼저, Discriminator에 대한 max 부터 살펴 보면, Real을 입력으로 넣었을 때는, log(D(x))의 기댓값이 최대가 되게 하고, G(z) 즉, 가짜를 가짜라고 할 확률 1-D(G(z))는 최대가 되게끔 학습을 하는 것입니다.</li><li>Generator 에 대한 min 을 살펴보면, G(z) 는 가우시안 랜덤 변수를 받아 생성된 데이터를 D(G(z)), discriminator에 넣었을 때, 1-D(G(z)), 즉 가짜라고 할 확률을 최소화하게끔 학습하는 것입니다. 이는 결국, Discriminator를 속이기 위해 generator의 최적화가 실행된다는 의미입니다.</li></ul><p>이 식에서 중요한 점은, Discriminator 는 학습할 때, Generator 가 생성한 데이터와 진짜 데이터 모두를 보며 학습하지만, Generator 는 그 어디에서도 진짜 데이터가 어떻게 생겼는지는 확인하지 않습니다. 오로지 Discriminator 를 속이기 위해 학습하는 것이지만, 그 결과 우리가 가지고 있는 진짜 데이터와 비슷하게 만들수 있는 모델을 획득하게 될 수 있는 것이라는 점에서 매우 획기적인 모델입니다.</p><h3 id="2-2-실제-구현에서의-변형"><a href="#2-2-실제-구현에서의-변형" class="headerlink" title="2-2. 실제 구현에서의 변형"></a>2-2. 실제 구현에서의 변형</h3><p>Generator 에 대한 loss function 은 log(1-(D(G(z)))를 최소화 하는 것입니다. 하지만, log(1-x) 형태의 식은 x가 0일 때, 그 gradient 가 매우 작아, 학습이 매우 오래 걸리는 문제가 있습니다. 이를 해결하기 위해, log(1-D(G(z)))를 G에 대해 최소화 하는 것은 결국, -log(D(G(z)))를 최소화 하는 것과 같고, 이는 log(D(G(z)))를 최대화 하는 것과 같습니다. 따라서 실제 구현에서의 criterion 은 Discriminator 가 사용하는 criterion(여기선, binary cross enntropy loss)을 동일하게 사용합니다.</p><h2 id="3-학습-및-모델-결과"><a href="#3-학습-및-모델-결과" class="headerlink" title="3. 학습 및 모델 결과"></a>3. 학습 및 모델 결과</h2><p>학습 parameter 는 다음과 같습니다.</p><ul><li>Total epoch: 300</li><li>batch size : 128</li><li>z dimension : 100</li><li>Adam optimizer : lr&#x3D;0.0002, weight_decay&#x3D;8e-9</li></ul><p>다음은 generator가 학습이 되가면서, 같은 가우시안 랜덤 노이즈에 대해 mnist 와 닮은 데이터를 생성해 나가는 과정입니다.</p><p>(1) 0 epoch</p><p>약 400개의 배치를 학습한 후, 찍은 사진이기에 가운데에 아주 미세한 형태는 보이지만, 가우시안 노이즈임을 확인 할 수 있습니다.</p><p><img src="/2019/08/13/Vanilla-GAN/Untitled-adec04da-b417-40c9-b511-43d380ca6d78.png"></p><p>(2) 20 epoch</p><p>20 epoch 만 되더라도, <del>(마치 뱃속의 아가처럼(?))</del> 가운데에 어떤 형태가 생성되기 시작하는 것을 확인 할 수 있습니다. </p><p><img src="/2019/08/13/Vanilla-GAN/Untitled-0322c576-8ea5-4e73-8268-e2d82fdb4708.png"></p><p>(3) 100 epoch</p><p>9, 3, 8, (horizontal flipped) 3, 1.. 아주 힘들게 MNIST 와 비슷해 보이는 숫자를 확인 할 수 있습니다.</p><p><img src="/2019/08/13/Vanilla-GAN/Untitled-fcb15889-a098-48e5-8cd9-29d26dd0fbf7.png"></p><h2 id="4-결론"><a href="#4-결론" class="headerlink" title="4. 결론"></a>4. 결론</h2><p>이번 구현의 목표는 나의 첫 vanilla gan 을 논문과 여러 자료를 공부해보며, 구현해 보는 것에 있었기에, 이를 완수하고, 실제로 학습 시켰을 때, generator 로써 기능을 할 수 있다는 점에서 유의미 하였습니다. 다양한 repository 에서 서로 다른 framework 를 사용하여, gan 을 구현하는 것을 참조 할 수 있습니다. 하지만, 직접 공부해보고, loss function의 의미를 해석하여 직접 구현해보며 많은 것을 배울 수 있었습니다. 실제로 loss function 위 처럼 바꾸지 않았을 때는 1000 epoch 를 학습하더라도 generator가 학습 되지 않는 실패 경험을 통해, 자세한 논문 리딩과 분석은 구현에 있어 필수적임을 느낄 수 있었습니다.</p><h2 id="5-Futher-Study"><a href="#5-Futher-Study" class="headerlink" title="5.  Futher Study"></a>5.  Futher Study</h2><p>자원의 제약으로 작은 모델 구조와 hyper parameter tuning을 더 하지 못한게 아쉽습니다. generator 가 생성해내는 모양이 조금더 세밀하게 할 수 있는 것을 더 해보고 싶고, MNIST 데이터 뿐만아니라 본 논문의 참조사진처럼 CIFAR10 이나, TFD 데이터에 대해서도 실험해보고 싶습니다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;A pytorch implementation of Vanilla GAN using MNIST digits data&lt;br&gt;(&lt;a href=&quot;https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf&quot;&gt;https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;실험 결과와 코드는 &lt;a href=&quot;https://github.com/EmjayAhn/GAN-pytorch&quot;&gt;https://github.com/EmjayAhn/GAN-pytorch&lt;/a&gt; 에서 확인 할 수 있습니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="https://emjayahn.github.io/categories/Paper/"/>
    
    
    <category term="Gan" scheme="https://emjayahn.github.io/tags/Gan/"/>
    
    <category term="Vanilla Gan" scheme="https://emjayahn.github.io/tags/Vanilla-Gan/"/>
    
    <category term="paper" scheme="https://emjayahn.github.io/tags/paper/"/>
    
    <category term="논문" scheme="https://emjayahn.github.io/tags/%EB%85%BC%EB%AC%B8/"/>
    
  </entry>
  
  <entry>
    <title>[CS224n]Lecture04-BackPropagation</title>
    <link href="https://emjayahn.github.io/2019/08/09/CS224n-Lecture04-Summary/"/>
    <id>https://emjayahn.github.io/2019/08/09/CS224n-Lecture04-Summary/</id>
    <published>2019-08-09T13:26:12.000Z</published>
    <updated>2019-08-09T13:29:25.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Lecture-04-Backpropagation-and-computation-graphs"><a href="#Lecture-04-Backpropagation-and-computation-graphs" class="headerlink" title="Lecture 04: Backpropagation and computation graphs"></a>Lecture 04: Backpropagation and computation graphs</h1><p>Standford University 의 CS224n 강의를 듣고 정리하는 글입니다.</p><span id="more"></span><p>기본적인 computation graph 와 backpropagation 에 관한 내용은 스킵하도록 하겠습니다. 새롭고, 핵심적인 내용만 간추린 내용입니다.</p><h2 id="1-Word-Vector를-Retraining"><a href="#1-Word-Vector를-Retraining" class="headerlink" title="1. Word Vector를 Retraining?"></a>1. Word Vector를 Retraining?</h2><p>Quetion: Retraining 에 대한 판단의 시작 예: TV, telly, television 이 pre-trained word vector 에서는 비슷한  공간에 분포되어있다고 가정할 때, training data 에는 TV 와 telly 단어만 존재하고, test data 에 television이 존재 할 때, word vector 는 어떻게 될 것인가?</p><ul><li>Answer: Training data 에 있는 TV 와 telly 에 해당하는 word vector 는 back prop을 진행하면서, 미세하게 업데이트 되며, 같은 방향으로 이동하게 된다. 반면, television에 해당하는 word vector는 weight parameter 업데이트가 일어나지 않으므로, 처음에는 비슷한 공간에 분포 했으나, TV 와 telly 와 멀어지게 된다.</li></ul><h3 id="1-1-Word-Vector의-Retraining-여부"><a href="#1-1-Word-Vector의-Retraining-여부" class="headerlink" title="1-1. Word Vector의 Retraining 여부"></a>1-1. Word Vector의 Retraining 여부</h3><ul><li>Word Vector가 학습 할 때는 매우 큰 데이터셋을 가지고 학습하게 된다. 따라서 매우 다양한 단어들이 Corpus 로 존재한다.</li><li>Fine tuning?: 우리가 가지고 있는 training dataset 이 매우 작다면, 위에서 든 예에서 직감할 수 있듯이, pre trained vector 를 fine tuning 하게 되면, training set 에 fitting 되는 효과가 있고, 우리가 의도치 않는 weight 의 업데이트가 되거나 혹은 되지 않을 수 있다.</li></ul><h2 id="2-효율적인-gradient-계산"><a href="#2-효율적인-gradient-계산" class="headerlink" title="2. 효율적인 gradient 계산"></a>2. 효율적인 gradient 계산</h2><ul><li>사실 당연하게 여김에도, 우리가 손으로 계산하는 (upstream network * local gradient) 과정을 아래 식에서도 확인 할 수 있듯이, ds&#x2F;dh, dh&#x2F;dz term 은 중복되는 과정이다.</li></ul><p>$$\frac{ds}{dW}&#x3D;\frac{ds}{dh}\frac{dh}{dz}\frac{dz}{dW}$$</p><p>$$\frac{ds}{db}&#x3D;\frac{ds}{dh}\frac{dh}{dz}\frac{dz}{db}$$</p><ul><li>따라서 효율적인 computation을 구현하기 위해서, back propagation에서 upstream network 를 저장하고, 각 parameter 에 대한 local gradient를 구해, 동시에 곱해주어 back prop 을 진행 할 수 있다.</li></ul><h2 id="3-Regularization"><a href="#3-Regularization" class="headerlink" title="3. Regularization"></a>3. Regularization</h2><p>우리가 parameter 가 많아지면 많아질 수록, training error 와  test error 는 낮아지기 마련이다. 하지만, 어느 수준을 넘어가게 되면, training set 에 대해서는 매우 정확해지는 반면, test data(validate data)에 대해서는 generalization에서 실패한 그래프나 수치들을 확인할 수 있다. 따라서, 우리는 반드시 우리가 최적화 하려고 하는 Loss 에 대해 Regularization 을 해주어야만 한다.</p><p><img src="/2019/08/09/CS224n-Lecture04-Summary/Untitled-0b756cac-8f09-434f-8310-8014237e4df0.png"></p><p>다음은 L2 Regularization term 이 추가된 loss function 이다. 지겹도록 바왔음에도, 꼭 식을 보면 해석해야겠기에, Model parameter (weight) theta 가 제곱term 으로 너무 커지는 것을 방지하기 위해 lambda 에 비례하여 penalty term 을 추가한다.</p><p><img src="/2019/08/09/CS224n-Lecture04-Summary/Untitled-8dbb0e2b-833b-4f99-ac77-ff0ad096d113.png"></p><h2 id="4-Vectorization"><a href="#4-Vectorization" class="headerlink" title="4. Vectorization"></a>4. Vectorization</h2><p>우리가 forward&#x2F;backward propagation 을 진행하면서, 각 data의 계산을 looping 하여 계산한다면, 매우 비효율적인 계산 방식이 된다. 우리는 위대한 Vecor&#x2F;Matrix Multiplication 방법으로, 즉, 모든 data 와 weight을 행렬로 만들어 forward&#x2F;backward 계산을 진행해야한다. 또한 이렇게 진행했을 때, 가속화 도구인 GPU 활용의 이점을 사용할 수 있다.</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Lecture-04-Backpropagation-and-computation-graphs&quot;&gt;&lt;a href=&quot;#Lecture-04-Backpropagation-and-computation-graphs&quot; class=&quot;headerlink&quot; title=&quot;Lecture 04: Backpropagation and computation graphs&quot;&gt;&lt;/a&gt;Lecture 04: Backpropagation and computation graphs&lt;/h1&gt;&lt;p&gt;Standford University 의 CS224n 강의를 듣고 정리하는 글입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Lecture" scheme="https://emjayahn.github.io/categories/Lecture/"/>
    
    <category term="CS224n" scheme="https://emjayahn.github.io/categories/Lecture/CS224n/"/>
    
    
    <category term="CS224n" scheme="https://emjayahn.github.io/tags/CS224n/"/>
    
    <category term="summary" scheme="https://emjayahn.github.io/tags/summary/"/>
    
  </entry>
  
  <entry>
    <title>[Linux] 자고있을 때도, 알아서.. 리눅스 Crontab</title>
    <link href="https://emjayahn.github.io/2019/08/06/linux-crontab/"/>
    <id>https://emjayahn.github.io/2019/08/06/linux-crontab/</id>
    <published>2019-08-06T12:15:20.000Z</published>
    <updated>2019-08-06T13:16:20.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>데이터를 모으기 위해 크롤링을 진행하거나, 머신러닝, 딥러닝 실험을 할 때 Linux 환경의 머신에서 정해진 시간과 주기에 맞추어 크롤링을 실행하고, 학습을 해준다면, 수많은 작업들을 미리 설정해둔 내용을 바탕으로 편하게 작업을 자동화 할 수 있습니다. </p><span id="more"></span><h2 id="1-Crontab-스케줄-작성-삭제-목록-확인"><a href="#1-Crontab-스케줄-작성-삭제-목록-확인" class="headerlink" title="1. Crontab 스케줄 작성, 삭제, 목록 확인"></a>1. Crontab 스케줄 작성, 삭제, 목록 확인</h2><p>1-1. Crontab 스케줄 작성하기</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></figure><p>-e (edit) 옵션으로 Crontab 의 스케쥴을 설정해 줄 수 있습니다. 작성할 스케쥴은 리눅스의 디폴트 에디터인 vi 에디터를 이용합니다.</p><p>1-2. Crontab 스케줄 지우기</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -r</span><br></pre></td></tr></table></figure><p>-r (remove) 옵션으로 Crontab 에 등록된 스케줄을 삭제해 줄 수 있습니다.</p><p>1-3. Crontab 스케줄 목록 확인하기</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -l</span><br></pre></td></tr></table></figure><p>-l (list) 옵션으로 Crontab 에 등록된 스케줄 리스트를 확인 할 수 있습니다.</p><h2 id="2-Crontab-주기"><a href="#2-Crontab-주기" class="headerlink" title="2. Crontab 주기"></a>2. Crontab 주기</h2><p>항상 사용할 때마다, 헷갈리고 잊어버리는 설정 주기 순서입니다.</p><p>마지막의 <code>요일</code> 부분은 0, 7: 일요일, 1: 월요일 ~ 6: 토요일</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*   *    *   *   *</span><br><span class="line">분  시간  일   월  요일</span><br></pre></td></tr></table></figure><br>예를 들어, 매주 월요일에 crawling.py 를 실행한다면, 아래와 같이 crontab edit 창에서 작성하고 저장하면 됩니다.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* * * * 5 python3 /directory/crawling.py</span><br></pre></td></tr></table></figure>이제부터는 조금 복잡한 주기를 설정할 수도 있습니다.2-1. 반복- 매시 25분, 45분에 실행하고 싶을 때<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">25,45 * * * * python3 /directory/crawling.py</span><br></pre></td></tr></table></figure>- 매 20분마다 실행하고 싶을 때<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/20 * * * * python3 /directory/crawling.py</span><br></pre></td></tr></table></figure>2-2. 범위- 매주 수요일에서 금요일까지 1시 30분마다 실행 시킬 때<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30 1 * * 3-5 python3 /directory/crawling.py</span><br></pre></td></tr></table></figure><h2 id="3-예제"><a href="#3-예제" class="headerlink" title="3. 예제"></a>3. 예제</h2><p>2분마다 “THIS IS CRONTAAAB”을 test.txt 에 기록해보자.</p><ul><li>“THIS IS CRONTAAAB”을 test.txt 파일에 기록하는 shell command 를 작성합니다.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># program.sh파일에 다음과 같이 작성합니다.</span><br><span class="line">echo &quot;THIS IS CRONTAAAB&quot; &gt;&gt; ./test.txt&quot;</span><br></pre></td></tr></table></figure></li><li><code>crontab -l</code> 명령어를 통해 다음과 같이 작성합니다<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/2 * * * * /directory/program.sh </span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;데이터를 모으기 위해 크롤링을 진행하거나, 머신러닝, 딥러닝 실험을 할 때 Linux 환경의 머신에서 정해진 시간과 주기에 맞추어 크롤링을 실행하고, 학습을 해준다면, 수많은 작업들을 미리 설정해둔 내용을 바탕으로 편하게 작업을 자동화 할 수 있습니다. &lt;/p&gt;</summary>
    
    
    
    <category term="Development" scheme="https://emjayahn.github.io/categories/Development/"/>
    
    <category term="Linux" scheme="https://emjayahn.github.io/categories/Development/Linux/"/>
    
    
    <category term="linux" scheme="https://emjayahn.github.io/tags/linux/"/>
    
    <category term="리눅스" scheme="https://emjayahn.github.io/tags/%EB%A6%AC%EB%88%85%EC%8A%A4/"/>
    
    <category term="crontab" scheme="https://emjayahn.github.io/tags/crontab/"/>
    
    <category term="크론탭" scheme="https://emjayahn.github.io/tags/%ED%81%AC%EB%A1%A0%ED%83%AD/"/>
    
  </entry>
  
</feed>
